# Lingua 项目架构与技术报告（第一部分：概述、架构与技术）

**生成日期**: 2025-01-27  
**项目版本**: v0.1.0  
**报告版本**: 1.0

> **注意**: 这是报告的第一部分，包含项目概述、系统架构、业务流程、技术栈、模型版本和客户端架构。  
> 完整报告还包括：[第二部分：部署、性能与结构](./v0.1_第二部分_部署性能与结构.md)

---

## 目录

1. [项目概述](#1-项目概述)
2. [系统架构](#2-系统架构)
3. [业务流程](#3-业务流程)
4. [技术栈](#4-技术栈)
5. [模型版本](#5-模型版本)
6. [客户端架构](#6-客户端架构)

---

## 1. 项目概述

### 1.1 项目定位

**Lingua** 是一个**实时语音转语音翻译系统**（Speech-to-Speech Translation, S2S），旨在实现跨语言的实时自然交流。系统支持将一种语言的语音输入转换为另一种语言的语音输出，实现端到端的实时翻译。

### 1.2 核心特性

- ✅ **实时翻译**: 支持流式处理，低延迟响应
- ✅ **多语言支持**: 支持中文、英文等多种语言
- ✅ **本地部署**: 所有处理在本地完成，保护用户隐私
- ✅ **模块化设计**: 各组件可独立替换和升级
- ✅ **GPU 加速**: ASR 和 NMT 支持 CUDA GPU 加速
- ✅ **流式处理**: 支持增量翻译和增量语音合成

### 1.3 支持的语言对

- ✅ **英文 → 中文** (en → zh)
- ✅ **中文 → 英文** (zh → en)

---

## 2. 系统架构

### 2.1 整体架构

Lingua 采用**微服务架构**，核心服务与客户端分离，实现"一套核心，多种壳"的设计理念。

```
┌─────────────────────────────────────────────────────────────┐
│                        客户端层                              │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐   │
│  │ Chrome   │  │ Electron │  │  Mobile  │  │   PWA    │   │
│  │ Extension│  │          │  │          │  │          │   │
│  └────┬─────┘  └────┬─────┘  └────┬─────┘  └────┬─────┘   │
└───────┼─────────────┼─────────────┼─────────────┼─────────┘
        │             │             │             │
        └─────────────┴─────────────┴─────────────┘
                          │
        ┌─────────────────┴─────────────────┐
        │                                   │
┌───────▼───────────────────────────────────▼──────────────┐
│              CoreEngine Service (Rust)                   │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐│
│  │   VAD    │  │   ASR    │  │  Emotion │  │  Persona ││
│  │ (Silero) │  │ (Whisper)│  │ (XLM-R)  │  │ (Rule)   ││
│  └────┬─────┘  └────┬─────┘  └────┬─────┘  └────┬─────┘│
│       │             │             │             │      │
│       └─────────────┴─────────────┴─────────────┘      │
│                          │                              │
│                    ┌─────▼─────┐                        │
│                    │ EventBus  │                        │
│                    └─────┬─────┘                        │
│                          │                              │
│       ┌──────────────────┴──────────────────┐          │
│       │                                     │          │
│  ┌────▼─────┐                        ┌─────▼─────┐    │
│  │   NMT    │                        │    TTS    │    │
│  │ (Marian) │                        │  (Piper)  │    │
│  └────┬─────┘                        └─────┬─────┘    │
└───────┼────────────────────────────────────┼──────────┘
        │                                    │
┌───────▼──────────────┐         ┌──────────▼──────────┐
│  NMT Service         │         │  TTS Service        │
│  (Python + M2M100)   │         │  (Piper HTTP)       │
│  Port: 5008          │         │  Port: 5005         │
│  GPU: CUDA 12.1      │         │  GPU: 未启用        │
└──────────────────────┘         └─────────────────────┘
```

### 2.2 核心服务组成

#### 2.2.1 CoreEngine Service（核心引擎）

**技术栈**: Rust + Tokio  
**端口**: 5009  
**职责**:
- 统一编排各个模块
- 通过 EventBus 发布事件
- 管理模块生命周期
- 对外暴露统一 S2S API

**主要组件**:
- `EventBus`: 事件总线，用于模块间通信
- `VAD`: 语音活动检测（Silero VAD）
- `ASR`: 语音识别（Whisper，支持 CUDA GPU 加速）
- `NMT Client`: 机器翻译客户端（调用 NMT Service）
- `Emotion`: 情感分析（XLM-R ONNX，部分完成）
- `Persona`: 个性化适配（基于规则的文本转换）
- `TTS Client`: 语音合成客户端（调用 TTS Service）
- `ConfigManager`: 配置管理
- `CacheManager`: 缓存管理
- `TelemetrySink`: 遥测数据收集

**GPU 支持**: ✅ CUDA 12.4（Whisper ASR）

#### 2.2.2 NMT Service（机器翻译服务）

**技术栈**: Python + FastAPI + PyTorch  
**端口**: 5008  
**职责**: 提供神经机器翻译能力

**模型**: M2M100
- `m2m100-en-zh`: 英文→中文
- `m2m100-zh-en`: 中文→英文

**GPU 支持**: ✅ PyTorch CUDA 12.1

#### 2.2.3 TTS Service（语音合成服务）

**技术栈**: Piper TTS + FastAPI（WSL2）  
**端口**: 5005  
**职责**: 提供语音合成能力

**模型**: Piper TTS
- 中文: `zh_CN-huayan-medium`
- 英文: `en_US-lessac-medium`

**GPU 支持**: ❌ 暂未启用

---

## 3. 业务流程

### 3.1 核心翻译流程

```
输入语音（音频流）
    ↓
┌─────────────────────────────────────┐
│  VAD (语音活动检测)                  │
│  - 检测语音段边界                    │
│  - 识别静音和语音                    │
│  模型: Silero VAD                   │
└──────────────┬──────────────────────┘
               ↓
┌─────────────────────────────────────┐
│  ASR (语音识别)                      │
│  - 将语音转换为文本                  │
│  - 自动语言检测                      │
│  - 流式识别                          │
│  模型: Whisper Base (CUDA GPU)      │
└──────────────┬──────────────────────┘
               ↓
┌─────────────────────────────────────┐
│  Emotion (情感分析) [可选]           │
│  - 分析文本情感                      │
│  - 生成情感标签                      │
│  模型: XLM-R ONNX (部分完成)        │
└──────────────┬──────────────────────┘
               ↓
┌─────────────────────────────────────┐
│  Persona (个性化适配) [可选]         │
│  - 根据文化背景调整文本              │
│  - 支持专业/非正式风格转换           │
│  实现: 基于规则的文本转换            │
└──────────────┬──────────────────────┘
               ↓
┌─────────────────────────────────────┐
│  NMT (机器翻译)                      │
│  - 将源语言文本翻译为目标语言        │
│  - 支持增量翻译                      │
│  - KV Cache 优化                    │
│  模型: M2M100 (PyTorch CUDA GPU)    │
└──────────────┬──────────────────────┘
               ↓
┌─────────────────────────────────────┐
│  TTS (语音合成)                      │
│  - 将翻译文本合成为语音              │
│  - 流式合成                          │
│  模型: Piper TTS                    │
└──────────────┬──────────────────────┘
               ↓
输出语音（音频流）
```

### 3.2 事件驱动架构

系统采用**事件驱动架构**，通过 `EventBus` 实现模块间解耦：

**主要事件类型**:
- `asr.partial`: ASR 部分识别结果
- `asr.final`: ASR 最终识别结果
- `emotion.detected`: 情感分析结果
- `persona.adjusted`: 个性化调整结果
- `translation.complete`: 翻译完成
- `tts.audio`: TTS 音频输出
- `s2s.complete`: 端到端翻译完成

### 3.3 流式处理

系统支持**流式处理**，实现低延迟：

1. **流式 ASR**: 实时识别语音，输出部分和最终结果
2. **增量 NMT**: 支持增量解码，利用 KV Cache 优化
3. **流式 TTS**: 支持增量语音合成和播放

---

## 4. 技术栈

### 4.1 编程语言

| 组件 | 语言 | 版本 |
|------|------|------|
| 核心引擎 | Rust | Edition 2021 |
| NMT 服务 | Python | 3.10+ |
| TTS 服务 | Python | 3.10+ (WSL2) |
| 客户端 | TypeScript/JavaScript | ES2020+ |

### 4.2 核心依赖（Rust）

| 依赖 | 版本 | 用途 |
|------|------|------|
| `tokio` | 1.x | 异步运行时 |
| `ort` | 1.16.3 | ONNX Runtime（模型推理） |
| `whisper-rs` | 0.15.1 | Whisper ASR 集成（CUDA 支持） |
| `ndarray` | 0.15 | 数值计算 |
| `serde` | 1.x | 序列化/反序列化 |
| `reqwest` | 0.11 | HTTP 客户端（TTS 服务调用） |
| `axum` | 0.7 | HTTP 服务器框架 |
| `tokio-tungstenite` | 0.21 | WebSocket 支持 |
| `tokenizers` | 0.15 | Tokenizer 支持（Emotion） |

### 4.3 核心依赖（Python）

#### NMT Service

| 依赖 | 版本 | 用途 |
|------|------|------|
| `fastapi` | ≥0.104.0 | Web 框架 |
| `uvicorn` | ≥0.24.0 | ASGI 服务器 |
| `torch` | ≥2.0.0 | PyTorch（CUDA 12.1） |
| `transformers` | 4.35.0-4.50.0 | HuggingFace Transformers |
| `sentencepiece` | ≥0.1.99 | 文本分词 |
| `safetensors` | ≥0.4.1 | 模型加载 |

#### TTS Service

- Piper TTS（通过 WSL2 部署）
- FastAPI（HTTP 服务）

### 4.4 模型技术

| 模块 | 技术 | 模型 |
|------|------|------|
| ASR | Whisper (OpenAI) | whisper-base |
| NMT | M2M100 (Facebook) | m2m100-en-zh, m2m100-zh-en |
| TTS | Piper TTS | zh_CN-huayan-medium, en_US-lessac-medium |
| Emotion | XLM-R (Facebook) | xlm-r-base (部分完成) |
| VAD | Silero VAD | silero_vad_official.onnx |

### 4.5 部署环境

| 环境 | 说明 |
|------|------|
| 开发环境 | Windows 10/11 |
| 运行时 | Windows (主系统) + WSL2 (TTS 服务) |
| GPU | NVIDIA CUDA 12.4 (ASR), CUDA 12.1 (NMT) |
| 目标平台 | 本地部署（当前），WASM/浏览器（计划中） |

---

## 5. 模型版本

### 5.1 ASR 模型

**模型**: Whisper Base  
**版本**: whisper-base  
**位置**: `core/engine/models/asr/whisper-base/`  
**格式**: ONNX (int8 量化) + GGML  
**大小**: 147 MB  
**特性**:
- 支持 99 种语言
- 自动语言检测
- 流式识别
- CUDA GPU 加速

**文件结构**:
```
whisper-base/
├── encoder_model_int8.onnx
├── decoder_model_int8.onnx
├── decoder_with_past_model_int8.onnx
├── ggml-base.bin
├── tokenizer.json
├── vocab.json
└── config.json
```

### 5.2 NMT 模型

**模型**: M2M100  
**版本**: 
- `m2m100-en-zh`: 英文→中文
- `m2m100-zh-en`: 中文→英文

**位置**: `core/engine/models/nmt/`  
**格式**: ONNX  
**特性**:
- 支持增量翻译
- KV Cache 优化
- PyTorch CUDA GPU 加速

**文件结构**:
```
m2m100-en-zh/
├── encoder.onnx
├── decoder.onnx
├── tokenizer.json
├── vocab.json
└── config.json
```

### 5.3 TTS 模型

**模型**: Piper TTS  
**版本**:
- 中文: `zh_CN-huayan-medium`
- 英文: `en_US-lessac-medium`

**位置**: WSL2 环境  
**格式**: Piper 原生格式  
**特性**:
- 高质量语音合成
- 流式合成
- 多语言支持

### 5.4 VAD 模型

**模型**: Silero VAD  
**版本**: silero_vad_official  
**位置**: `core/engine/models/vad/silero/`  
**格式**: ONNX  
**特性**:
- 实时语音活动检测
- 低延迟
- 高准确率

### 5.5 Emotion 模型

**模型**: XLM-R  
**版本**: xlm-r-base  
**位置**: `core/engine/models/emotion/xlm-r/`  
**格式**: ONNX (IR 9)  
**状态**: ⚠️ 部分完成（存在 IR 版本兼容性问题）

---

## 6. 客户端架构

### 6.1 客户端类型

系统支持多种客户端形态，均通过统一的 API 与核心服务通信：

#### 6.1.1 Chrome 扩展

**技术栈**: TypeScript  
**位置**: `clients/chrome_extension/`  
**功能**:
- 音频采集（MediaRecorder）
- WebSocket 流式通信
- 实时字幕显示
- 音频播放

**主要模块**:
- `background/`: 后台服务（EngineBridge, EventRelay）
- `content/`: 内容脚本（音频捕获）
- `ui/`: 用户界面（状态管理）

#### 6.1.2 Electron 应用

**技术栈**: TypeScript + Electron  
**位置**: `clients/electron/`  
**状态**: 开发中

#### 6.1.3 移动端应用

**技术栈**: React Native / Flutter  
**位置**: `clients/mobile/`  
**状态**: 规划中

#### 6.1.4 Web PWA

**技术栈**: JavaScript  
**位置**: `clients/web_pwa/`  
**功能**:
- 渐进式 Web 应用
- 离线支持
- 实时翻译界面

### 6.2 客户端 API

#### 6.2.1 同步 S2S API

**端点**: `POST /s2s`  
**请求**:
```json
{
  "audio": "<base64_encoded_audio>",
  "src_lang": "en",
  "tgt_lang": "zh"
}
```

**响应**:
```json
{
  "audio": "<base64_encoded_audio>",
  "transcript": "源语言文本",
  "translation": "目标语言文本"
}
```

#### 6.2.2 WebSocket 流式 API

**端点**: `WS /stream`  
**消息类型**:
- `start`: 开始流式翻译
- `audio`: 发送音频数据
- `output`: 接收翻译结果
- `stop`: 停止翻译

---

**继续阅读**: [第二部分：部署、性能与结构](./v0.1_第二部分_部署性能与结构.md)

