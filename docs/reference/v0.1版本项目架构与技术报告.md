# Lingua 项目架构与技术报告

**生成日期**: 2025-01-27  
**项目版本**: v0.1.0  
**报告版本**: 1.0

---

## 目录

1. [项目概述](#1-项目概述)
2. [系统架构](#2-系统架构)
3. [业务流程](#3-业务流程)
4. [技术栈](#4-技术栈)
5. [模型版本](#5-模型版本)
6. [客户端架构](#6-客户端架构)
7. [部署架构](#7-部署架构)
8. [性能指标](#8-性能指标)
9. [项目结构](#9-项目结构)

---

## 1. 项目概述

### 1.1 项目定位

**Lingua** 是一个**实时语音转语音翻译系统**（Speech-to-Speech Translation, S2S），旨在实现跨语言的实时自然交流。系统支持将一种语言的语音输入转换为另一种语言的语音输出，实现端到端的实时翻译。

### 1.2 核心特性

- ✅ **实时翻译**: 支持流式处理，低延迟响应
- ✅ **多语言支持**: 支持中文、英文等多种语言
- ✅ **本地部署**: 所有处理在本地完成，保护用户隐私
- ✅ **模块化设计**: 各组件可独立替换和升级
- ✅ **GPU 加速**: ASR 和 NMT 支持 CUDA GPU 加速
- ✅ **流式处理**: 支持增量翻译和增量语音合成

### 1.3 支持的语言对

- ✅ **英文 → 中文** (en → zh)
- ✅ **中文 → 英文** (zh → en)

---

## 2. 系统架构

### 2.1 整体架构

Lingua 采用**微服务架构**，核心服务与客户端分离，实现"一套核心，多种壳"的设计理念。

```
┌─────────────────────────────────────────────────────────────┐
│                        客户端层                              │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐   │
│  │ Chrome   │  │ Electron │  │  Mobile  │  │   PWA    │   │
│  │ Extension│  │          │  │          │  │          │   │
│  └────┬─────┘  └────┬─────┘  └────┬─────┘  └────┬─────┘   │
└───────┼─────────────┼─────────────┼─────────────┼─────────┘
        │             │             │             │
        └─────────────┴─────────────┴─────────────┘
                          │
        ┌─────────────────┴─────────────────┐
        │                                   │
┌───────▼───────────────────────────────────▼──────────────┐
│              CoreEngine Service (Rust)                   │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐│
│  │   VAD    │  │   ASR    │  │  Emotion │  │  Persona ││
│  │ (Silero) │  │ (Whisper)│  │ (XLM-R)  │  │ (Rule)   ││
│  └────┬─────┘  └────┬─────┘  └────┬─────┘  └────┬─────┘│
│       │             │             │             │      │
│       └─────────────┴─────────────┴─────────────┘      │
│                          │                              │
│                    ┌─────▼─────┐                        │
│                    │ EventBus  │                        │
│                    └─────┬─────┘                        │
│                          │                              │
│       ┌──────────────────┴──────────────────┐          │
│       │                                     │          │
│  ┌────▼─────┐                        ┌─────▼─────┐    │
│  │   NMT    │                        │    TTS    │    │
│  │ (Marian) │                        │  (Piper)  │    │
│  └────┬─────┘                        └─────┬─────┘    │
└───────┼────────────────────────────────────┼──────────┘
        │                                    │
┌───────▼──────────────┐         ┌──────────▼──────────┐
│  NMT Service         │         │  TTS Service        │
│  (Python + M2M100)   │         │  (Piper HTTP)       │
│  Port: 5008          │         │  Port: 5005         │
│  GPU: CUDA 12.1      │         │  GPU: 未启用        │
└──────────────────────┘         └─────────────────────┘
```

### 2.2 核心服务组成

#### 2.2.1 CoreEngine Service（核心引擎）

**技术栈**: Rust + Tokio  
**端口**: 9000  
**职责**:
- 统一编排各个模块
- 通过 EventBus 发布事件
- 管理模块生命周期
- 对外暴露统一 S2S API

**主要组件**:
- `EventBus`: 事件总线，用于模块间通信
- `VAD`: 语音活动检测（Silero VAD）
- `ASR`: 语音识别（Whisper，支持 CUDA GPU 加速）
- `NMT Client`: 机器翻译客户端（调用 NMT Service）
- `Emotion`: 情感分析（XLM-R ONNX，部分完成）
- `Persona`: 个性化适配（基于规则的文本转换）
- `TTS Client`: 语音合成客户端（调用 TTS Service）
- `ConfigManager`: 配置管理
- `CacheManager`: 缓存管理
- `TelemetrySink`: 遥测数据收集

**GPU 支持**: ✅ CUDA 12.4（Whisper ASR）

#### 2.2.2 NMT Service（机器翻译服务）

**技术栈**: Python + FastAPI + PyTorch  
**端口**: 5008  
**职责**: 提供神经机器翻译能力

**模型**: M2M100
- `m2m100-en-zh`: 英文→中文
- `m2m100-zh-en`: 中文→英文

**GPU 支持**: ✅ PyTorch CUDA 12.1

#### 2.2.3 TTS Service（语音合成服务）

**技术栈**: Piper TTS + FastAPI（WSL2）  
**端口**: 5005  
**职责**: 提供语音合成能力

**模型**: Piper TTS
- 中文: `zh_CN-huayan-medium`
- 英文: `en_US-lessac-medium`

**GPU 支持**: ❌ 暂未启用

---

## 3. 业务流程

### 3.1 核心翻译流程

```
输入语音（音频流）
    ↓
┌─────────────────────────────────────┐
│  VAD (语音活动检测)                  │
│  - 检测语音段边界                    │
│  - 识别静音和语音                    │
│  模型: Silero VAD                   │
└──────────────┬──────────────────────┘
               ↓
┌─────────────────────────────────────┐
│  ASR (语音识别)                      │
│  - 将语音转换为文本                  │
│  - 自动语言检测                      │
│  - 流式识别                          │
│  模型: Whisper Base (CUDA GPU)      │
└──────────────┬──────────────────────┘
               ↓
┌─────────────────────────────────────┐
│  Emotion (情感分析) [可选]           │
│  - 分析文本情感                      │
│  - 生成情感标签                      │
│  模型: XLM-R ONNX (部分完成)        │
└──────────────┬──────────────────────┘
               ↓
┌─────────────────────────────────────┐
│  Persona (个性化适配) [可选]         │
│  - 根据文化背景调整文本              │
│  - 支持专业/非正式风格转换           │
│  实现: 基于规则的文本转换            │
└──────────────┬──────────────────────┘
               ↓
┌─────────────────────────────────────┐
│  NMT (机器翻译)                      │
│  - 将源语言文本翻译为目标语言        │
│  - 支持增量翻译                      │
│  - KV Cache 优化                    │
│  模型: M2M100 (PyTorch CUDA GPU)    │
└──────────────┬──────────────────────┘
               ↓
┌─────────────────────────────────────┐
│  TTS (语音合成)                      │
│  - 将翻译文本合成为语音              │
│  - 流式合成                          │
│  模型: Piper TTS                    │
└──────────────┬──────────────────────┘
               ↓
输出语音（音频流）
```

### 3.2 事件驱动架构

系统采用**事件驱动架构**，通过 `EventBus` 实现模块间解耦：

**主要事件类型**:
- `asr.partial`: ASR 部分识别结果
- `asr.final`: ASR 最终识别结果
- `emotion.detected`: 情感分析结果
- `persona.adjusted`: 个性化调整结果
- `translation.complete`: 翻译完成
- `tts.audio`: TTS 音频输出
- `s2s.complete`: 端到端翻译完成

### 3.3 流式处理

系统支持**流式处理**，实现低延迟：

1. **流式 ASR**: 实时识别语音，输出部分和最终结果
2. **增量 NMT**: 支持增量解码，利用 KV Cache 优化
3. **流式 TTS**: 支持增量语音合成和播放

---

## 4. 技术栈

### 4.1 编程语言

| 组件 | 语言 | 版本 |
|------|------|------|
| 核心引擎 | Rust | Edition 2021 |
| NMT 服务 | Python | 3.10+ |
| TTS 服务 | Python | 3.10+ (WSL2) |
| 客户端 | TypeScript/JavaScript | ES2020+ |

### 4.2 核心依赖（Rust）

| 依赖 | 版本 | 用途 |
|------|------|------|
| `tokio` | 1.x | 异步运行时 |
| `ort` | 1.16.3 | ONNX Runtime（模型推理） |
| `whisper-rs` | 0.15.1 | Whisper ASR 集成（CUDA 支持） |
| `ndarray` | 0.15 | 数值计算 |
| `serde` | 1.x | 序列化/反序列化 |
| `reqwest` | 0.11 | HTTP 客户端（TTS 服务调用） |
| `axum` | 0.7 | HTTP 服务器框架 |
| `tokio-tungstenite` | 0.21 | WebSocket 支持 |
| `tokenizers` | 0.15 | Tokenizer 支持（Emotion） |

### 4.3 核心依赖（Python）

#### NMT Service

| 依赖 | 版本 | 用途 |
|------|------|------|
| `fastapi` | ≥0.104.0 | Web 框架 |
| `uvicorn` | ≥0.24.0 | ASGI 服务器 |
| `torch` | ≥2.0.0 | PyTorch（CUDA 12.1） |
| `transformers` | 4.35.0-4.50.0 | HuggingFace Transformers |
| `sentencepiece` | ≥0.1.99 | 文本分词 |
| `safetensors` | ≥0.4.1 | 模型加载 |

#### TTS Service

- Piper TTS（通过 WSL2 部署）
- FastAPI（HTTP 服务）

### 4.4 模型技术

| 模块 | 技术 | 模型 |
|------|------|------|
| ASR | Whisper (OpenAI) | whisper-base |
| NMT | M2M100 (Facebook) | m2m100-en-zh, m2m100-zh-en |
| TTS | Piper TTS | zh_CN-huayan-medium, en_US-lessac-medium |
| Emotion | XLM-R (Facebook) | xlm-r-base (部分完成) |
| VAD | Silero VAD | silero_vad_official.onnx |

### 4.5 部署环境

| 环境 | 说明 |
|------|------|
| 开发环境 | Windows 10/11 |
| 运行时 | Windows (主系统) + WSL2 (TTS 服务) |
| GPU | NVIDIA CUDA 12.4 (ASR), CUDA 12.1 (NMT) |
| 目标平台 | 本地部署（当前），WASM/浏览器（计划中） |

---

## 5. 模型版本

### 5.1 ASR 模型

**模型**: Whisper Base  
**版本**: whisper-base  
**位置**: `core/engine/models/asr/whisper-base/`  
**格式**: ONNX (int8 量化) + GGML  
**大小**: 147 MB  
**特性**:
- 支持 99 种语言
- 自动语言检测
- 流式识别
- CUDA GPU 加速

**文件结构**:
```
whisper-base/
├── encoder_model_int8.onnx
├── decoder_model_int8.onnx
├── decoder_with_past_model_int8.onnx
├── ggml-base.bin
├── tokenizer.json
├── vocab.json
└── config.json
```

### 5.2 NMT 模型

**模型**: M2M100  
**版本**: 
- `m2m100-en-zh`: 英文→中文
- `m2m100-zh-en`: 中文→英文

**位置**: `core/engine/models/nmt/`  
**格式**: ONNX  
**特性**:
- 支持增量翻译
- KV Cache 优化
- PyTorch CUDA GPU 加速

**文件结构**:
```
m2m100-en-zh/
├── encoder.onnx
├── decoder.onnx
├── tokenizer.json
├── vocab.json
└── config.json
```

### 5.3 TTS 模型

**模型**: Piper TTS  
**版本**:
- 中文: `zh_CN-huayan-medium`
- 英文: `en_US-lessac-medium`

**位置**: WSL2 环境  
**格式**: Piper 原生格式  
**特性**:
- 高质量语音合成
- 流式合成
- 多语言支持

### 5.4 VAD 模型

**模型**: Silero VAD  
**版本**: silero_vad_official  
**位置**: `core/engine/models/vad/silero/`  
**格式**: ONNX  
**特性**:
- 实时语音活动检测
- 低延迟
- 高准确率

### 5.5 Emotion 模型

**模型**: XLM-R  
**版本**: xlm-r-base  
**位置**: `core/engine/models/emotion/xlm-r/`  
**格式**: ONNX (IR 9)  
**状态**: ⚠️ 部分完成（存在 IR 版本兼容性问题）

---

## 6. 客户端架构

### 6.1 客户端类型

系统支持多种客户端形态，均通过统一的 API 与核心服务通信：

#### 6.1.1 Chrome 扩展

**技术栈**: TypeScript  
**位置**: `clients/chrome_extension/`  
**功能**:
- 音频采集（MediaRecorder）
- WebSocket 流式通信
- 实时字幕显示
- 音频播放

**主要模块**:
- `background/`: 后台服务（EngineBridge, EventRelay）
- `content/`: 内容脚本（音频捕获）
- `ui/`: 用户界面（状态管理）

#### 6.1.2 Electron 应用

**技术栈**: TypeScript + Electron  
**位置**: `clients/electron/`  
**状态**: 开发中

#### 6.1.3 移动端应用

**技术栈**: React Native / Flutter  
**位置**: `clients/mobile/`  
**状态**: 规划中

#### 6.1.4 Web PWA

**技术栈**: JavaScript  
**位置**: `clients/web_pwa/`  
**功能**:
- 渐进式 Web 应用
- 离线支持
- 实时翻译界面

### 6.2 客户端 API

#### 6.2.1 同步 S2S API

**端点**: `POST /s2s`  
**请求**:
```json
{
  "audio": "<base64_encoded_audio>",
  "src_lang": "en",
  "tgt_lang": "zh"
}
```

**响应**:
```json
{
  "audio": "<base64_encoded_audio>",
  "transcript": "源语言文本",
  "translation": "目标语言文本"
}
```

#### 6.2.2 WebSocket 流式 API

**端点**: `WS /stream`  
**消息类型**:
- `start`: 开始流式翻译
- `audio`: 发送音频数据
- `output`: 接收翻译结果
- `stop`: 停止翻译

---

## 7. 部署架构

### 7.1 服务部署

```
┌─────────────────────────────────────────┐
│         Windows 主系统                   │
│                                         │
│  ┌───────────────────────────────────┐ │
│  │  CoreEngine Service (Rust)        │ │
│  │  Port: 9000                       │ │
│  │  GPU: CUDA 12.4                   │ │
│  └───────────────────────────────────┘ │
│                                         │
│  ┌───────────────────────────────────┐ │
│  │  NMT Service (Python)             │ │
│  │  Port: 5008                       │ │
│  │  GPU: PyTorch CUDA 12.1           │ │
│  └───────────────────────────────────┘ │
│                                         │
└─────────────────────────────────────────┘
              │
              │ WSL2
              ▼
┌─────────────────────────────────────────┐
│         WSL2 (Ubuntu)                   │
│                                         │
│  ┌───────────────────────────────────┐ │
│  │  TTS Service (Piper HTTP)         │ │
│  │  Port: 5005                       │ │
│  │  GPU: 未启用                      │ │
│  └───────────────────────────────────┘ │
│                                         │
└─────────────────────────────────────────┘
```

### 7.2 配置文件

**主配置**: `lingua_core_config.toml`

```toml
[nmt]
url = "http://127.0.0.1:5008"

[tts]
url = "http://127.0.0.1:5005/tts"

[asr]
url = "http://127.0.0.1:6006"

[engine]
port = 9000
whisper_model_path = "models/asr/whisper-base"
silero_vad_model_path = "models/vad/silero/silero_vad_official.onnx"
```

### 7.3 启动脚本

**一键启动**: `start_all_services_simple.ps1`  
**一键停止**: `stop_all_services.ps1`

**启动流程**:
1. 设置 CUDA 环境变量
2. 启动 NMT 服务（Python）
3. 启动 CoreEngine（Rust）
4. 验证服务健康状态

---

## 8. 性能指标

### 8.1 GPU 加速效果

| 组件 | CPU 耗时 | GPU 耗时 | 提升倍数 |
|------|---------|---------|---------|
| ASR (Whisper) | 6-7 秒 | 1-2 秒 | 3-4x |
| NMT (M2M100) | 3-4 秒 | 0.5-1 秒 | 3-4x |
| **端到端总计** | **13-15 秒** | **4.5-7 秒** | **2-3x** |

### 8.2 系统要求

**最低要求**:
- CPU: 4 核以上
- 内存: 8 GB
- 存储: 5 GB（模型文件）
- GPU: NVIDIA GPU（可选，但强烈推荐）

**推荐配置**:
- CPU: 8 核以上
- 内存: 16 GB
- 存储: 10 GB（模型文件）
- GPU: NVIDIA RTX 3060 或更高

### 8.3 延迟指标

- **ASR 延迟**: 1-2 秒（GPU）
- **NMT 延迟**: 0.5-1 秒（GPU）
- **TTS 延迟**: 0.5-1 秒
- **端到端延迟**: 4.5-7 秒（GPU）

---

## 9. 项目结构

```
lingua/
├── core/
│   ├── engine/                    # 核心引擎 (Rust)
│   │   ├── src/                   # 源代码
│   │   │   ├── bootstrap/         # 核心引擎启动
│   │   │   ├── asr_whisper/       # ASR 模块
│   │   │   ├── nmt_incremental/   # NMT 模块
│   │   │   ├── tts_streaming/     # TTS 模块
│   │   │   ├── emotion_adapter/   # 情感分析
│   │   │   ├── persona_adapter/   # 个性化适配
│   │   │   ├── vad/               # VAD 模块
│   │   │   └── ...
│   │   ├── models/                # 模型文件
│   │   │   ├── asr/               # ASR 模型
│   │   │   ├── nmt/               # NMT 模型
│   │   │   ├── tts/               # TTS 模型
│   │   │   ├── vad/               # VAD 模型
│   │   │   └── emotion/           # Emotion 模型
│   │   ├── Cargo.toml             # Rust 依赖
│   │   └── docs/                  # 文档
│   └── bindings/                  # 绑定（WASM 等）
│
├── services/
│   └── nmt_m2m100/                # NMT 服务 (Python)
│       ├── nmt_service.py         # FastAPI 服务
│       ├── requirements.txt       # Python 依赖
│       └── venv/                  # 虚拟环境
│
├── clients/                       # 客户端
│   ├── chrome_extension/          # Chrome 扩展
│   ├── electron/                  # Electron 应用
│   ├── mobile/                    # 移动端
│   └── web_pwa/                   # Web PWA
│
├── docs/                          # 文档
│   ├── architecture/              # 架构文档
│   ├── operational/               # 运维文档
│   ├── models/                    # 模型文档
│   └── product/                   # 产品文档
│
├── scripts/                       # 脚本工具
│   ├── *.ps1                      # PowerShell 脚本
│   └── *.py                       # Python 脚本
│
├── third_party/                   # 第三方库
│   ├── whisper.cpp/               # Whisper C++ 实现
│   ├── piper/                     # Piper TTS
│   └── esaxx-rs/                  # 补丁库
│
├── config.toml                    # 配置文件
├── lingua_core_config.toml        # 核心配置
├── start_all_services_simple.ps1  # 一键启动脚本
└── stop_all_services.ps1          # 一键停止脚本
```

---

## 10. 技术亮点

### 10.1 架构设计

- ✅ **模块化设计**: 各组件通过 Trait 接口解耦，易于替换和测试
- ✅ **事件驱动**: 通过 EventBus 实现模块间异步通信
- ✅ **微服务架构**: 核心服务与客户端分离，支持多端接入

### 10.2 性能优化

- ✅ **GPU 加速**: ASR 和 NMT 支持 CUDA GPU 加速，性能提升 3-4 倍
- ✅ **KV Cache**: NMT 模块使用 KV Cache 优化，减少重复计算
- ✅ **增量处理**: 支持增量翻译和增量语音合成，降低延迟

### 10.3 技术选型

- ✅ **Rust**: 核心引擎使用 Rust，保证性能和安全性
- ✅ **ONNX Runtime**: 统一的模型推理框架，支持多模型
- ✅ **流式处理**: 支持实时流式处理，提升用户体验

---

## 11. 已知问题与限制

### 11.1 当前问题

1. **Emotion 模块**: 存在 ONNX IR 版本兼容性问题（需要 IR ≤ 9，但部分模型为 IR 10）
2. **TTS GPU 加速**: 暂未启用 GPU 加速
3. **WSL2 依赖**: 中文 TTS 依赖 WSL2 环境，增加部署复杂度

### 11.2 技术债务

1. **ONNX Runtime 版本锁定**: 当前使用 ort 1.16.3（仅支持 IR ≤ 9），限制了可用的模型版本
2. **Windows 链接器问题**: 已通过修改 esaxx-rs 解决，但需要维护本地补丁

### 11.3 待完成功能

- ⚠️ WASM 构建（浏览器集成）
- ⚠️ Chrome 扩展完整集成
- ⚠️ 移动端应用开发
- ⚠️ 更多语言对支持

---

## 12. 开发与维护

### 12.1 开发环境

- **操作系统**: Windows 10/11
- **Rust**: Edition 2021
- **Python**: 3.10+
- **CUDA**: 12.4 (ASR), 12.1 (NMT)
- **IDE**: Visual Studio Code / Cursor

### 12.2 构建命令

```powershell
# 编译核心引擎（Release）
cd core/engine
cargo build --release

# 编译核心引擎（CUDA 支持）
cargo build --release --features cuda
```

### 12.3 测试命令

```powershell
# 运行单元测试
cd core/engine
cargo test

# 运行集成测试
cargo test --test integration_test
```

### 12.4 启动服务

```powershell
# 一键启动所有服务
.\start_all_services_simple.ps1

# 一键停止所有服务
.\stop_all_services.ps1
```

---

## 13. 相关文档

### 13.1 核心文档

- `docs/PROJECT_OVERVIEW.md` - 项目总览
- `docs/DOCUMENTATION_INDEX.md` - 文档索引
- `docs/product/Lingua_Core_Runtime_一键启动与服务设计说明.md` - 服务设计说明

### 13.2 架构文档

- `core/engine/docs/SYSTEM_ARCHITECTURE_OVERVIEW.md` - 系统架构总览
- `docs/architecture/` - 架构相关文档

### 13.3 运维文档

- `docs/operational/编译和启动命令参考.md` - 编译和启动命令
- `docs/GPU_启用指南.md` - GPU 配置指南

---

## 14. 版本历史

| 版本 | 日期 | 说明 |
|------|------|------|
| v0.1.0 | 2025-01-27 | 初始版本，核心功能完成 |

---

## 15. 联系方式

**项目名称**: Lingua  
**项目类型**: 语音转语音翻译系统  
**开发状态**: 活跃开发中  
**最后更新**: 2025-01-27

---

**报告版本**: 1.0  
**生成日期**: 2025-01-27  
**维护者**: 开发团队

