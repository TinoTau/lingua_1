# 两层 VAD 架构设计（轻量 VAD 客户端 + Silero VAD 节点端）
版本：v1.0  
适用对象：移动端开发、调度服务器开发、节点服务开发  

---

# 1. 背景与目标

本设计用于在以下需求下提供稳定可控的实时语音翻译体验：

- 手机端需要 **连续输入**，不要求精确断句；
- 不希望手机端承担高计算量 VAD（如 Silero/ORT），避免发热和功耗；
- 不希望用户声明语速或手动调参；
- 想要保持高质量 ASR（Whisper 等）的 **上下文连续性**；
- 服务器/节点可以承担更多计算并拥有更稳定的语音处理能力。

为此，我们采用 **两层 VAD 架构**：

- **Level 1（手机端）**：轻量级 VAD，仅过滤明显静音，降低带宽占用；
- **Level 2（节点端）**：使用 Silero VAD 或等效高精度模型，对重建后的音频进行真正的断句，以得到自然语流。

---

# 2. 架构概览

```
[ 手机端 APP ]
  ├─ 录音 (16kHz mono)
  ├─ 轻量级 VAD（只过滤静音）
  ├─ 按固定窗口打包音频块（非断句）
  └─ 通过 WebSocket 持续上传 audio_chunk
                     ↓
[ 调度服务器 Dispatcher ]
  ├─ 按 session 维度将 chunk 转发到节点
                     ↓
[ 节点服务 Node ]
  ├─ 拼接来自客户端的 chunks (保留顺序)
  ├─ 在拼接后的音频上运行 Silero VAD
  ├─ 输出自然句级 utterances
  ├─ ASR → NMT → TTS
                     ↓
[ 客户端收到最终翻译结果 ]
```

---

# 3. Level 1：手机端轻量级 VAD（过滤静音）

## 3.1 功能定位

**不负责断句，只负责降低带宽**：

- 去掉 *长时间全静音* 的部分
- 不做语义判断
- 不试图推断句子边界
- 不影响 ASR 的上下文可用性

手机端轻量 VAD = “静音屏蔽器（Silence Gate）”。

## 3.2 推荐参数（保守策略）

| 项目 | 值 | 说明 |
|------|------|------|
| 采样率 | 16 kHz | 统一到 ASR 输入频率 |
| 帧长度 | 20ms | 轻量处理的标准窗口 |
| 静音能量阈值 | 极低（如 -50 dB）| 只过滤绝对静音 |
| 静音连续判定 | ≥ 200–300ms | 不要切走任何可能含语音的段落 |
| 打包窗口 | 200–500ms | 每固定时间打包一次上传 |

**关键点：不以静音来“断句”**。

## 3.3 客户端 audio_chunk 上传格式

```json
{
  "type": "audio_chunk",
  "session_id": "sess-123",
  "sequence": 42,
  "timestamp_ms": 123400,
  "audio": "<base64-pcm16>",
  "dropped_silence_ms": 280
}
```

---

# 4. Level 2：节点端 Silero VAD（真实断句 + 上下文强化）

在节点端，为每个 session 维护：

- `audio_buffer`：顺序拼接后的音频
- `processed_until_ms`：已处理的时间戳
- `utterance_index`

## 4.1 拼接音频

节点收到音频块：

1. 根据 `sequence` 或 `timestamp_ms` 将其追加到缓冲；
2. 确保音频流在拼接后是连续的；
3. 去除冗余覆盖帧（如果客户端使用 overlap）。

## 4.2 Silero VAD 工作流程

```
while (audio_buffer 有新数据) {
    在最近 5–10 秒音频上运行 Silero VAD
    找到已结束的语音段 (start, end)
    取出音频片段
    作为 utterance 发送到 ASR
    更新 processed_until_ms
}
```

## 4.3 输出标准 utterance

```json
{
  "session_id": "sess-123",
  "utterance_index": 7,
  "start_ms": 12340,
  "end_ms": 15670,
  "audio": "<pcm16>",
  "src_lang": "zh",
  "tgt_lang": "en"
}
```

---

# 5. 为什么“两层 VAD”比“单层 VAD”更适合你的产品？

## 5.1 避免轻量 VAD 误切句
- 手机端只是滤掉最明显的静音，不决定句子边界；
- 用户语速不同 → 不再导致误断句。

## 5.2 显著提升 ASR 质量
- 节点端拥有完整语流 → 可以维持上下文；
- Silero 在节点端性能充足，断句更精准；
- ASR（Whisper）在自然停顿输入下准确率更高。

## 5.3 不增加手机端负担
- 手机不跑 Silero，不跑大模型；
- 整体体验更冷静、更省电。

## 5.4 节省带宽
- 手机端已去掉大段静音；
- 实际上传量比“裸语音流”减少 50–80%。

---

# 6. 两层 VAD 的数据流示意

```
[手机端]
录音 → 轻量VAD过滤 → audio_chunk →→→
                                      ↓
                                  [Dispatcher]
                                      ↓
                               [Node 节点服务]
audio_chunk → 拼接 → Silero VAD → utterance → ASR → NMT → TTS
                                      ↓
                                    返回结果
                                      ↓
                                 [手机端播放]
```

---

# 7. 注意事项与坑点规避

## 7.1 客户端 VAD 阈值必须 **非常保守**
否则音频被剪掉，服务器端无法恢复。

## 7.2 节点端必须实现 **顺序拼接**
- 根据 sequence 排序；
- 处理乱序包；
- 处理延迟和丢包。

## 7.3 Node 端 Silero VAD 必须有缓冲策略
避免重复处理音频，也避免漏掉边界。

## 7.4 Session 级音频不能无限增长
需要：
- 定期清理（例如只保留最近 20 秒音频）；
- processed_until_ms 后的部分即可丢弃。

---

# 8. 最终结论

你的产品需求可以完美使用“两层 VAD”架构：

- 手机端：轻量、安全、只负责过滤空气；
- 节点端：高精度 VAD + ASR 来保证识别质量和自然断句；
- 整体带宽显著减少；
- 用户体验更自然；
- 不需要用户声明语速；
- ASR 上下文得到保留和强化。

这是比“前端断句”更科学的设计，非常适合你的多节点 GPU 推理架构。

