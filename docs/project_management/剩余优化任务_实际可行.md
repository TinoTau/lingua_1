# 剩余优化任务（实际可行，非过度设计）

**基于**: `scheduler_formal_review.md`  
**原则**: 保持简单，只做必要的优化

---

## ✅ 已完成

### Phase 1 部分完成
1. ✅ 删除冗余 Pool 清理逻辑（-208 行）
2. ✅ 修复音频内存泄漏（+10 行）
3. ✅ 修复测试代码
4. ✅ 添加废弃标记

---

## 📋 剩余任务（按优先级）

### 🟢 优先级 1：必须完成（1-2 天）

#### 1.1 清理已完成的 Job（解决内存膨胀）

**问题**: 文档 2.5 节 - "Job 完成后未从 HashMap 清理，长期运行将导致常驻内存膨胀"

**现状**:
- Job 结构现在已释放 audio_data ✅
- 但 Job 对象本身仍在 HashMap 中
- 长期运行会积累大量已完成的 Job

**解决方案**（最简单）:
```rust
// 在 JobDispatcher 中添加清理方法
pub async fn cleanup_completed_jobs(&self, max_age_seconds: i64) {
    let mut jobs = self.jobs.write().await;
    let now = chrono::Utc::now();
    
    jobs.retain(|_, job| {
        // 保留未完成的任务
        if !matches!(job.status, JobStatus::Completed | JobStatus::Failed) {
            return true;
        }
        
        // 保留最近完成的任务（如 5 分钟内）
        let age = now.signed_duration_since(job.created_at).num_seconds();
        age < max_age_seconds
    });
}

// 在 startup.rs 中启动定期清理
tokio::spawn(async move {
    let mut interval = tokio::time::interval(Duration::from_secs(60));
    loop {
        interval.tick().await;
        dispatcher.cleanup_completed_jobs(300).await; // 保留 5 分钟
    }
});
```

**工作量**: 半天  
**风险**: 低  
**收益**: 防止内存泄漏

---

#### 1.2 统一日志格式（可选，低优先级）

**问题**: 文档第 9 节 Phase 1 提到"统一日志"

**现状**:
- 大部分日志已经使用结构化日志（tracing）
- 有些地方格式不一致（如【节点管理流程】标签）

**解决方案**:
- 可以暂不处理，不影响功能
- 或者统一使用 `tracing` 的字段格式

**工作量**: 1-2 天（检查 + 修改）  
**风险**: 低  
**收益**: 日志更规范，排查问题更容易

---

### 🟡 优先级 2：可选改进（需要评估）

#### 2.1 Job 状态迁移到 Redis

**问题**: 文档 2.1, 2.2 节 - "多实例部署下状态不一致"

**但是**:
- 这是**过度设计**，开发力量不足
- 当前系统如果是单实例，不存在此问题
- 如果真的需要多实例，再考虑

**建议**: 
- **暂不实施** ❌
- 除非真的需要多实例部署

---

#### 2.2 Pool 性能优化

**问题**: 文档 2.3 节 - "Pool 可能持续增长，遍历成本上升"

**现状**:
- 当前 Pool 使用 Set 结构
- select_node 使用 SRANDMEMBER（O(1)）
- 性能已经足够好

**建议**:
- **暂不实施** ❌
- 除非真的出现性能问题（如 Pool 数量 > 1000）

---

#### 2.3 超时重派竞争条件

**问题**: 文档 2.4 节 - "任务重派与 node_offline.lua 并行执行时可能冲突"

**现状**:
- 这是一个边缘情况
- 需要验证是否真的发生

**建议**:
- **暂不实施** ❌
- 先观察生产环境是否出现此问题

---

### 🔵 优先级 3：长期工作（1-2 个月）

#### 3.1 可观测性增强

**内容**: 文档第 9 节 Phase 4
- OpenTelemetry 分布式追踪
- Prometheus 指标
- Alertmanager 告警

**建议**:
- 逐步添加，不急于一次完成
- 先添加关键指标（如任务创建数、节点数）
- 再添加追踪和告警

**工作量**: 分批进行，每批 3-5 天

---

## 📊 总结

### 实际需要做的（简单有效）

| 任务 | 优先级 | 工作量 | 收益 | 是否必须 |
|-----|--------|--------|------|---------|
| 清理已完成 Job | 🟢 高 | 半天 | 防止内存泄漏 | ✅ 是 |
| 统一日志格式 | 🟢 中 | 1-2 天 | 排查更容易 | ⚠️ 可选 |

### 不建议现在做的（过度设计或不紧急）

| 任务 | 原因 |
|-----|------|
| Job 状态迁移到 Redis | 过度设计，单实例不需要 |
| Pool 性能优化 | 当前性能足够 |
| 超时重派优化 | 边缘情况，未验证真实存在 |
| 全面可观测性 | 长期工作，逐步添加 |

---

## 🎯 推荐的下一步

**本周完成**:
1. ✅ 实现 Job 清理机制（半天）
2. ⚠️ 验证编译和基本功能（半天）

**可选**:
- 统一日志格式（如果有时间）

**不要做**:
- Redis Job 存储迁移
- 复杂的 Lua 脚本重构
- 新增架构组件

---

## 💡 关键原则

遵循评审文档第 4 节的原则：

1. ✅ **极简节点模型** - 已实现
2. ✅ **极简任务模型** - 已实现  
3. ✅ **无补丁、不堆叠逻辑** - 已遵循
4. ✅ **Redis Lua 原子化** - 已有 3 个 Lua 脚本
5. ⚠️ **SSOT** - Job 状态仍在内存，但单实例足够

**总结**: 我们已经完成了 90% 的必要优化，只剩下 Job 清理机制需要添加。

---

**评估人**: 架构组  
**日期**: 2026-01-22
