# 音频处理流程说明

## 实际流程

### 1. Opus 解码位置

**Opus 解码在 `AudioAggregator` 中完成**（node agent 层面）：

```
JobAssignMessage (Opus base64)
    ↓
AudioAggregator.processAudioChunk()
    ↓
decodeAudioChunk() → decodeOpusToPcm16()
    ↓
返回 PCM16 Buffer
```

**代码位置**：
- `audio-aggregator.ts` 第 79 行：`decodeAudioChunk(job, ...)` 
- `audio-aggregator-decoder.ts` 第 30 行：`decodeOpusToPcm16(job.audio, sampleRate)`

**结论**：✅ Opus 解码确实在 node agent（AudioAggregator）中完成，不在 ASR 服务中。

---

### 2. 音频在 Pipeline 中的传递

#### 当前实现

**ASR 步骤**（`asr-step.ts`）：
```typescript
// 1. AudioAggregator 返回 PCM16 Buffer
const audioProcessResult = await audioProcessor.processAudio(job);
// audioProcessResult.audioForASR 是 base64 编码的 PCM16 字符串

// 2. 将 base64 字符串解码回 Buffer，存储到 JobContext
ctx.audio = Buffer.from(audioForASR, 'base64');  // PCM16 Buffer
ctx.audioFormat = 'pcm16';
```

**Embedding 步骤**（`embedding-step.ts`）：
```typescript
// 从 JobContext 获取 PCM16 Buffer
const audioF32 = convertPcm16ToF32(ctx.audio);  // 转换为 f32
```

**YourTTS 步骤**（`yourtts-step.ts`）：
```typescript
// 从 JobContext 获取 PCM16 Buffer
const audioF32 = convertPcm16ToF32(ctx.audio);  // 转换为 f32
// 直接作为 reference_audio 传递
```

---

## 我做的操作

### 操作1：在 ASR 步骤中存储 PCM16 音频到 JobContext

**位置**：`asr-step.ts` 第 59-62 行

```typescript
// 将解码后的 PCM16 音频存储到 JobContext（供后续步骤使用，如 Embedding）
// audioForASR 是 base64 编码的 PCM16 字符串
ctx.audio = Buffer.from(audioForASR, 'base64');
ctx.audioFormat = 'pcm16';
```

**原因**：
- `audioForASR` 是 base64 编码的字符串（`PipelineOrchestratorAudioProcessor` 转换的）
- 需要解码回 Buffer 格式，供后续步骤使用
- 存储到 `ctx.audio` 和 `ctx.audioFormat`，这样 Embedding 和 YourTTS 步骤可以直接使用

### 操作2：Embedding 步骤使用 JobContext 中的 PCM16 音频

**位置**：`embedding-step.ts`

```typescript
// ASR 步骤已经将 Opus 解码为 PCM16 并存储到 ctx.audio
// 验证音频格式（应该是 PCM16）
if (ctx.audioFormat !== 'pcm16') {
  return;
}

// 将 PCM16 转换为 f32 格式
const audioF32 = convertPcm16ToF32(ctx.audio);
```

### 操作3：YourTTS 步骤使用方案2（直接传递 reference_audio）

**位置**：`yourtts-step.ts`

```typescript
// 从 JobContext 获取 PCM16 Buffer（ASR 步骤已解码）
const audioF32 = convertPcm16ToF32(ctx.audio);

// 直接传递 reference_audio，不使用 speaker_id
const response = await axios.post(
  `${endpoint.baseUrl}/synthesize`,
  {
    text: textToTts,
    language: job.tgt_lang || 'zh',
    reference_audio: audioF32,  // 直接提供原始音频（f32 格式）
    reference_sample_rate: job.sample_rate || 16000,
  }
);
```

---

## 完整流程

```
1. JobAssignMessage (Opus base64)
   ↓
2. AudioAggregator.processAudioChunk()
   - decodeOpusToPcm16() → PCM16 Buffer
   ↓
3. PipelineOrchestratorAudioProcessor.processAudio()
   - 接收 PCM16 Buffer
   - 转换为 base64 字符串 → audioForASR
   ↓
4. ASR 步骤 (asr-step.ts)
   - 接收 audioForASR (base64 字符串)
   - 解码回 Buffer → ctx.audio (PCM16 Buffer)
   - ctx.audioFormat = 'pcm16'
   ↓
5. Embedding 步骤 (embedding-step.ts)
   - 从 ctx.audio 获取 PCM16 Buffer
   - 转换为 f32 → 调用 speaker-embedding 服务
   ↓
6. YourTTS 步骤 (yourtts-step.ts)
   - 从 ctx.audio 获取 PCM16 Buffer
   - 转换为 f32 → 作为 reference_audio 传递给 YourTTS 服务
```

---

## 总结

1. **Opus 解码位置**：✅ 在 `AudioAggregator`（node agent）中完成，不在 ASR 服务中

2. **JobContext 字段**：
   - ✅ `ctx.audio`：存储 PCM16 Buffer（ASR 步骤中设置）
   - ✅ `ctx.audioFormat`：存储 'pcm16'（ASR 步骤中设置）
   - ✅ 这两个字段在 `JobContext` 接口中已存在（第 10-11 行）

3. **音频传递**：
   - ✅ ASR 步骤：将解码后的 PCM16 存储到 `ctx.audio`
   - ✅ Embedding 步骤：从 `ctx.audio` 获取 PCM16，转换为 f32
   - ✅ YourTTS 步骤：从 `ctx.audio` 获取 PCM16，转换为 f32，作为 `reference_audio` 传递

**关键点**：音频在 Pipeline 中一路传递，从 ASR 步骤开始就是 PCM16 格式，后续步骤直接使用，不需要重复解码。
