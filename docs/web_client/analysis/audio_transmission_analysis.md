# 节点端音频传输过程分析

## 音频传输流程

### 1. 节点端生成TTS音频
- TTS服务生成WAV格式音频（PCM16，16kHz单声道）
- 20秒音频 ≈ 640KB（未压缩）

### 2. 节点端编码和压缩
- **如果支持Opus编码**：
  - 解析WAV文件，提取PCM16数据
  - 编码为Opus格式（压缩率约10:1）
  - 20秒音频压缩后 ≈ 64-128KB（取决于比特率，通常24-32kbps）
- **如果不支持Opus**：
  - 直接使用PCM16格式
  - 20秒音频 ≈ 640KB

### 3. Base64编码
- 将音频数据（Opus或PCM16）转换为base64字符串
- Base64编码会增加约33%的大小
- 20秒Opus音频（64KB）→ base64后 ≈ 85KB
- 20秒PCM16音频（640KB）→ base64后 ≈ 853KB

### 4. 传输到调度服务器
- **整个音频作为一个完整的base64字符串**，通过`job_result`消息一次性发送
- **没有切碎再组装的过程**
- 消息格式：
  ```json
  {
    "type": "job_result",
    "tts_audio": "base64_encoded_audio_data...",  // 完整的base64字符串
    "tts_format": "opus" 或 "pcm16"
  }
  ```

### 5. 调度服务器转发
- 调度服务器接收到`job_result`后，直接转发给web端
- **没有切碎，没有缓存，直接转发**

### 6. Web端接收和播放
- Web端接收到完整的base64字符串
- 解码base64，转换为Float32Array
- 添加到播放缓冲区

## 带宽开销分析

### 20秒音频的带宽开销

| 格式 | 原始大小 | Base64后 | 传输大小 |
|------|---------|---------|---------|
| PCM16 | 640KB | 853KB | 853KB |
| Opus (24kbps) | 60KB | 80KB | 80KB |
| Opus (32kbps) | 80KB | 107KB | 107KB |

### 对带宽的影响

1. **一次性传输**：
   - 20秒音频（Opus压缩后）≈ 80-107KB
   - 如果使用PCM16，则高达853KB
   - **没有流式传输，没有分片**

2. **网络延迟**：
   - 大音频块会导致：
     - WebSocket消息较大，可能触发分帧
     - 网络传输时间增加
     - 接收端需要等待完整消息才能开始解码

3. **内存占用**：
   - 节点端：需要完整加载音频到内存
   - 调度服务器：需要完整接收和转发
   - Web端：需要完整接收和解码

## 优化建议

### 1. 流式传输（推荐）
- 将长音频切分为多个chunk（例如每2秒一个chunk）
- 每个chunk单独编码和传输
- Web端边收边播，降低延迟

### 2. 压缩优化
- 确保使用Opus编码（压缩率约10:1）
- 根据网络条件调整比特率（24kbps vs 32kbps）

### 3. 分片传输
- 即使不流式传输，也可以将长音频切分为多个消息
- 每个消息包含一个音频片段
- Web端接收后组装

## 当前实现总结

✅ **优点**：
- 实现简单，逻辑清晰
- 音频完整性有保障（不会丢失片段）

❌ **缺点**：
- 长音频（20秒+）带宽开销大
- 一次性传输，延迟较高
- 内存占用较大

## 结论

**是的，20秒的音频是整个压缩后一次性发送的，没有切碎再组装的过程。**

**对带宽的影响**：
- 如果使用Opus编码（24-32kbps），20秒音频约80-107KB，影响相对较小
- 如果使用PCM16，20秒音频约853KB，影响较大
- 建议确保使用Opus编码以降低带宽开销

**建议**：
- 对于长音频（>10秒），考虑实现流式传输或分片传输
- 确保节点端使用Opus编码（当前实现已支持）
- 监控网络带宽使用情况，必要时调整比特率

