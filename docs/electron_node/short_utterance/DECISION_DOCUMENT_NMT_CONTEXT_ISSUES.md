# NMT 上下文功能问题分析及优化建议

## 文档目的

本文档旨在向决策部门汇报当前 NMT 上下文功能的实现情况、发现的问题，以及建议的优化方向。

---

## 一、背景和目标

### 1.1 原始需求

**问题**：ASR 识别准确率不高，导致翻译质量下降

**解决方案**：
1. **S1 (Prompt Bias)**：在 ASR 解码时注入关键词和最近上下文，提升识别准确率
2. **S2 (Rescoring)**：对短句/低质量文本生成候选并选择最优
3. **NMT 上下文功能**：启用 NMT 的上下文功能（`context_text`），通过提供上一句的 ASR 文本作为上下文，帮助 NMT 模型进行错误纠正，提高翻译准确率

**预期效果**：
- 提高 ASR 识别准确率（S1/S2）
- 提高翻译准确率（NMT 上下文）
- 改善用户体验

### 1.2 开发历程

**S1/S2 开发阶段**：
- 开发时间：2025-01-XX
- 状态：✅ S1 已实现，⚠️ S2 框架已实现但未启用
- 最终状态：**S1 和 S2 均被禁用**（通过 feature flag）

**NMT 上下文功能开发阶段**：
- 开发时间：2025-12-XX
- 状态：✅ 已实现，但效果不佳
- 当前状态：**需要决策是否保留**

---

## 二、S1/S2 开发过程中的问题总结

### 2.1 S1 (Prompt Bias) 的问题

#### 2.1.1 Prompt 污染问题（严重）

**问题描述**：
- S1 正在工作，但 Prompt 内容包含了大量**错误的识别结果**
- 这些错误结果被用作上下文，导致后续识别也被误导
- 形成**错误传播循环**：错误识别 → 错误上下文 → 更多错误识别

**实际案例**：
```
Prompt 内容：
[CONTEXT]
Recent:
那么能正常把云反归了          ← "云反归了" 应该是 "语音返回了"
这个我们可以单结不讨论        ← "单结不讨论" 应该是 "单独讨论"
但是在实际运动中用户说的关键词可能是要返回来的 投 一两句小时也就消失了
来 感觉都可以去看一下日治了完全没有语音产生可能还是 泡泡的问题  ← 多处错误
[/CONTEXT]
```

**根本原因**：
1. **质量门控不够严格**：`qualityScore >= 0.4` 仍然可能是低质量识别
2. **没有验证 recentCommittedText 的质量**：直接使用，没有验证其质量
3. **关键词提取可能包含错误**：从错误识别结果中提取的关键词也是错误的

**影响**：
- 识别准确率**下降**（而不是提升）
- 错误传播，导致后续识别更差
- 用户体验严重下降

**解决方案**：
- ✅ 已通过 feature flag 禁用 S1（`enableS1PromptBias: false`）
- ⚠️ 需要增强质量门控（提高阈值到 0.6+）才能重新启用

---

#### 2.1.2 识别准确率提升不明显

**用户反馈**：
- "识别不准确"：存在同音字替换问题（如"短句"识别为"短剧"）
- "作詞編曲編"识别错误
- "現在有反回了"应该是"返回了"

**实际效果**：
- S1 Prompt 虽然正常工作，但识别准确率提升不明显
- 甚至因为 Prompt 污染问题，识别准确率下降

**可能原因**：
1. Prompt 内容不够有效（关键词提取不够准确）
2. ASR 模型对 Prompt 的响应不够敏感
3. Prompt 污染导致错误传播

---

### 2.2 S2 (Rescoring) 的问题

#### 2.2.1 无法真正工作（核心问题）

**问题描述**：
- `CandidateProvider` 当前只返回 `primary` 候选，没有生成真正的候选（N-best 或二次解码）
- Rescoring 只能对同一个文本打分，无法替换为更好的候选
- 因此 rescoring 实际上**没有意义**，只是增加了延迟

**代码状态**：
```typescript
// candidate-provider.ts
async provide(ctx: CandidateProviderContext): Promise<CandidateProviderResult> {
  const candidates: Candidate[] = [];
  // 只添加primary作为候选
  candidates.push({
    text: ctx.primaryText,
    source: 'primary',
  });
  // TODO: N-best和二次解码未实现
  return { candidates, source: 'none' };
}
```

**根本原因**：
1. **Faster-Whisper 不支持 N-best**：已验证，无法获取多个候选
2. **二次解码已禁用**：GPU 占用过高（约 2.5 倍），导致"没有可用节点"的错误

**影响**：
- S2 框架已实现，但**无法真正工作**
- 增加了不必要的性能开销（检查、日志等）
- 用户期望的功能无法实现

**解决方案**：
- ✅ 已通过 feature flag 禁用 S2（`enableS2Rescoring: false`）
- ⚠️ 需要找到替代方案（如更换 ASR 模型支持 N-best，或优化二次解码的 GPU 占用）

---

#### 2.2.2 GPU 过载问题（严重）

**问题描述**：
- 实现 S1/S2 后，出现"没有可用节点"的错误
- 重启节点端后，仍然没有找到可用节点
- 问题出现在 S2 二次解码功能

**根本原因**：
- **二次解码 GPU 占用过高**：约 2.5 倍于正常 ASR 调用
- 第一次任务时触发 S2 Rescoring，导致额外 ASR 调用
- 如果服务还在启动中，可能导致"没有可用节点"

**配置**：
- `beamSize`: 15（比 primary 的 10 更大）
- `patience`: 2.0（比 primary 的 1.0 更高）
- `temperature`: 0.0（更确定）
- `bestOf`: 5

**影响**：
- 系统无法正常工作
- 用户体验严重下降
- 需要禁用二次解码功能

**解决方案**：
- ✅ 已禁用二次解码功能
- ✅ 已通过 feature flag 禁用 S2

---

#### 2.2.3 性能开销

**问题描述**：
- Rescoring 逻辑虽然被触发，但只处理 primary 候选，仍然有计算开销
- 每次 commit 都会检查是否需要 rescoring，即使没有真正的候选
- 日志记录可能增加开销

**影响**：
- 增加不必要的延迟
- 浪费系统资源

**解决方案**：
- ✅ 已禁用 S2，避免不必要的开销

---

### 2.3 其他问题

#### 2.3.1 重复返回问题

**问题描述**：
- 最后一句重复："这些漏掉的音频 但是不知道是什么的，可以看到最后一句还是重复的内容"
- 停止说话后，返回了两次结果

**可能原因**：
1. 重复检测逻辑不够严格（只检测完全相同的文本）
2. `lastSentText` 更新时机问题
3. `AggregatorState` 的 `lastCommittedText` 检测可能没有正确工作

**解决方案**：
- 已改进重复检测逻辑（使用更严格的文本比较）
- 在多个层级进行重复检测

---

#### 2.3.2 音频数量不一致

**问题描述**：
- 用户怀疑有音频被丢弃
- Web 端发出的和节点端返回的音频数量不一致

**可能原因**：
1. VAD 过滤：静音片段被过滤
2. 音频缓冲：某些音频块可能没有及时处理
3. ASR 服务过滤：低质量音频被 ASR 服务过滤

**解决方案**：
- 已添加音频追踪日志
- 已优化音频处理流程

---

### 2.4 S1/S2 最终状态

**当前状态**：
- ✅ **S1 Prompt Bias**: 默认禁用（`enableS1PromptBias: false`）
- ✅ **S2 Rescoring**: 默认禁用（`enableS2Rescoring: false`）
- ✅ **Aggregator**: 仍然启用（文本聚合功能不受影响）

**禁用原因**：
1. **S1**：Prompt 污染问题，导致识别准确率下降
2. **S2**：无法真正工作（缺少候选生成），GPU 过载问题

**代码保留**：
- 代码仍然保留，通过 feature flag 禁用
- 方便后续调试和修复
- 保留相关日志，方便分析问题

---

### 2.5 S1/S2 开发成本与收益

**开发成本**：
- **S1**：约 1000+ 行代码（PromptBuilder、集成等）
- **S2**：约 2000+ 行代码（NeedRescoreDetector、Rescorer、CandidateProvider、二次解码等）
- **总开发时间**：约 2-3 周
- **测试和调试时间**：约 1-2 周

**实际收益**：
- ❌ **S1**：识别准确率提升不明显，甚至下降（Prompt 污染）
- ❌ **S2**：无法真正工作（缺少候选生成）
- ❌ **用户体验**：严重下降（识别错误、GPU 过载、重复返回等）

**结论**：**收益 < 成本**，功能被禁用

---

## 三、当前实现（NMT 上下文功能）

### 2.1 技术实现

**实现方式**：
1. 在节点端聚合阶段，保存最近提交的 ASR 文本
2. 在翻译阶段，将上一句的 ASR 文本作为 `context_text` 传递给 NMT 服务
3. NMT 服务将 `context_text` 和当前 `text` 简单拼接：`"{context_text} {text}"`
4. M2M100 模型翻译整个拼接文本

**代码位置**：
- `electron_node/electron-node/main/src/aggregator/aggregator-manager.ts`: `getLastCommittedText()`
- `electron_node/electron-node/main/src/agent/postprocess/translation-stage.ts`: 获取并传递 `context_text`
- `electron_node/services/nmt_m2m100/nmt_service.py`: 拼接并翻译

### 2.2 已实现的修复

**问题 1：contextText 获取错误**
- **状态**：✅ 已修复
- **修复**：修改 `getLastCommittedText()` 方法，确保返回上一句而不是当前句

**问题 2：NMT 返回拼接文本的完整翻译**
- **状态**：✅ 已实现提取逻辑（需要测试验证）
- **修复**：在 NMT 服务中添加提取逻辑，从完整翻译中提取只当前句的翻译部分
- **方法**：单独翻译 `context_text`，然后从完整翻译中提取剩余部分

---

## 四、发现的问题（NMT 上下文功能）

### 3.1 翻译准确率提升不明显

**用户反馈**：
- "识别率不佳"
- "翻译准确率不高"

**实际效果**：
- ASR 识别准确率问题仍然存在（如 "瀵瑰対瀵?" 应该是 "对不起"）
- NMT 上下文功能对翻译准确率的提升不明显
- 翻译质量仍然不佳

**可能原因**：
1. ASR 识别错误本身导致上下文也是错误的，无法有效纠错
2. M2M100 模型的上下文纠错能力有限
3. 简单拼接的方式可能不是最佳的上下文利用方式

---

### 3.2 重复翻译问题

**问题描述**：
- NMT 服务返回的是 `"{context_text} {text}"` 的完整翻译
- 导致翻译结果包含上一句和当前句的翻译
- 用户看到重复的翻译内容

**示例**：
```
输入: context_text="你好", text="世界"
NMT 返回: "Hello World"  (包含两者的翻译)
期望: "World"  (只包含当前句的翻译)
```

**修复状态**：
- ✅ 已实现提取逻辑
- ⚠️ 需要测试验证

**影响**：
- 用户体验差
- 翻译结果不准确

---

### 3.3 性能开销

**问题描述**：
- 每次翻译都需要额外调用一次 NMT（用于翻译 `context_text` 以提取当前句翻译）
- 增加处理时间

**实际数据**：
- 当前处理时间：1.7-5.4 秒
- 用户反馈：翻译速度勉强可以接受
- 如果增加额外的 NMT 调用，处理时间可能增加 50-100%

**影响**：
- 用户体验下降
- 系统负载增加

---

### 3.4 实现复杂度

**问题描述**：
- 需要维护 `context_text` 的获取逻辑
- 需要实现提取逻辑（从完整翻译中提取只当前句的翻译）
- 需要处理各种边界情况（提取失败、长度估算不准确等）

**代码复杂度**：
- 增加了约 60 行代码（提取逻辑）
- 增加了错误处理逻辑
- 增加了测试和维护成本

---

## 五、性能影响分析

### 4.1 处理时间

**当前状态**（无额外 NMT 调用）：
- 平均处理时间：2-5 秒
- 用户反馈：勉强可以接受

**启用提取逻辑后**（需要额外 NMT 调用）：
- 预计处理时间：3-8 秒（增加 50-100%）
- 用户反馈：可能不可接受

### 4.2 系统负载

**当前状态**：
- 每次翻译：1 次 NMT 调用

**启用提取逻辑后**：
- 每次翻译：2 次 NMT 调用（1 次翻译拼接文本 + 1 次翻译 context_text）
- 系统负载：增加 100%

### 4.3 资源消耗

**GPU 显存**：
- 每次额外调用增加约 36-72MB 显存消耗（取决于 max_new_tokens）

**CPU/内存**：
- 每次额外调用增加约 100-200MB 内存消耗

---

## 六、根本问题分析

### 5.1 聚合功能的失败

**原始设计**：
- 聚合功能旨在合并短句，提高翻译质量
- 通过上下文功能提高翻译准确率

**实际效果**：
- 聚合功能本身工作正常（正确合并短句）
- 但上下文功能带来的问题超过了收益

**失败原因**：
1. **ASR 识别准确率是根本问题**：如果 ASR 识别错误，上下文也是错误的，无法有效纠错
2. **NMT 模型限制**：M2M100 是端到端模型，不支持真正的上下文参数，只能通过拼接实现
3. **实现复杂度**：需要额外的提取逻辑，增加了系统复杂度和性能开销
4. **收益不明显**：翻译准确率提升不明显，但带来了重复翻译和性能问题

---

### 5.2 核心矛盾

**矛盾点**：
- **目标**：提高翻译准确率（通过上下文纠错）
- **实际**：翻译准确率提升不明显，反而带来了重复翻译和性能问题
- **成本**：增加了实现复杂度、性能开销和维护成本

**结论**：
- **收益 < 成本**：上下文功能的收益（翻译准确率提升）不明显，但成本（性能开销、实现复杂度）较高
- **根本问题未解决**：ASR 识别准确率问题仍然存在，上下文功能无法有效解决

---

## 七、建议的优化方向

### 6.1 方案 A：移除 NMT 上下文功能（推荐）

**方案描述**：
- 移除 `context_text` 参数
- 简化 NMT 调用逻辑
- 移除提取逻辑

**优点**：
- ✅ 解决重复翻译问题
- ✅ 减少性能开销（减少 50% NMT 调用）
- ✅ 简化实现和维护
- ✅ 提高处理速度

**缺点**：
- ❌ 失去上下文纠错能力（但实际效果不明显）
- ❌ 翻译准确率可能略有下降（但当前提升不明显）

**实施成本**：
- 低：只需要移除相关代码

**预期效果**：
- 处理时间：减少 50%
- 系统负载：减少 50%
- 用户体验：改善（无重复翻译，速度更快）

---

### 6.2 方案 B：优化 ASR 识别准确率（根本解决方案）

**方案描述**：
- 优化 ASR 模型配置
- 或者使用更好的 ASR 模型
- 或者添加后处理来纠正常见错误

**优点**：
- ✅ 解决根本问题（ASR 识别准确率）
- ✅ 提高翻译质量
- ✅ 不需要上下文功能也能获得好的翻译效果

**缺点**：
- ❌ 可能需要更换 ASR 模型（成本较高）
- ❌ 或者需要大量调优工作

**实施成本**：
- 中-高：需要评估和测试不同的 ASR 模型或配置

**预期效果**：
- ASR 识别准确率：显著提升
- 翻译质量：显著提升
- 用户体验：显著改善

---

### 6.3 方案 C：保留上下文功能但优化实现（折中方案）

**方案描述**：
- 保留 `context_text` 功能
- 优化提取逻辑（使用缓存、长度比例估算等）
- 或者使用更智能的上下文处理方式

**优点**：
- ✅ 保留上下文纠错能力
- ✅ 减少性能开销（通过缓存等优化）

**缺点**：
- ❌ 仍然存在重复翻译风险
- ❌ 实现复杂度仍然较高
- ❌ 收益不明显

**实施成本**：
- 中：需要实现缓存机制等优化

**预期效果**：
- 处理时间：减少 30-50%（通过缓存）
- 系统负载：减少 30-50%
- 用户体验：改善（但仍可能有重复翻译）

---

### 6.4 方案 D：使用支持上下文的 NMT 模型（长期方案）

**方案描述**：
- 更换为支持真正上下文参数的 NMT 模型
- 或者使用商业 API（如 Google Translate API、DeepL API 等）

**优点**：
- ✅ 支持真正的上下文功能
- ✅ 不需要提取逻辑
- ✅ 翻译质量可能更好

**缺点**：
- ❌ 需要更换模型或使用商业 API（成本较高）
- ❌ 可能需要重新训练或集成

**实施成本**：
- 高：需要评估和集成新的模型或 API

**预期效果**：
- 翻译质量：可能显著提升
- 用户体验：可能显著改善

---

## 八、推荐方案

### 7.1 短期方案（立即实施）：方案 A - 移除 NMT 上下文功能

**理由**：
1. **收益不明显**：上下文功能对翻译准确率的提升不明显
2. **问题较多**：重复翻译、性能开销、实现复杂度
3. **成本低**：只需要移除相关代码
4. **效果明显**：解决重复翻译问题，提高处理速度

**实施步骤**：
1. 移除 `context_text` 参数传递
2. 移除 NMT 服务中的提取逻辑
3. 简化代码
4. 测试验证

**预期效果**：
- ✅ 解决重复翻译问题
- ✅ 处理时间减少 50%
- ✅ 系统负载减少 50%
- ✅ 代码简化，维护成本降低

---

### 7.2 长期方案（根本解决）：方案 B - 优化 ASR 识别准确率

**理由**：
1. **解决根本问题**：ASR 识别准确率是翻译质量的根本
2. **收益最大**：提高 ASR 准确率可以显著提高翻译质量
3. **不需要上下文**：如果 ASR 准确率高，上下文功能可能不需要

**实施步骤**：
1. 评估当前 ASR 模型（Faster-Whisper）的配置
2. 测试不同的 ASR 模型或配置
3. 优化 ASR 模型参数
4. 或者考虑使用更好的 ASR 模型

**预期效果**：
- ✅ ASR 识别准确率显著提升
- ✅ 翻译质量显著提升
- ✅ 用户体验显著改善

---

## 九、风险评估

### 8.1 移除上下文功能的风险

**风险**：
- 翻译准确率可能略有下降（但当前提升不明显）

**缓解措施**：
- 如果 ASR 识别准确率高，上下文功能可能不需要
- 可以通过优化 ASR 模型来补偿

**评估**：
- **风险等级**：低
- **影响范围**：翻译准确率（但当前提升不明显）

---

### 8.2 保留上下文功能的风险

**风险**：
- 重复翻译问题可能仍然存在
- 性能开销可能影响用户体验
- 实现复杂度可能增加维护成本

**缓解措施**：
- 优化提取逻辑
- 添加缓存机制
- 但收益仍然不明显

**评估**：
- **风险等级**：中-高
- **影响范围**：用户体验、系统性能、维护成本

---

## 十、成本效益分析

### 9.1 当前状态（启用上下文功能）

**成本**：
- 实现复杂度：高（需要提取逻辑、错误处理等）
- 性能开销：高（需要额外 NMT 调用）
- 维护成本：高（需要处理各种边界情况）

**收益**：
- 翻译准确率提升：不明显
- 用户体验：差（重复翻译、速度慢）

**结论**：**收益 < 成本**

---

### 9.2 移除上下文功能后

**成本**：
- 实现复杂度：低（代码简化）
- 性能开销：低（减少 50% NMT 调用）
- 维护成本：低（代码简单）

**收益**：
- 翻译准确率：可能略有下降（但当前提升不明显）
- 用户体验：改善（无重复翻译、速度更快）

**结论**：**收益 > 成本**

---

### 9.3 优化 ASR 识别准确率后

**成本**：
- 实现复杂度：中-高（需要评估和测试）
- 性能开销：低（不需要额外调用）
- 维护成本：中（需要持续优化）

**收益**：
- 翻译准确率：显著提升
- 用户体验：显著改善

**结论**：**收益 >> 成本**

---

## 十一、决策建议

### 10.1 立即行动（短期）

**建议**：**移除 NMT 上下文功能**

**理由**：
1. 当前收益不明显，但成本较高
2. 可以立即解决重复翻译和性能问题
3. 实施成本低，风险小

**预期效果**：
- ✅ 解决重复翻译问题
- ✅ 提高处理速度（减少 50%）
- ✅ 简化代码和维护

---

### 10.2 长期规划（根本解决）

**建议**：**优化 ASR 识别准确率**

**理由**：
1. 解决根本问题（ASR 识别准确率）
2. 收益最大（显著提高翻译质量）
3. 不需要上下文功能也能获得好的效果

**预期效果**：
- ✅ ASR 识别准确率显著提升
- ✅ 翻译质量显著提升
- ✅ 用户体验显著改善

---

### 10.3 可选方案（如果必须保留上下文功能）

**建议**：**优化实现（方案 C）**

**理由**：
1. 如果决策部门认为上下文功能必须保留
2. 可以通过缓存等优化减少性能开销
3. 但仍需要处理重复翻译问题

**预期效果**：
- ⚠️ 性能开销减少 30-50%
- ⚠️ 但仍可能有重复翻译问题
- ⚠️ 实现复杂度仍然较高

---

## 十二、总结

### 11.1 当前状态

- ✅ **contextText 获取**：已修复（正确获取上一句）
- ✅ **提取逻辑**：已实现（从完整翻译中提取只当前句的翻译）
- ❌ **翻译准确率提升**：不明显
- ❌ **重复翻译问题**：仍然存在（需要测试验证提取逻辑）
- ❌ **性能开销**：较高（需要额外 NMT 调用）
- ❌ **ASR 识别准确率**：不佳（根本问题）

### 12.2 核心问题

**根本问题**：ASR 识别准确率不高

**尝试的解决方案**：
1. **S1/S2**：通过 Prompt Bias 和 Rescoring 提升 ASR 识别准确率
   - **结果**：失败（S1 Prompt 污染，S2 无法工作）
   - **状态**：已禁用
2. **NMT 上下文功能**：通过上下文纠错提高翻译准确率
   - **结果**：效果不佳（翻译准确率提升不明显，带来重复翻译和性能问题）
   - **状态**：需要决策是否保留

**实际效果**：
- S1/S2：识别准确率提升不明显，甚至下降（Prompt 污染）
- NMT 上下文：翻译准确率提升不明显，带来重复翻译和性能问题
- **总体结论**：收益 < 成本

### 12.3 建议

**短期**：
1. **移除 NMT 上下文功能**
   - 解决重复翻译问题
   - 提高处理速度
   - 简化代码和维护

2. **保持 S1/S2 禁用状态**
   - S1：Prompt 污染问题未解决
   - S2：无法真正工作（缺少候选生成）

**长期**：优化 ASR 识别准确率（根本解决方案）
- 解决根本问题（ASR 识别准确率）
- 显著提高翻译质量
- 不需要 S1/S2 或 NMT 上下文功能也能获得好的效果
- **建议方向**：
  - 评估当前 ASR 模型（Faster-Whisper）的配置
  - 测试不同的 ASR 模型或配置
  - 优化 ASR 模型参数
  - 或者考虑使用更好的 ASR 模型

---

## 十三、附录

### 13.1 相关文档

**NMT 上下文功能相关**：
- `electron_node/docs/short_utterance/LATEST_INTEGRATION_TEST_ANALYSIS.md`: 最新集成测试分析
- `electron_node/docs/short_utterance/NMT_CONTEXT_OUTPUT_EXPLANATION.md`: NMT 上下文输出行为说明
- `electron_node/docs/short_utterance/MAX_NEW_TOKENS_EXPLANATION.md`: max_new_tokens 参数说明

**S1/S2 开发相关**：
- `electron_node/docs/short_utterance/S1_S2_DEVELOPMENT_SUMMARY.md`: S1/S2 开发内容总结
- `electron_node/docs/short_utterance/S1_S2_ISSUE_ANALYSIS.md`: S1/S2 问题分析与优化方案
- `electron_node/docs/short_utterance/S1_S2_TESTING_ISSUES_ANALYSIS.md`: S1/S2 测试问题分析
- `electron_node/docs/short_utterance/S1_S2_GPU_OVERLOAD_ANALYSIS.md`: S1/S2 导致的 GPU 过载问题分析
- `electron_node/docs/short_utterance/S1_S2_DISABLE_ROLLBACK.md`: S1/S2 禁用回退说明
- `electron_node/docs/short_utterance/S1_PROMPT_CONTAMINATION_ANALYSIS.md`: S1 Prompt 污染问题分析

### 12.2 代码位置

- `electron_node/electron-node/main/src/aggregator/aggregator-manager.ts`: contextText 获取逻辑
- `electron_node/electron-node/main/src/agent/postprocess/translation-stage.ts`: contextText 传递逻辑
- `electron_node/services/nmt_m2m100/nmt_service.py`: NMT 服务实现和提取逻辑

### 12.3 测试数据

- 测试时间：2025-12-29 22:19-22:20
- 处理时间：1.7-5.4 秒
- 用户反馈：翻译速度勉强可以接受，仍然有重复，识别率不佳

---

## 十四、决策要点

### 14.1 关键问题

1. **NMT 上下文功能是否值得保留？**
   - 当前收益不明显
   - 成本较高（性能开销、实现复杂度）
   - 建议：移除

2. **S1/S2 是否应该重新启用？**
   - S1：Prompt 污染问题未解决，需要增强质量门控
   - S2：无法真正工作（缺少候选生成），GPU 过载问题
   - 建议：保持禁用状态，除非找到根本解决方案

3. **如何提高翻译准确率？**
   - 根本问题：ASR 识别准确率不高
   - 已尝试方案：S1/S2（失败）、NMT 上下文（效果不佳）
   - 建议：优化 ASR 模型或配置（根本解决方案）

4. **如何处理重复翻译问题？**
   - 已实现提取逻辑，但需要测试验证
   - 或者移除上下文功能，从根本上解决

### 14.2 决策建议

**推荐方案**：
1. **短期**：
   - 移除 NMT 上下文功能
   - 保持 S1/S2 禁用状态
2. **长期**：优化 ASR 识别准确率（根本解决方案）

**理由**：
- **S1/S2**：已尝试，但失败（S1 Prompt 污染，S2 无法工作），收益 < 成本
- **NMT 上下文**：当前收益不明显，但成本较高，收益 < 成本
- **根本问题**：ASR 识别准确率不高，应该从源头解决
- **移除上下文功能**：可以立即解决重复翻译和性能问题
- **优化 ASR**：解决根本问题，显著提高翻译质量，不需要额外的纠错机制

---

**文档创建时间**：2025-12-29  
**文档版本**：1.0  
**文档状态**：待决策

