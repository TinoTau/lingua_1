# 长句前半句丢失 — Turn 亲和写入时机修复（2026-01）

**现象**：语音识别稳定性测试中，同一段长句被切分为多 job（如 job 5、7、8）时，返回结果中这些 job 的 ASR 文本**丢失前半句**，仅剩后半句（如「那两个不同的任务甚至出现…」「这次的长距能够被完整的识别出来…」「当时规则时基本可用的。」）。

**结论**：根因在**调度端**：同一 turn 内 affinity 写入时机错误，导致同一 turn 的第 2、3… 个 job 被派发到**不同节点**，每个节点只收到本 job 的音频片段，节点端聚合按 `bufferKey=job_id` 隔离，无法跨 job 合并，因此出现「前半句在 A 节点、后半句在 B 节点」的语义不完整。

---

## 一、根因（调度端）

### 1.1 Turn 亲和设计

- 同一 **turn**（同一段连续发言，可能被 MaxDuration 切分为多个 job）内的 job 应**路由到同一节点**，以便节点端在同一 buffer 上做音频聚合与 ASR。
- 调度端通过 Redis `scheduler:turn:{turn_id}` 的 `affinity_node_id` 记录「本 turn 已选节点」；`select_node.lua` 在选节点时若传入 `turn_id` 且存在 `affinity_node_id`，则优先选该节点。

### 1.2 Bug：写入时机过晚

- **原逻辑**：在 `actor_finalize.rs` 中，**全部** job 由 `create_translation_jobs` 创建并返回后，才根据 `jobs.first()` 写入 `affinity_node_id`。
- **问题**：`create_translation_jobs` 内部对**每个** job 都会调用 `create_job_with_minimal_scheduler` → `pool_service.select_node(..., turn_id)`。此时 Redis 中**尚无** `scheduler:turn:{turn_id}` 的 `affinity_node_id`（因为还没写），因此：
  - 第 1 个 job：`select_node(turn_id)` 无亲和，随机选节点 A；
  - 第 2、3… 个 job：`select_node(turn_id)` 仍无亲和，可能选到节点 B、C…
- **结果**：同一 turn 的多个 job 被派到不同节点，每个节点只处理本 job 的那一段音频，节点端无法合并，用户看到「job 5/7/8 只有后半句」。

---

## 二、修复（调度端）

- **位置**：`central_server/scheduler/src/websocket/job_creator.rs`
- **改动**：
  1. 新增 `write_turn_affinity_after_first_job(state, turn_id, session_id, node_id)`：向 Redis 写入 `scheduler:turn:{turn_id}` 的 `affinity_node_id` 与 `scheduler:session:{session_id}` 的 `current_turn_id`。
  2. 在 **room 模式** 下，`create_translation_jobs` 的循环中，**第一个 job 创建并 push 后、继续创建下一个 job 前**，若为 MaxDuration 且该 job 已分配节点，则调用 `write_turn_affinity_after_first_job`。
- **效果**：同 turn 内第 2、3… 个 job 在调用 `select_node(turn_id)` 时，Redis 中已有 `affinity_node_id`，会命中同一节点，长句多 job 落在同一节点，节点端聚合正常，前半句不再丢失。

---

## 三、节点端日志检查（如何确认每个 job 在各服务的处理）

若需从节点端日志确认「每个 job 在各服务里的处理过程、输入输出」，可重点查：

1. **调度派发**  
   - 调度端日志：`【派发】准备发送 JobAssign 到节点` / `【派发】JobAssign 发送成功`，含 `job_id`、`node_id`、`utterance_index`。  
   - 确认同一 utterance_index 下多个 job 是否都派到同一 `node_id`（修复前会分散到不同 node_id）。

2. **节点接收 job**  
   - 节点端：收到 `job_assign` 后的处理入口（如 `node-agent-simple` / job-processor），一般会打 `job_id`、`session_id`。  
   - 可搜 `job_id` 或 `job.job_id` 定位该 job 的完整处理链。

3. **AudioAggregator（bufferKey=job_id）**  
   - 日志关键字：`AudioAggregator`、`bufferKey`、`job_id`、`MaxDuration`、`pendingMaxDurationAudio`。  
   - 可确认每个 job 的音频是否按 `job_id` 进入对应 buffer、是否有合并/切分（如「Processing MaxDuration finalize」「Caching to pendingTimeoutAudio」）。

4. **ASR 输入/输出**  
   - 送 ASR 前：通常会有「送 ASR」或 task-router 调用 ASR 的日志，可看到本段音频长度或 base64 长度。  
   - ASR 返回：原始 ASR 结果、partial/final 等，一般会带 `job_id` 或 `originalJobId`。  
   - 若某 job 只收到「后半段」音频，则 ASR 输出会只有后半句，与现象一致。

5. **NMT/后续阶段**  
   - 按 `job_id` 或 `originalJobId` 追踪该 job 的译文与后续步骤。

**建议**：对出问题的 utterance（如导致 job 5、7、8 前半句丢失的那段长句），在调度端按 `session_id` + `utterance_index` 过滤，确认该次 finalize 创建的所有 job 的 `job_id` 与派发到的 `node_id`；在节点端按这些 `job_id` 过滤，看每个 job 的聚合与 ASR 输入是否仅为一段（后半段），即可验证「多 job 被派到多节点」的根因。

---

## 四、针对「句尾/句间/句首」丢失的日志检查清单（按 job 追踪）

以下针对**单次测试**中出现的多类丢失（job1 句尾、job6–8 间整句、job11 缺「如果」、job11–12 间、job14 缺「否则」），按节点端各环节给出**可搜索关键字**与**建议核对项**。未改节点逻辑，仅做排查指引。

### 4.1 各环节日志关键字（节点端）

| 环节 | 建议搜索关键字 | 日志中关键字段 | 用途 |
|------|----------------|----------------|------|
| 接收 job | `Processing job: received audio data` | jobId, sessionId, utteranceIndex, audioLength | 确认该 job 收到的音频长度 |
| BufferKey | `[BufferKey] Processing audio chunk` | jobId, bufferKey, utteranceIndex, isManualCut, isTimeoutTriggered, isMaxDurationTriggered | 确认每个 job 对应哪个 buffer、触发类型 |
| 新建 buffer | `Creating new buffer` | jobId, bufferKey, utteranceIndex | 确认是否新开 buffer（新句子/新 job） |
| 送 ASR 前 | `Audio processed with streaming split, proceeding to ASR` | jobId, segmentCount, segmentLengths, originalJobIds | **关键**：本 job 送了几段、每段长度、归属哪些 originalJobId |
| MaxDuration 处理 | `Processing MaxDuration finalize` / `Recorded MaxDuration` | jobId, sessionId, audioDurationMs, outputSegmentCount | 长句切分是否按预期 |
| Timeout 缓存 | `Caching to pendingTimeoutAudio` | jobId, sessionId | 超时 finalize 是否把尾段缓存到 pending |
| 手动/Timeout 合并 | `AudioAggregator: Finalize` 等 | jobId, audioToProcess 相关 | 合并后送 ASR 的整段长度 |
| OriginalJob 分发 | `OriginalJobResultDispatcher` / `registerOriginalJob` / `dispatchSegment` | originalJobId, expectedSegmentCount, receivedCount, asrText | 每个 originalJob 收到几段 ASR、合并后的 asrText |
| ASR 完成 | `ASR completed`（若存在） | jobId | 释放 ASR 容量 |

说明：`segmentLengths` 为各段 PCM 字节数，除以 `(16000*2)` 可得约等于秒数，用于核对「某句尾/句首」是否在本 job 的输入里。

### 4.2 按你描述的丢失现象该查什么

- **Job 1 丢失句尾**  
  - 搜该 job 的 `job_id`（或 utterance_index=1），看 `proceeding to ASR` 的 `segmentCount`、`segmentLengths`。  
  - 若本 job 只送了前半段（例如只送了一段且长度偏短），则「句尾」可能在**下一段**才被送进下一个 job；再搜 utterance_index=2 或相邻 job 的 `received audio data` 和 `proceeding to ASR`，看是否包含那句尾的音频。  
  - 若本 job 送的总时长已覆盖整句，但 ASR 结果仍缺句尾，则可能是 ASR 漏识别或 NMT/后续截断，需再对 ASR 输出做比对。

- **Job 6–8 之间丢失一整句**  
  - 先确认 utterance_index 6、7、8 对应的三个 job 的 `job_id` 与调度端派发的 `node_id`（是否同一节点）。  
  - 分别搜这三个 job_id 的 `proceeding to ASR`、`segmentLengths` 和 dispatcher 的 `expectedSegmentCount`/`receivedCount`，看 6 与 7、7 与 8 之间**音频边界**是否把「那一句」整句划进某一个 job，还是被切到两段中间（前半在 job6 尾、后半在 job7 头，或类似）。  
  - 若某句完全不在任一段 segmentLengths 覆盖范围内，则可能是调度端 finalize 切点导致该句未被包含在任何一次送 ASR 的音频中，需结合调度端该段时间的 finalize 原因（max_duration/timeout/manual）看。

- **Job 11 丢失开头的「如果」**  
  - 搜 job11 的 `received audio data`（audioLength）和 `proceeding to ASR`（segmentCount、segmentLengths）。  
  - 若第一段音频起始处就不包含「如果」（例如第一段从「这次的长句…」开始），则「如果」可能被划到**上一个 job**（job10）的尾段；搜 job10 的 ASR 输出或 dispatcher 的 asrText，看是否含「如果」。  
  - 若 job10 也没有，则可能是调度端在该处做了 finalize，把「如果」和后面拆成两段，其中一段未送 ASR 或未落在当前看到的 job 上，需结合调度端 finalize 序列看。

- **Job 11–12 之间丢失一部分内容**  
  - 与 6–8 类似：看 job11 的最后一端 segment 的结束位置，和 job12 的第一段 segment 的起始位置，在时间/文本上是否衔接。  
  - 在 dispatcher 里看 job11 的 `expectedSegmentCount`/`receivedCount` 和最终合并的 asrText，以及 job12 的 asrText，确认缺失内容是否落在「两 job 边界」的某一段（被切到对侧或未送 ASR）。

- **Job 14 丢失「否则」**  
  - 搜 job14 的 `received audio data`、`proceeding to ASR` 的 segment 信息。  
  - 若首段音频就不含「否则」，则「否则」可能在 job13 的尾段；查 job13 的 ASR/合并结果是否含「否则」。  
  - 若两处都没有，同样需看调度端在该时刻的 finalize 与派发，确认「否则」所在的那小段是否被单独成 job 或未送 ASR。

### 4.3 输入/输出含义小结

- **输入**（每个 job 在各服务）：  
  - 对 **AudioAggregator**：`job` 的 `audio`（base64）+ `is_manual_cut` / `is_timeout_triggered` / `is_max_duration_triggered`；解码后为 `currentAudio` + 已有 buffer 内容。  
  - 对 **ASR**：Aggregator 输出的 `audioSegments`（多段 base64 PCM），对应日志里的 `segmentCount`、`segmentLengths`。  

- **输出**（每个 job）：  
  - **Aggregator**：`audioSegments`、`originalJobIds`（每段归属的 job）。  
  - **ASR**：每段的识别文本，由 **OriginalJobResultDispatcher** 按 `originalJobId` 归并后得到该 job 的最终 asrText；若某段缺失或归并到别的 job，就会出现「句尾/句首/句间」丢失。

按上述关键字和顺序在节点端日志里按 job_id/utterance_index 过滤，即可逐 job 核对「输入是什么、输出是什么」，并判断丢失发生在切分边界、归并归属还是 ASR 本身。

---

## 五、如何配合检查（本地执行）

**说明**：当前环境无法直接读取你本机上的集成测试运行日志，需要你在本机跑完集成测试后自行抓取日志并（可选）把结果贴出，便于进一步分析。

### 5.0 日志未生成 / 找不到时

- **日志生成路径**：由 `findProjectRoot(__dirname)` 决定，固定为 **「electron-node 项目根」下的 `logs/electron-main.log`**。  
  - 项目根 = 含 `package.json` 且含 `main` 目录的那一层，即 `electron_node/electron-node/`。  
  - 因此默认路径为：**`electron_node/electron-node/logs/electron-main.log`**。  
  - 脚本（如 `analyze-job-logs.js`）默认读取的也是该路径下的 `logs/electron-main.log`。

- **启动时必看**：主进程启动后控制台会打印：  
  `[Logger] Log file path: ...`、`[Logger] Log directory: ...`、`[Logger] Project root (log base): ...`  
  **以控制台里打印的路径为准**；若找不到文件，先对照这三行确认实际写入目录。

- **若之前「日志没生成」**：旧版 `main/logger.js` 曾用 `process.cwd()` 作为日志根目录，日志会写在「启动进程时的当前工作目录」下的 `logs/`。若从仓库根或其他目录启动应用，日志会出现在该目录的 `logs/` 下，而不是 `electron-node/logs/`。现已与 `main/src/logger.ts` 统一为 `findProjectRoot(__dirname)`，日志始终在 **electron-node 项目根/logs/**；重新构建并启动后，按上面控制台输出即可找到文件。

- **建议**：在 **`electron_node/electron-node`** 目录下执行 `npm run start`（或你的启动命令），这样项目根确定，日志一定在 `electron_node/electron-node/logs/electron-main.log`；若该目录不存在，启动时 logger 会自动创建 `logs` 目录。

- **路径唯一性与防丢失确认**：  
  - **唯一路径**：主进程日志仅写入上述一个路径（`projectRoot/logs/electron-main.log` 或测试时 `electron-main.test.log`），无第二处写入，不会出现「日志分散到两个文件」的冗余。  
  - **无重复逻辑导致分裂**：`main/src/logger.ts` 与 `main/logger.js` 使用相同的 `findProjectRoot(__dirname)` 与同一 `logFile`；脚本统一用 `../logs/electron-main.log`（相对 electron-node 项目根），与 logger 写入路径一致。  
  - **防丢失**：logger 初始化前会 `mkdirSync(logDir, { recursive: true })`；pino 使用文件追加写入；若 pino 初始化失败，会回退到仅控制台输出，进程不崩溃，控制台仍可排查。

1. **节点端日志路径**（运行节点应用时，非 jest）  
   - 默认：`electron_node/electron-node/logs/electron-main.log`  
   - 以启动时控制台打印的 `[Logger] Log file path: ...` 为准。

2. **用现有脚本按 job 汇总**（推荐）  
   在 `electron_node/electron-node` 下执行：  
   ```bash
   node scripts/analyze-job-logs.js logs/electron-main.log [session-id] [job-pattern]
   ```  
   - 不填 `session-id` 则不过滤 session；`job-pattern` 默认为 `"job"`，可改为某次测试的 job 前缀或完整 job_id。  
   - 脚本会解析 JSON 日志、按时间排序，并列出与 job 相关的条目，便于看每个 job 在各阶段的输入/输出。

3. **或手动 grep**  
   在节点日志所在目录执行（PowerShell）：  
   ```powershell
   Select-String -Path "logs\electron-main.log" -Pattern "Processing job|BufferKey|proceeding to ASR|segmentCount|segmentLengths|originalJobIds|OriginalJobResultDispatcher" | Select-Object -First 200
   ```  
   再按 `job_id`/`utterance_index` 在结果里逐条对照第四节的关键字与含义。

4. **把结果发给我**  
   运行脚本后的控制台输出，或手动 grep 的结果中与「出问题的 utterance_index / job_id」（如 1、6、8、11、12、14）相关的片段，复制贴到对话里，我可以根据内容帮你判断原因（切分边界、归并归属或 ASR 等）。

---

## 六、相关文档

- 节点端 Job 日志分析脚本：`electron_node/electron-node/scripts/analyze-job-logs.js`
- 调度端 Turn 亲和设计：`central_server/scheduler/docs/调度服务器_turn内job亲和_最小patch与tasklist.md`
- 决策审议：`docs/decision/Session_Affinity与turnId_设计方案_决策审议_2026_01.md`
- 节点端 bufferKey：`electron_node/docs/节点端_buffer_key_改造_可行性确认与待确认项.md`
