# 同音/近音后处理：无词表约束与可行方案 — 决策审议

## 1. 约束（产品与部署）

- **节点由用户自行下载部署**，调度服务器**随机分配任务**，同一节点会处理来自不同会话、不同用户的任务。
- 因此：**节点上的词表无法覆盖所有任务**；在节点侧积累「常用词」「错误→正确映射」等词表**没有意义**，且增加维护成本。
- **决策**：节点端**不采用任何词表设计**（包括常用词表、错误→正确短语表、可学习词表等）。

## 2. 同音/近音后处理在无词表下的局限

- **目标**：在 ASR 输出上做「同音/近音」纠错，只允许同音字替换，避免跨音误改（如 余英→英文）。
- **必要环节**：  
  - 用「同音字组」（由拼音数据自动得到，非词表）约束**可替换候选**；  
  - 在多个同音候选（如 余/语/鱼）中**选出一个**，必须依赖某种**偏好或打分**。
- **无词表时的后果**：  
  - 若**不用词表**，且**不用其他打分手段**（如语言模型），则无法在 余/语/鱼 中选 语；  
  - 多候选时只能**保留原字**，即**不进行替换**，同音/近音后处理**无法产生实际纠错效果**。

## 3. 当前实现状态

- **已实现**：  
  - Pipeline 中已增加 **PHONETIC_CORRECTION** 步骤（位于 AGGREGATION 与 SEMANTIC_REPAIR 之间）；  
  - 模块内保留**同音字组**（SAME_PINYIN_GROUPS），由拼音自动得到 字→[同音字]，**无词表**；  
  - 在满足「无词表」约束下，多候选时**一律保留原字**，故 **correct(text) 当前恒返回原文**，本步不修改文本。
- **效果**：  
  - 当前该步骤**不产生实际纠错**，仅保留流水线占位与同音字组数据结构，便于日后接入**非词表打分**（如 LM 文件）时复用。

## 4. 可选方向（供决策部门审议）

| 选项 | 内容 | 说明 |
|------|------|------|
| **A. 维持现状** | 保留 PHONETIC_CORRECTION 步骤与同音字组，不做替换，满足「无词表」约束。 | 无纠错效果，仅占位；后续若引入 LM 等非词表打分，可在此扩展。 |
| **B. 移除步骤** | 从 Pipeline 中移除 PHONETIC_CORRECTION，不再保留同音/近音后处理占位。 | 代码更简；若将来要做同音纠错，需重新加步骤与数据结构。 |
| **C. 引入非词表打分** | 在满足「无词表」前提下，引入**一次性数据/模型**（如 n-gram 语言模型文件、小规模神经 LM）对候选句打分，在同音字组内选最优。 | 可产生实际纠错效果；需选型、数据/模型来源与部署方式（随节点分发或单独下载），由决策部门拍板。 |

## 5. 语义修复模型与能力（与同音打分选型的关联）

### 5.1 当前语义修复模型

- **模型**：**Qwen2.5-3B-Instruct**（GGUF 量化），通过 llama-cpp-python 加载。
- **路径**：服务在 `models/qwen2.5-3b-instruct-zh-gguf/` 下查找，优先 `qwen2.5-3b-instruct-q4_k_m.gguf`，其次 `q4_0`、`q4_k_s`。
- **用途**：仅用于**语义修复**（ASR 文本同音字/错别字/繁简等），与同音/近音后处理步骤（PHONETIC_CORRECTION）分离。

### 5.2 语义修复服务当前能力

- **API 返回**：`decision`、`text_out`、`confidence`、`diff`、`reason_codes`、`repair_time_ms`。
- **confidence**：在引擎内**写死为 0.85**，非模型输出，也非 logprob/loss。
- **结论**：语义修复服务属于**第三种**——**只能返回文本，没有任何真实分数**（无 logprob/loss/score；confidence 为占位值）。

因此，若要在同音候选间做**非词表**的选优，**不能**依赖语义修复模型输出分数，只能：
- **任选其一**：引入**轻量打分器**（如字符级 n-gram LM，仍非词表），对同音候选句打分；或
- 通过改 prompt 让模型输出「自评分 + 解释」（属第二种「可用」），需改语义修复 prompt 与解析逻辑，并由决策部门确认是否采用。

### 5.3 三种能力对照（供审议）

| 能力 | 说明 | 当前是否具备 |
|------|------|--------------|
| **能返回 logprob / loss / score（最佳）** | 模型或引擎返回生成序列的 logprob/loss/score，可直接用于候选排序。 | **否**：llama-cpp-python 的 create_chat_completion 未请求且存在 logprobs 支持问题；当前未暴露任何真实分数。 |
| **不能返回 logprob，但可按 prompt 输出「自评分 + 解释」（可用）** | 通过 prompt 要求模型输出自评分与简短解释，解析后用于排序。 | **否**：当前 prompt 要求「只输出修正后文本，不要解释」，未要求自评分；若采用需改 prompt 与解析。 |
| **只能返回文本，没有任何分数** | 仅能拿到修正后文本；若要做同音候选选优，必须另加轻量打分器（如字符级 n-gram LM，仍非词表）。 | **是**：当前语义修复属此类。 |

---

## 6. 小结

- **约束**：节点端不采用任何词表（用户自部署 + 随机调度，词表无法应对所有任务，积累无意义）。
- **结论**：在该约束下，若不引入**非词表打分**（如 LM），同音/近音后处理**无法在多候选时选优**，当前实现**不修改文本**，仅占位。
- **语义修复**：模型为 Qwen2.5-3B-Instruct（GGUF）；服务**只能返回文本、无真实分数**；若用非词表方式做同音选优，需引入轻量打分器（如字符级 n-gram LM）或改为「自评分 + 解释」方案。
- **提请审议**：采纳上述 A/B/C 中哪一选项，是否引入轻量打分器或「自评分 + 解释」，以及「非词表打分」的边界与实现路径。
