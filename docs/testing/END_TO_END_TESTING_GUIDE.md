# 端到端测试指南

**版本**: v1.0  
**最后更新**: 2025-01-XX  
**适用对象**: 测试人员、开发人员、QA 团队

---

## 📋 目录

1. [测试概述](#1-测试概述)
2. [测试环境准备](#2-测试环境准备)
3. [基础功能测试](#3-基础功能测试)
4. [高级功能测试](#4-高级功能测试)
5. [错误场景测试](#5-错误场景测试)
6. [性能测试](#6-性能测试)
7. [测试检查清单](#7-测试检查清单)
8. [高级功能测试说明](#8-高级功能测试说明)
9. [问题报告模板](#9-问题报告模板)
10. [测试工具和脚本](#11-测试工具和脚本)
11. [常见问题排查](#12-常见问题排查)
12. [测试报告模板](#13-测试报告模板)
13. [相关文档](#14-相关文档)

---

## 1. 测试概述

### 1.1 测试目标

端到端测试旨在验证整个系统的完整功能流程，确保：

- ✅ 所有组件能够正常协作
- ✅ 核心翻译流程完整可用
- ✅ 高级功能（双向模式、会议室模式）正常工作
- ✅ 错误处理机制有效
- ✅ 系统性能满足要求

### 1.2 测试范围

**核心功能**：
- 实时语音翻译（ASR → NMT → TTS）
- 会话模式（持续监听）
- 双向模式（面对面模式）
- 会议室模式（WebRTC 连接和音频混控）
- 功能选择（可选模块）
- ASR 字幕显示

**非核心功能**（可选测试）：
- Utterance Group（所有组件已完成 ✅，需要 Python M2M100 服务端支持上下文参数）
- Silero VAD 上下文缓冲（已实现 ✅，但当前在 `inference.rs` 中未使用）
- 模块化功能（音色识别、语速控制等，需要模型支持）

### 1.3 测试架构

```
┌─────────────┐
│ Web Client  │ (测试客户端)
└──────┬──────┘
       │ WebSocket
       ▼
┌─────────────────┐
│   Scheduler     │ (调度服务器)
└──────┬──────────┘
       │ WebSocket
       ▼
┌─────────────────┐
│ Electron Node   │ (节点客户端)
└──────┬──────────┘
       │ HTTP
       ▼
┌─────────────────┐
│ Node Inference  │ (推理服务)
└─────────────────┘
```

---

## 2. 测试环境准备

### 2.1 前置要求

**硬件要求**：
- CPU: 4 核以上（推荐 8 核）
- 内存: 8GB 以上（推荐 16GB）
- 存储: 10GB+ 可用空间（用于模型文件）
- GPU: 可选，用于加速推理（推荐 NVIDIA GPU，支持 CUDA）

**软件要求**：
- **Rust**: 1.70+ (用于调度服务器和节点推理服务)
- **Node.js**: 18+ (用于 Electron 和 Web 客户端)
- **Python**: 3.10+ (用于模型库服务)
- **CUDA**: 12.1+ (可选，用于 GPU 加速)
- **浏览器**: Chrome/Edge 最新版本（用于 Web 客户端）

### 2.2 环境配置

#### 2.2.1 克隆项目

```bash
git clone <repository-url>
cd lingua_1
```

#### 2.2.2 配置调度服务器

编辑 `scheduler/config.toml`:

```toml
[server]
port = 8080
host = "0.0.0.0"

[model_hub]
base_url = "http://localhost:5000"
storage_path = "./models"

[scheduler.load_balancer]
strategy = "least_connections"
resource_threshold = 0.25  # CPU/GPU/内存使用率阈值
```

#### 2.2.3 配置节点推理服务

设置环境变量：

```powershell
# Windows PowerShell
$env:MODELS_DIR = "D:\models"  # 模型文件目录
$env:INFERENCE_SERVICE_PORT = "9000"
$env:ASR_MODEL_PATH = "D:\models\whisper-large-v3"
$env:NMT_SERVICE_URL = "http://localhost:8000"  # Python M2M100 服务
$env:TTS_SERVICE_URL = "http://localhost:5001"  # Piper TTS 服务
```

#### 2.2.4 配置 Electron Node 客户端

设置环境变量：

```powershell
# Windows PowerShell
$env:SCHEDULER_URL = "ws://localhost:8080/ws/node"
$env:MODEL_HUB_URL = "http://localhost:5000"
$env:INFERENCE_SERVICE_URL = "http://localhost:9000"
```

#### 2.2.5 配置 Web 客户端

编辑 `web-client/src/config.ts` (如果存在) 或直接在代码中设置：

```typescript
const SCHEDULER_URL = 'ws://localhost:8080/ws/session';
```

### 2.3 启动服务

#### 2.3.1 启动模型库服务

```powershell
cd model-hub
python -m venv venv
.\venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/macOS
pip install -r requirements.txt
python src/main.py
```

**验证**: 访问 `http://localhost:5000/api/models` 应返回模型列表。

#### 2.3.2 启动调度服务器

```powershell
cd scheduler
cargo build --release
cargo run --release
```

**验证**: 
- 检查日志输出，确认服务启动成功
- 访问 `http://localhost:8080` 应返回服务信息（如果有健康检查端点）

#### 2.3.3 启动节点推理服务

```powershell
cd node-inference
cargo build --release
cargo run --release
```

**验证**:
- 检查日志输出，确认服务启动成功
- 访问 `http://localhost:9000/health` 应返回健康状态

#### 2.3.4 启动 Electron Node 客户端

```powershell
cd electron-node
npm install
npm run build
npm start
```

**验证**:
- 检查 Electron 窗口是否正常打开
- 检查系统资源监控是否正常显示
- 检查节点是否成功注册到调度服务器（查看调度服务器日志）

#### 2.3.5 启动 Web 客户端

```powershell
cd web-client
npm install
npm run dev
```

**验证**: 访问 `http://localhost:3000` 应显示 Web 客户端界面。

#### 2.3.6 一键启动（Windows）

使用提供的 PowerShell 脚本：

```powershell
.\scripts\start_all.ps1
```

这将启动所有服务（模型库、调度服务器、API Gateway）。

### 2.4 模型准备

#### 2.4.1 安装必需模型

在 Electron Node 客户端中：

1. 打开"模型管理"界面
2. 下载并安装以下模型：
   - **ASR 模型**: Whisper (推荐 `whisper-large-v3`)
   - **NMT 模型**: M2M100 (需要 Python 服务支持)
   - **TTS 模型**: Piper (需要 TTS 服务支持)

#### 2.4.2 验证模型安装

- 检查 Electron Node 客户端的模型列表
- 确认模型状态为"已安装"
- 检查节点注册消息中的 `installed_models` 字段

---

## 3. 基础功能测试

### 3.1 测试用例 1: 单次翻译流程

**目标**: 验证基本的语音翻译流程（ASR → NMT → TTS）

**前置条件**:
- ✅ 所有服务已启动
- ✅ 节点已注册并处于 `ready` 状态
- ✅ 必需模型已安装

**测试步骤**:

1. **打开 Web 客户端**
   - 访问 `http://localhost:3000`
   - 确认界面正常显示

2. **配置翻译参数**
   - 选择源语言：中文 (zh)
   - 选择目标语言：英文 (en)
   - 选择模式：单向模式

3. **建立连接**
   - 点击"连接"按钮
   - 等待连接成功（状态显示为"已连接"）

4. **开始会话**
   - 点击"开始"按钮
   - 确认状态变为"录音中"

5. **说话并发送**
   - 对着麦克风说："今天天气不错"
   - 等待静音自动结束（约 1 秒）或点击"发送"按钮
   - 确认状态变为"等待结果"

6. **验证结果**
   - 等待翻译结果返回
   - 确认状态变为"播放中"
   - 确认听到英文 TTS 播放："The weather is nice today."
   - 确认 ASR 字幕显示："今天天气不错"
   - 确认翻译文本显示："The weather is nice today."

7. **结束会话**
   - 等待播放完成
   - 点击"结束"按钮
   - 确认状态变为"已断开"

**预期结果**:
- ✅ 连接成功
- ✅ 录音正常
- ✅ 翻译结果正确
- ✅ TTS 播放正常
- ✅ ASR 字幕显示正确
- ✅ 状态转换正常

**验证点**:
- [ ] WebSocket 连接建立成功
- [ ] `session_init` 消息发送成功
- [ ] `session_init_ack` 消息接收成功
- [ ] 音频数据上传成功
- [ ] `translation_result` 消息接收成功
- [ ] TTS 音频播放成功
- [ ] ASR 字幕显示正确

---

### 3.2 测试用例 2: 会话模式（持续监听）

**目标**: 验证会话模式下持续监听和多次发送功能

**前置条件**: 同测试用例 1

**测试步骤**:

1. **建立连接并开始会话**
   - 按照测试用例 1 的步骤 1-4 建立连接并开始会话

2. **第一次说话**
   - 说："你好"
   - 等待自动结束或点击"发送"
   - 确认翻译结果播放

3. **第二次说话（无需重新开始）**
   - 等待播放完成后，状态应自动回到"录音中"
   - 说："我是张三"
   - 等待自动结束或点击"发送"
   - 确认翻译结果播放

4. **第三次说话**
   - 等待播放完成后，状态应自动回到"录音中"
   - 说："很高兴认识你"
   - 等待自动结束或点击"发送"
   - 确认翻译结果播放

5. **结束会话**
   - 点击"结束"按钮
   - 确认状态变为"已断开"

**预期结果**:
- ✅ 播放完成后自动回到录音状态
- ✅ 可以连续多次说话和翻译
- ✅ 每次翻译结果都正确
- ✅ 状态转换正常

**验证点**:
- [ ] 播放完成后状态自动回到 `INPUT_RECORDING`
- [ ] 可以连续多次发送音频
- [ ] 每次翻译结果都正确
- [ ] 会话状态 (`isSessionActive`) 保持为 `true`

---

### 3.3 测试用例 3: 手动截断功能

**目标**: 验证用户手动点击"发送"按钮截断音频的功能

**前置条件**: 同测试用例 1

**测试步骤**:

1. **建立连接并开始会话**
   - 按照测试用例 1 的步骤 1-4 建立连接并开始会话

2. **说话并立即手动截断**
   - 开始说话："这是一个测试"
   - 在说完之前立即点击"发送"按钮
   - 确认音频被截断并发送

3. **验证结果**
   - 确认翻译结果返回
   - 确认播放正常

**预期结果**:
- ✅ 手动点击"发送"可以立即截断音频
- ✅ 截断后的音频可以正常翻译
- ✅ 翻译结果正确

**验证点**:
- [ ] 手动截断功能正常
- [ ] 截断后的音频可以正常处理
- [ ] 翻译结果正确

---

### 3.4 测试用例 4: 静音自动结束

**目标**: 验证静音检测自动结束录音的功能

**前置条件**: 同测试用例 1

**测试步骤**:

1. **建立连接并开始会话**
   - 按照测试用例 1 的步骤 1-4 建立连接并开始会话

2. **说话后保持静音**
   - 说："测试静音检测"
   - 说完后保持静音 1 秒以上
   - 确认录音自动结束（无需点击"发送"）

3. **验证结果**
   - 确认翻译结果返回
   - 确认播放正常

**预期结果**:
- ✅ 静音 1 秒后自动结束录音
- ✅ 自动发送音频
- ✅ 翻译结果正确

**验证点**:
- [ ] 静音检测功能正常
- [ ] 静音阈值设置正确（1000ms + 250ms 尾部缓冲）
- [ ] 自动结束和发送功能正常

---

### 3.5 测试用例 5: 播放期间关麦

**目标**: 验证播放期间自动关闭麦克风的功能

**前置条件**: 同测试用例 1

**测试步骤**:

1. **建立连接并开始会话**
   - 按照测试用例 1 的步骤 1-4 建立连接并开始会话

2. **说话并等待播放**
   - 说："测试关麦功能"
   - 等待翻译结果返回并开始播放

3. **验证播放期间麦克风状态**
   - 在播放期间尝试说话
   - 确认麦克风已关闭（浏览器应显示麦克风已关闭）
   - 确认播放不受影响

4. **验证播放完成后重新开麦**
   - 等待播放完成
   - 确认状态回到"录音中"
   - 确认麦克风重新打开

**预期结果**:
- ✅ 播放期间麦克风自动关闭
- ✅ 播放完成后麦克风自动重新打开
- ✅ 避免回声问题

**验证点**:
- [ ] 播放期间麦克风关闭
- [ ] 播放完成后麦克风重新打开
- [ ] 状态转换正常

---

## 4. 高级功能测试

### 4.1 测试用例 6: 双向模式（面对面模式）

**目标**: 验证双向自动翻译模式

**前置条件**:
- ✅ 所有服务已启动
- ✅ 节点已注册并处于 `ready` 状态
- ✅ 必需模型已安装
- ✅ 节点支持自动语言检测

**测试步骤**:

1. **打开 Web 客户端并配置双向模式**
   - 访问 `http://localhost:3000`
   - 选择模式：双向模式
   - 配置语言对：中文 (zh) 和 英文 (en)

2. **建立连接**
   - 点击"连接"按钮
   - 等待连接成功

3. **第一次说话（中文）**
   - 点击"开始"按钮
   - 说中文："你好"
   - 等待自动结束或点击"发送"
   - 确认翻译成英文并播放

4. **第二次说话（英文）**
   - 等待播放完成后，状态应自动回到"录音中"
   - 说英文："Hello"
   - 等待自动结束或点击"发送"
   - 确认翻译成中文并播放

5. **第三次说话（中文）**
   - 等待播放完成后，状态应自动回到"录音中"
   - 说中文："很高兴认识你"
   - 等待自动结束或点击"发送"
   - 确认翻译成英文并播放

6. **验证语言检测**
   - 检查调度服务器日志，确认 `detected_lang` 字段正确
   - 检查翻译方向是否正确切换

7. **结束会话**
   - 点击"结束"按钮

**预期结果**:
- ✅ 中文自动翻译成英文
- ✅ 英文自动翻译成中文
- ✅ 语言检测准确
- ✅ 翻译方向自动切换

**验证点**:
- [ ] `mode="two_way_auto"` 参数正确传递
- [ ] `lang_a` 和 `lang_b` 参数正确传递
- [ ] 语言检测功能正常
- [ ] 翻译方向自动切换
- [ ] 翻译结果正确

---

### 4.2 测试用例 7: 会议室模式 - 创建和加入房间

**目标**: 验证会议室模式的房间创建和加入功能

**前置条件**:
- ✅ 所有服务已启动
- ✅ 至少 2 个节点已注册并处于 `ready` 状态
- ✅ 必需模型已安装

**测试步骤**:

1. **第一个用户：创建房间**
   - 打开 Web 客户端（浏览器窗口 1）
   - 选择模式：会议室模式
   - 点击"创建房间"按钮
   - 记录房间码（6 位数字）

2. **第二个用户：加入房间**
   - 打开 Web 客户端（浏览器窗口 2，或使用另一个浏览器）
   - 选择模式：会议室模式
   - 输入房间码
   - 点击"加入房间"按钮
   - 确认加入成功

3. **验证成员列表**
   - 在两个浏览器窗口中确认成员列表显示正确
   - 确认两个用户都在成员列表中

4. **退出房间**
   - 在任一浏览器窗口中点击"退出房间"按钮
   - 确认退出成功
   - 确认另一个浏览器窗口中的成员列表更新

**预期结果**:
- ✅ 房间创建成功
- ✅ 房间码正确生成
- ✅ 加入房间成功
- ✅ 成员列表正确显示
- ✅ 退出房间功能正常

**验证点**:
- [ ] `room_create` 消息发送成功
- [ ] `room_created` 消息接收成功
- [ ] 房间码正确生成（6 位数字）
- [ ] `room_join` 消息发送成功
- [ ] `room_joined` 消息接收成功
- [ ] 成员列表正确更新
- [ ] `room_leave` 消息发送成功
- [ ] `room_left` 消息接收成功

---

### 4.3 测试用例 8: 会议室模式 - 多语言翻译路由

**目标**: 验证会议室模式下为不同语言创建独立翻译任务

**前置条件**:
- ✅ 所有服务已启动
- ✅ 至少 2 个节点已注册并处于 `ready` 状态
- ✅ 必需模型已安装
- ✅ 已创建房间并至少有 2 个成员

**测试步骤**:

1. **配置成员语言偏好**
   - 成员 A：输入语言 = 中文 (zh)，输出语言 = 英文 (en)
   - 成员 B：输入语言 = 英文 (en)，输出语言 = 中文 (zh)

2. **成员 A 说话**
   - 成员 A 说中文："你好"
   - 等待翻译结果

3. **验证翻译路由**
   - 检查调度服务器日志，确认创建了 2 个独立的 Job：
     - Job 1: zh → en (发送给成员 A)
     - Job 2: zh → en (发送给成员 B，因为成员 B 的输出语言是中文，但输入是英文，所以应该收到英文翻译)
   - 实际上，应该根据每个成员的输出语言创建 Job

4. **成员 B 说话**
   - 成员 B 说英文："Hello"
   - 等待翻译结果

5. **验证翻译路由**
   - 检查调度服务器日志，确认创建了相应的 Job

**预期结果**:
- ✅ 为每个不同的目标语言创建独立的 Job
- ✅ 翻译结果正确路由到对应成员
- ✅ 每个成员收到正确的翻译结果

**验证点**:
- [ ] 调度服务器正确识别成员的语言偏好
- [ ] 为每个不同的目标语言创建独立的 Job
- [ ] 翻译结果正确路由
- [ ] 每个成员收到正确的翻译结果

---

### 4.4 测试用例 9: 会议室模式 - WebRTC 连接和音频混控

**目标**: 验证会议室模式下的 WebRTC P2P 连接和音频混控功能

**前置条件**:
- ✅ 所有服务已启动
- ✅ 至少 2 个节点已注册并处于 `ready` 状态
- ✅ 必需模型已安装
- ✅ 已创建房间并至少有 2 个成员
- ✅ 浏览器支持 WebRTC

**测试步骤**:

1. **启用原声传递**
   - 在两个浏览器窗口中，确认原声传递开关已启用
   - 确认 WebRTC 连接建立（检查浏览器控制台日志）

2. **成员 A 说话**
   - 成员 A 说："测试原声传递"
   - 成员 B 应该立即听到原声（低延迟）

3. **验证音频混控**
   - 成员 B 应该先听到原声
   - 翻译音频到达后，原声应淡出，翻译音频应淡入
   - 确认混控效果平滑（无突兀切换）

4. **禁用原声传递**
   - 在成员 B 的浏览器窗口中，禁用对成员 A 的原声传递
   - 确认 WebRTC 连接断开（检查浏览器控制台日志）

5. **成员 A 再次说话**
   - 成员 A 说："测试禁用原声"
   - 成员 B 应该只听到翻译音频（不听到原声）

6. **验证带宽优化**
   - 检查浏览器网络监控，确认 WebRTC 连接已断开
   - 确认不再有 WebRTC 流量

**预期结果**:
- ✅ WebRTC 连接建立成功
- ✅ 原声传递正常
- ✅ 音频混控效果平滑
- ✅ 原声传递开关实时生效
- ✅ 禁用原声时 WebRTC 连接断开（带宽优化）

**验证点**:
- [ ] WebRTC offer/answer/ICE 信令正常
- [ ] WebRTC 连接建立成功
- [ ] 原声音频传输正常
- [ ] 音频混控效果平滑（淡入淡出）
- [ ] 原声传递开关实时生效
- [ ] 禁用原声时 WebRTC 连接断开

---

### 4.5 测试用例 10: 功能选择

**目标**: 验证用户选择可选功能后，调度服务器正确匹配节点

**前置条件**:
- ✅ 所有服务已启动
- ✅ 至少 1 个节点已注册并处于 `ready` 状态
- ✅ 节点支持所需功能（或测试不支持的情况）

**测试步骤**:

1. **选择功能**
   - 打开 Web 客户端
   - 在功能选择界面中，选择"情感检测"功能
   - 确认功能选择保存

2. **建立连接并开始会话**
   - 选择源语言和目标语言
   - 点击"连接"按钮
   - 点击"开始"按钮

3. **说话并发送**
   - 说："我很高兴"
   - 等待翻译结果

4. **验证功能传递**
   - 检查 `session_init` 消息，确认 `features.emotion_detection = true`
   - 检查调度服务器日志，确认节点选择时考虑了功能要求
   - 检查 `job_assign` 消息，确认 `features.emotion_detection = true`

5. **验证功能结果**
   - 检查 `translation_result` 消息，确认 `extra.emotion` 字段存在（如果节点支持）

**预期结果**:
- ✅ 功能选择正确传递到调度服务器
- ✅ 调度服务器正确匹配支持该功能的节点
- ✅ 功能结果正确返回（如果节点支持）

**验证点**:
- [ ] 功能选择 UI 正常
- [ ] `features` 字段正确传递
- [ ] 调度服务器正确匹配节点
- [ ] 功能结果正确返回（如果支持）

---

## 5. 错误场景测试

### 5.1 测试用例 11: 节点离线处理

**目标**: 验证节点离线时的错误处理

**测试步骤**:

1. **建立正常连接**
   - 按照测试用例 1 建立连接并开始会话

2. **模拟节点离线**
   - 关闭 Electron Node 客户端
   - 或停止节点推理服务

3. **尝试翻译**
   - 说："测试节点离线"
   - 等待结果

4. **验证错误处理**
   - 确认收到错误消息
   - 确认错误消息格式正确
   - 确认用户看到友好的错误提示

**预期结果**:
- ✅ 系统检测到节点离线
- ✅ 返回适当的错误消息
- ✅ 用户看到友好的错误提示

---

### 5.2 测试用例 12: 网络中断恢复

**目标**: 验证网络中断后的恢复能力

**测试步骤**:

1. **建立正常连接**
   - 按照测试用例 1 建立连接并开始会话

2. **模拟网络中断**
   - 断开网络连接（禁用网络适配器）
   - 或关闭调度服务器

3. **验证连接断开**
   - 确认 WebSocket 连接断开
   - 确认状态变为"已断开"

4. **恢复网络**
   - 重新连接网络
   - 或重新启动调度服务器

5. **重新连接**
   - 点击"连接"按钮
   - 确认重新连接成功

**预期结果**:
- ✅ 网络中断时连接正确断开
- ✅ 网络恢复后可以重新连接
- ✅ 重新连接后功能正常

---

### 5.3 测试用例 13: 模型缺失处理

**目标**: 验证节点缺少必需模型时的错误处理

**测试步骤**:

1. **卸载模型**
   - 在 Electron Node 客户端中，卸载 ASR 模型

2. **建立连接并尝试翻译**
   - 按照测试用例 1 建立连接并开始会话
   - 说："测试模型缺失"
   - 等待结果

3. **验证错误处理**
   - 确认收到 `MODEL_NOT_AVAILABLE` 错误
   - 确认错误消息格式正确
   - 确认用户看到友好的错误提示

**预期结果**:
- ✅ 系统检测到模型缺失
- ✅ 返回 `MODEL_NOT_AVAILABLE` 错误
- ✅ 用户看到友好的错误提示

---

## 6. 性能测试

### 6.1 测试用例 14: 延迟测试

**目标**: 测量端到端翻译延迟

**测试步骤**:

1. **建立连接并开始会话**
   - 按照测试用例 1 建立连接并开始会话

2. **测量延迟**
   - 记录开始说话的时间点 (T1)
   - 说："测试延迟"
   - 记录翻译结果返回的时间点 (T2)
   - 记录 TTS 播放开始的时间点 (T3)

3. **计算延迟**
   - 端到端延迟 = T3 - T1
   - ASR 延迟 = T2 - T1（从日志中获取）
   - NMT 延迟 = （从日志中获取）
   - TTS 延迟 = T3 - T2

4. **多次测试**
   - 重复测试 10 次
   - 计算平均延迟和最大延迟

**预期结果**:
- ✅ 端到端延迟 < 5 秒（目标 < 3 秒）
- ✅ ASR 延迟 < 2 秒
- ✅ NMT 延迟 < 1 秒
- ✅ TTS 延迟 < 1 秒

---

### 6.2 测试用例 15: 并发测试

**目标**: 验证系统处理并发会话的能力

**测试步骤**:

1. **启动多个 Web 客户端**
   - 打开 5 个浏览器窗口
   - 每个窗口打开 Web 客户端

2. **同时建立连接**
   - 在 5 个窗口中同时点击"连接"按钮
   - 确认所有连接都成功

3. **同时开始会话**
   - 在 5 个窗口中同时点击"开始"按钮
   - 确认所有会话都开始成功

4. **同时说话**
   - 在 5 个窗口中同时说话
   - 等待所有翻译结果返回

5. **验证结果**
   - 确认所有翻译结果都正确
   - 确认没有连接断开
   - 检查调度服务器日志，确认负载均衡正常

**预期结果**:
- ✅ 系统可以处理至少 5 个并发会话
- ✅ 所有会话的翻译结果都正确
- ✅ 负载均衡正常工作

---

## 7. 测试检查清单

### 7.1 环境准备检查清单

- [ ] 所有服务已启动
- [ ] 节点已注册并处于 `ready` 状态
- [ ] 必需模型已安装
- [ ] 网络连接正常
- [ ] 浏览器支持 WebRTC（用于会议室模式测试）

### 7.2 基础功能检查清单

- [ ] 单次翻译流程正常
- [ ] 会话模式正常
- [ ] 手动截断功能正常
- [ ] 静音自动结束功能正常
- [ ] 播放期间关麦功能正常

### 7.3 高级功能检查清单

- [ ] 双向模式正常
- [ ] 会议室模式房间创建和加入正常
- [ ] 会议室模式多语言翻译路由正常
- [ ] 会议室模式 WebRTC 连接正常
- [ ] 会议室模式音频混控正常
- [ ] 功能选择正常

### 7.4 错误处理检查清单

- [ ] 节点离线处理正常
- [ ] 网络中断恢复正常
- [ ] 模型缺失处理正常

### 7.5 性能检查清单

- [ ] 端到端延迟满足要求
- [ ] 并发处理能力满足要求

---

## 8. 高级功能测试说明

### 8.1 Utterance Group 功能测试

**状态**: ✅ 所有组件已完成，需要 Python M2M100 服务端支持上下文参数

**测试目标**: 验证连续对话翻译的上下文一致性

**测试场景**:
1. **连续发言测试**:
   - 在 2 秒内连续发言多次
   - 验证 utterances 是否被组织到同一个 Group
   - 验证翻译质量是否提升（特别是代词、省略句）

2. **跨组切换测试**:
   - 发言后等待超过 2 秒（或 TTS 播放结束）
   - 再次发言，验证是否创建新 Group

3. **上下文拼接测试**:
   - 验证 `context_text` 格式正确
   - 验证上下文长度限制（最多 8 个 parts，800 字符）

**注意事项**:
- ⚠️ 当前流程限制：ASR 和 NMT 在节点端顺序执行，首次 `JobAssign` 时 `context_text` 为 `None`
- ⚠️ Python M2M100 服务端需要支持 `context_text` 参数（当前仅简单拼接）

**相关文档**:
- [Utterance Group 实现原理](../UTTERANCE_GROUP_IMPLEMENTATION.md)
- [Utterance Group 完整文档](../webClient/UTTERANCE_GROUP.md)

### 8.2 Silero VAD 上下文缓冲测试

**状态**: ✅ 已实现，但当前在 `inference.rs` 中未使用

**测试目标**: 验证节点端 VAD 的上下文缓冲机制

**测试场景**:
1. **RNN 隐藏状态测试**:
   - 验证隐藏状态在帧之间正确传递
   - 验证 `reset_state()` 功能正常

2. **语速自适应测试**:
   - 使用不同语速说话
   - 验证静音阈值是否自适应调整（200ms - 800ms）

3. **状态管理测试**:
   - 验证 `silence_frame_count`、`last_speech_timestamp` 等状态正确更新
   - 验证冷却期机制防止频繁边界检测

**注意事项**:
- ⚠️ 当前节点端 VAD 未集成到 `inference.rs` 处理流程中
- ⚠️ 需要实现流式断句功能才能完全生效

**相关文档**:
- [VAD 架构分析](../VAD_ARCHITECTURE_ANALYSIS.md)
- [上下文缓冲功能对比](../CONTEXT_BUFFERING_COMPARISON.md)

### 8.3 上下文缓冲功能对比

**重要说明**: Silero VAD 上下文缓冲和 Utterance Group 上下文缓冲**不重复**，而是**互补**的：

| 维度 | Silero VAD | Utterance Group |
|------|-----------|----------------|
| **层次** | 音频级别 | 文本级别 |
| **目标** | 提升 VAD 准确性 | 提升 NMT 质量 |
| **作用阶段** | ASR 之前 | NMT 阶段 |

**相关文档**:
- [上下文缓冲功能对比](../CONTEXT_BUFFERING_COMPARISON.md)

---

## 9. 问题报告模板

### 9.1 问题报告格式

```markdown
## 问题报告

**测试用例**: [测试用例编号和名称]
**严重程度**: [严重/中等/轻微]
**发现时间**: [YYYY-MM-DD HH:MM:SS]

### 问题描述
[详细描述问题现象]

### 复现步骤
1. [步骤 1]
2. [步骤 2]
3. [步骤 3]

### 预期结果
[描述预期结果]

### 实际结果
[描述实际结果]

### 环境信息
- 操作系统: [Windows 10/11/macOS/Linux]
- 浏览器: [Chrome/Edge/Firefox] [版本号]
- 调度服务器版本: [版本号]
- 节点推理服务版本: [版本号]
- Web 客户端版本: [版本号]

### 日志信息
[粘贴相关日志]

### 截图/视频
[如有，请附加]

### 其他信息
[其他相关信息]
```

---

## 11. 测试工具和脚本

### 11.1 日志查看工具

**调度服务器日志**:
```powershell
# 查看调度服务器日志
Get-Content scheduler/logs/scheduler.log -Tail 100 -Wait
```

**节点推理服务日志**:
```powershell
# 查看节点推理服务日志
Get-Content node-inference/logs/inference.log -Tail 100 -Wait
```

### 11.2 网络监控工具

使用浏览器开发者工具监控 WebSocket 消息：
1. 打开浏览器开发者工具 (F12)
2. 切换到"Network"标签
3. 过滤 "WS" (WebSocket)
4. 查看消息内容

### 11.3 性能监控工具

使用浏览器 Performance API 测量延迟：
```javascript
// 在浏览器控制台中运行
performance.mark('start');
// ... 执行操作 ...
performance.mark('end');
performance.measure('duration', 'start', 'end');
console.log(performance.getEntriesByName('duration'));
```

---

## 10. 常见问题排查

### 10.1 连接失败

**问题**: Web 客户端无法连接到调度服务器

**排查步骤**:
1. 检查调度服务器是否运行
2. 检查端口 8080 是否被占用
3. 检查防火墙设置
4. 检查 WebSocket URL 是否正确
5. 查看浏览器控制台错误信息
6. 查看调度服务器日志

### 12.2 节点未注册

**问题**: Electron Node 客户端无法注册到调度服务器

**排查步骤**:
1. 检查调度服务器是否运行
2. 检查 WebSocket URL 是否正确
3. 检查节点推理服务是否运行
4. 检查 GPU 要求（如果节点需要 GPU）
5. 查看 Electron Node 客户端日志
6. 查看调度服务器日志

### 12.3 翻译结果不正确

**问题**: 翻译结果不准确或错误

**排查步骤**:
1. 检查 ASR 识别结果是否正确
2. 检查 NMT 翻译结果是否正确
3. 检查模型是否正确加载
4. 检查音频质量
5. 查看节点推理服务日志

### 12.4 WebRTC 连接失败

**问题**: 会议室模式下 WebRTC 连接失败

**排查步骤**:
1. 检查浏览器是否支持 WebRTC
2. 检查防火墙设置（UDP 端口）
3. 检查 STUN/TURN 服务器配置
4. 查看浏览器控制台错误信息
5. 检查网络环境（NAT 类型）

---

## 13. 测试报告模板

### 11.1 测试报告格式

```markdown
# 端到端测试报告

**测试日期**: [YYYY-MM-DD]
**测试人员**: [姓名]
**测试环境**: [环境描述]

## 测试概要

- **测试用例总数**: [数量]
- **通过**: [数量]
- **失败**: [数量]
- **跳过**: [数量]
- **通过率**: [百分比]

## 测试结果详情

### 基础功能测试
- [ ] 测试用例 1: 单次翻译流程 - [通过/失败]
- [ ] 测试用例 2: 会话模式 - [通过/失败]
- [ ] 测试用例 3: 手动截断功能 - [通过/失败]
- [ ] 测试用例 4: 静音自动结束 - [通过/失败]
- [ ] 测试用例 5: 播放期间关麦 - [通过/失败]

### 高级功能测试
- [ ] 测试用例 6: 双向模式 - [通过/失败]
- [ ] 测试用例 7: 会议室模式 - 创建和加入房间 - [通过/失败]
- [ ] 测试用例 8: 会议室模式 - 多语言翻译路由 - [通过/失败]
- [ ] 测试用例 9: 会议室模式 - WebRTC 连接和音频混控 - [通过/失败]
- [ ] 测试用例 10: 功能选择 - [通过/失败]

### 错误场景测试
- [ ] 测试用例 11: 节点离线处理 - [通过/失败]
- [ ] 测试用例 12: 网络中断恢复 - [通过/失败]
- [ ] 测试用例 13: 模型缺失处理 - [通过/失败]

### 性能测试
- [ ] 测试用例 14: 延迟测试 - [通过/失败]
- [ ] 测试用例 15: 并发测试 - [通过/失败]

## 问题汇总

[列出所有发现的问题]

## 结论

[测试结论和建议]
```

---

## 14. 相关文档

### 核心文档
- [项目状态文档](../project_management/PROJECT_STATUS.md)
- [快速开始指南](../GETTING_STARTED.md)
- [架构文档](../ARCHITECTURE.md)
- [协议规范](../PROTOCOLS.md)

### 功能文档
- [Web 客户端文档](../webClient/README.md)
- [节点推理服务文档](../node_inference/README.md)

### 技术深度文档
- [Utterance Group 实现原理](../UTTERANCE_GROUP_IMPLEMENTATION.md)
- [上下文缓冲功能对比](../CONTEXT_BUFFERING_COMPARISON.md)
- [VAD 架构分析](../VAD_ARCHITECTURE_ANALYSIS.md)

---

**最后更新**: 2025-01-XX

