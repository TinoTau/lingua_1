# 节点端用户功能说明

**最后更新**: 2025-01-XX  
**系统状态**: ✅ **核心功能已完成，可以开始提供算力服务**

---

## 🎯 节点端用户角色

**您是谁**：算力提供方（Node Provider）  
**您的职责**：提供 GPU 算力，运行 AI 模型，为其他用户提供实时语音翻译服务

---

## 📋 系统要求

### 硬件要求

**必需**：
- ✅ **GPU**：必须有 NVIDIA GPU（这是强制要求，没有 GPU 无法注册）
- ✅ **CPU**：多核 CPU（推荐 8 核以上）
- ✅ **内存**：推荐 16GB 以上
- ✅ **存储**：足够的磁盘空间用于存储模型文件（每个模型可能需要几 GB 到几十 GB）

**推荐配置**：
- GPU：NVIDIA RTX 3060 或更高
- CPU：8 核以上
- 内存：32GB
- 存储：至少 100GB 可用空间

### 软件要求

- ✅ **操作系统**：Windows / Linux / macOS
- ✅ **GPU 驱动**：已安装 NVIDIA 驱动
- ✅ **网络**：能够连接到调度服务器

---

## 🚀 核心功能

### 1. 自动注册为算力节点 ✅

**功能描述**：  
启动 Electron Node 客户端后，系统会自动连接到调度服务器并注册为算力提供方。

**工作流程**：
1. 启动 Electron Node 客户端
2. 系统自动检测硬件信息（CPU、GPU、内存）
3. 自动连接到调度服务器
4. 自动发送注册信息
5. 服务器验证后，节点注册成功

**您需要做的**：
- ✅ 确保 GPU 已正确安装并识别
- ✅ 确保网络连接正常
- ✅ 启动客户端即可，无需手动操作

**状态显示**：
- 🟢 **已连接**：节点已成功注册，可以接收任务
- 🟡 **注册中**：正在注册，等待健康检查通过
- 🔴 **注册失败**：检查 GPU 配置或网络连接

---

### 2. 模型管理 📦

**功能描述**：  
您可以下载、安装和管理 AI 模型，这些模型用于提供翻译服务。

**可用模型类型**：
- **ASR（语音识别）**：将语音转换为文字
- **NMT（机器翻译）**：将一种语言翻译成另一种语言
- **TTS（语音合成）**：将文字转换为语音
- **VAD（语音活动检测）**：检测语音的开始和结束
- **可选模块模型**（可选）：
  - 音色识别模型
  - 音色生成模型
  - 语速识别模型
  - 语速控制模型
  - 情感检测模型
  - 个性化适配模型

**您可以做什么**：
- ✅ **浏览模型列表**：查看可用的模型
- ✅ **下载模型**：从模型库下载需要的模型
- ✅ **查看下载进度**：实时查看下载进度
- ✅ **安装模型**：下载完成后自动安装
- ✅ **卸载模型**：删除不需要的模型以释放空间
- ✅ **查看已安装模型**：查看当前已安装的模型列表

**重要说明**：
- 模型文件可能很大（几 GB 到几十 GB），请确保有足够的存储空间
- 下载速度取决于网络带宽
- 支持断点续传，下载中断后可以继续
- 模型安装后会自动验证完整性

---

### 3. 系统资源监控 📊

**功能描述**：  
实时监控您的系统资源使用情况，包括 CPU、GPU、内存等。

**监控指标**：
- ✅ **CPU 使用率**：实时显示 CPU 使用百分比
- ✅ **GPU 使用率**：实时显示 GPU 使用百分比
- ✅ **GPU 显存使用率**：实时显示 GPU 显存使用情况
- ✅ **内存使用率**：实时显示系统内存使用情况

**用途**：
- 了解系统负载情况
- 判断是否需要升级硬件
- 监控任务处理时的资源消耗

**显示方式**：
- 实时图表显示
- 数值百分比显示
- 资源使用趋势

---

### 4. 自动接收和处理翻译任务 🤖

**功能描述**：  
注册成功后，系统会自动接收调度服务器分配的任务，并自动处理。

**工作流程**：
1. 调度服务器根据用户需求选择您的节点
2. 任务自动下发到您的节点
3. 系统自动加载相应的模型
4. 自动处理任务（ASR → NMT → TTS）
5. 自动返回处理结果

**您需要做的**：
- ✅ **无需任何操作**：系统全自动处理
- ✅ 确保已安装所需的模型
- ✅ 确保系统资源充足

**任务类型**：
- 实时语音翻译任务
- 支持多种语言对（如中文 ↔ 英文）
- 支持可选功能（如音色识别、语速控制等）

---

### 5. 智能模块管理 🧩

**功能描述**：  
系统会根据任务需求自动启用或禁用功能模块，无需您手动操作。

**工作原理**：
- Web/移动端用户选择需要的功能
- 调度服务器匹配支持这些功能的节点
- 您的节点根据任务需求自动启用相应模块
- 任务完成后自动释放资源

**您需要做的**：
- ✅ **无需手动选择功能**：功能选择由使用翻译服务的用户决定
- ✅ 只需下载和安装模型即可
- ✅ 系统会自动根据任务需求启用模块

**支持的功能模块**（需要先下载相应模型）：
- 音色识别（Speaker Identification）
- 音色生成（Voice Cloning）
- 语速识别（Speech Rate Detection）
- 语速控制（Speech Rate Control）
- 情感检测（Emotion Detection）
- 个性化适配（Persona Adaptation）

---

### 6. 节点状态管理 📈

**功能描述**：  
系统会自动管理节点状态，确保节点健康运行。

**节点状态**：
- **registering**：正在注册，等待健康检查通过
- **ready**：已就绪，可以接收任务
- **degraded**：能力下降（如模型缺失、GPU 异常）
- **offline**：已离线（心跳丢失）

**状态转换**：
- 注册成功后，经过健康检查（连续 3 次心跳正常）后转为 `ready`
- 如果健康检查失败，会转为 `degraded`
- 如果心跳超时，会转为 `offline`

**您需要做的**：
- ✅ 确保 GPU 正常工作
- ✅ 确保已安装必需的模型
- ✅ 保持网络连接稳定
- ✅ 系统会自动管理状态，无需手动干预

---

## 🎨 用户界面

### 主界面布局

```
┌─────────────────────────────────────────┐
│  Lingua Node 客户端                      │
│  ┌───────────────────────────────────┐  │
│  │ ● 已连接                           │  │
│  │   节点ID: node-ABC12345            │  │
│  └───────────────────────────────────┘  │
│                                          │
│  ┌──────────────┬────────────────────┐  │
│  │ 系统资源监控  │   模型管理          │  │
│  │              │                    │  │
│  │ CPU: 25%     │  [下载模型]        │  │
│  │ GPU: 45%     │  [已安装模型列表]  │  │
│  │ 内存: 60%    │                    │  │
│  │              │  • ASR 模型        │  │
│  │ [实时图表]   │  • NMT 模型        │  │
│  │              │  • TTS 模型        │  │
│  └──────────────┴────────────────────┘  │
└─────────────────────────────────────────┘
```

### 界面功能

**顶部状态栏**：
- 显示连接状态（已连接/未连接）
- 显示节点 ID
- 显示注册状态

**左侧面板 - 系统资源监控**：
- CPU 使用率实时显示
- GPU 使用率和显存使用率
- 内存使用率
- 资源使用趋势图表

**右侧面板 - 模型管理**：
- 模型下载按钮
- 已安装模型列表
- 模型下载进度
- 模型卸载功能

---

## ⚙️ 配置说明

### 调度服务器地址

**环境变量配置**：
```powershell
# Windows PowerShell
$env:SCHEDULER_URL = "ws://localhost:5010/ws/node"
```

```bash
# Linux/macOS
export SCHEDULER_URL="ws://localhost:5010/ws/node"
```

### 模型库地址

**环境变量配置**：
```powershell
# Windows PowerShell
$env:MODEL_HUB_URL = "http://localhost:5000"
```

```bash
# Linux/macOS
export MODEL_HUB_URL="http://localhost:5000"
```

---

## 🔧 常见操作

### 1. 首次使用

1. **检查硬件**：
   - 确认 GPU 已安装并识别
   - 确认 GPU 驱动已安装

2. **启动客户端**：
   - 运行 Electron Node 客户端
   - 等待自动连接和注册

3. **下载模型**：
   - 打开"模型管理"界面
   - 选择需要的模型（ASR、NMT、TTS）
   - 点击下载并等待完成

4. **开始服务**：
   - 注册成功后，节点会自动接收任务
   - 无需其他操作

### 2. 添加新模型

1. 打开"模型管理"界面
2. 浏览可用模型列表
3. 选择需要的模型
4. 点击"下载"
5. 等待下载和安装完成

### 3. 卸载模型

1. 打开"模型管理"界面
2. 在已安装模型列表中找到要卸载的模型
3. 点击"卸载"
4. 确认卸载操作

### 4. 查看系统状态

1. 查看顶部状态栏的连接状态
2. 查看左侧面板的资源使用情况
3. 如果状态异常，检查：
   - GPU 是否正常工作
   - 网络连接是否正常
   - 模型是否完整

---

## ⚠️ 注意事项

### 1. GPU 要求

**重要**：节点必须有 GPU 才能注册为算力提供方。

- 如果没有 GPU，注册会失败
- GPU 驱动必须正确安装
- GPU 必须被系统正确识别

### 2. 模型管理

- 模型文件很大，请确保有足够的存储空间
- 下载模型需要时间，请耐心等待
- 支持断点续传，下载中断后可以继续
- 卸载模型会释放存储空间，但需要重新下载才能使用

### 3. 网络连接

- 必须能够连接到调度服务器
- 必须能够访问模型库服务
- 网络不稳定可能导致任务失败

### 4. 资源使用

- 处理任务时会占用 GPU 和 CPU 资源
- 建议在空闲时提供算力服务
- 如果系统负载过高，可以暂时关闭客户端

### 5. 功能选择

**重要**：节点端不提供功能开关 UI。

- 功能选择由使用翻译服务的用户（Web/移动端）决定
- 节点端只需下载和安装模型
- 系统会根据任务需求自动启用相应模块

---

## 🎯 使用场景

### 场景 1：个人用户提供算力

**情况**：您有一台配备 GPU 的电脑，想要在空闲时提供算力服务。

**操作**：
1. 启动 Electron Node 客户端
2. 下载必要的模型（ASR、NMT、TTS）
3. 保持客户端运行
4. 系统会自动接收和处理任务

**优势**：
- 充分利用闲置 GPU 资源
- 为其他用户提供翻译服务
- 无需手动操作

### 场景 2：企业部署算力节点

**情况**：企业需要部署多个算力节点，提供稳定的翻译服务。

**操作**：
1. 在多台服务器上部署 Electron Node 客户端
2. 配置调度服务器地址
3. 下载和安装所有需要的模型
4. 监控节点状态和资源使用情况

**优势**：
- 高可用性（多节点冗余）
- 负载均衡（调度服务器自动分配任务）
- 集中管理（通过调度服务器统一管理）

### 场景 3：开发者测试

**情况**：开发者需要测试新的模型或功能。

**操作**：
1. 在本地启动 Electron Node 客户端
2. 下载测试模型
3. 连接到测试环境的调度服务器
4. 测试模型和功能

**优势**：
- 本地测试环境
- 快速迭代
- 不影响生产环境

---

## 📊 节点状态说明

### 状态类型

| 状态 | 说明 | 您需要做什么 |
|------|------|------------|
| **registering** | 正在注册，等待健康检查通过 | 等待，通常需要 3 次心跳（约 45 秒） |
| **ready** | 已就绪，可以接收任务 | 无需操作，系统会自动接收任务 |
| **degraded** | 能力下降 | 检查 GPU 状态、模型完整性、网络连接 |
| **offline** | 已离线 | 检查网络连接，重启客户端 |

### 状态转换

```
启动客户端
  ↓
registering（注册中）
  ↓
[健康检查通过]
  ↓
ready（已就绪）←→ degraded（能力下降）
  ↓
[心跳超时]
  ↓
offline（离线）
```

---

## 🔗 相关文档

- [节点注册功能说明](./node_register/NODE_REGISTRATION_GUIDE.md) - 详细的注册流程和功能说明
- [节点注册协议规范](./node_register/NODE_REGISTRATION_PROTOCOL.md) - WebSocket 消息协议详细说明
- [Electron Node 实现文档](./electron_node/STAGE2.2_IMPLEMENTATION.md) - 技术实现细节
- [快速开始指南](./GETTING_STARTED.md) - 快速开始使用系统

---

## 📝 总结

作为节点端用户，您可以：

1. ✅ **提供算力服务**：利用 GPU 为其他用户提供实时语音翻译服务
2. ✅ **管理模型**：下载、安装、卸载 AI 模型
3. ✅ **监控资源**：实时查看系统资源使用情况
4. ✅ **自动处理任务**：系统自动接收和处理翻译任务，无需手动操作
5. ✅ **智能模块管理**：系统根据任务需求自动启用功能模块

**核心特点**：
- 🚀 **自动化**：注册、任务接收、模块启用全自动
- 🎯 **简单易用**：只需下载模型，无需复杂配置
- 📊 **可视化**：实时监控系统状态和资源使用
- 🔧 **灵活管理**：可以随时添加或删除模型

---

**最后更新**: 2025-01-XX

