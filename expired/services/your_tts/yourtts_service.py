#!/usr/bin/env python3
"""
YourTTS HTTP æœåŠ¡ï¼ˆZero-shot TTSï¼‰

ç”¨äºä» Rust ä»£ç è°ƒç”¨ YourTTS æ¨¡å‹è¿›è¡Œè¯­éŸ³åˆæˆï¼Œæ”¯æŒéŸ³è‰²å…‹éš†ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
    python yourtts_service.py [--gpu] [--port PORT] [--host HOST]

å‚æ•°ï¼š
    --gpu: ä½¿ç”¨ GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
    --port: æœåŠ¡ç«¯å£ï¼ˆé»˜è®¤ï¼š5004ï¼‰
    --host: æœåŠ¡åœ°å€ï¼ˆé»˜è®¤ï¼š127.0.0.1ï¼‰

API ç«¯ç‚¹ï¼š
    POST /synthesize
    Body: {
        "text": "è¦åˆæˆçš„æ–‡æœ¬",
        "reference_audio": [0.1, 0.2, ...],  # å‚è€ƒéŸ³é¢‘ï¼ˆå¯é€‰ï¼Œç”¨äºéŸ³è‰²å…‹éš†ï¼‰
        "language": "zh"  # è¯­è¨€ä»£ç ï¼ˆå¯é€‰ï¼‰
    }
    Response: {
        "audio": [0.1, 0.2, ...],  # åˆæˆçš„éŸ³é¢‘æ•°æ®ï¼ˆf32ï¼‰
        "sample_rate": 22050
    }
"""

import sys
import os
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
script_dir = Path(__file__).parent
project_root = script_dir.parent.parent
sys.path.insert(0, str(project_root))

from flask import Flask, request, jsonify
import numpy as np
import torch
import base64
import tempfile
import soundfile as sf
from scipy import signal
import requests

app = Flask(__name__)
tts_model = None
device = None

# Speaker ç¼“å­˜ï¼šå­˜å‚¨ speaker_id -> reference_audio çš„æ˜ å°„
# æ ¼å¼ï¼š{speaker_id: {"reference_audio": np.ndarray, "sample_rate": int, "voice_embedding": np.ndarray}}
speaker_cache = {}

# çº¿ç¨‹é”ï¼Œç”¨äºä¿æŠ¤ speaker_cache çš„å¹¶å‘è®¿é—®
import threading
speaker_cache_lock = threading.Lock()

def get_device(use_gpu=False):
    """è·å–è®¡ç®—è®¾å¤‡"""
    if use_gpu:
        if torch.cuda.is_available():
            selected_device = "cuda"
            print(f"âœ… Using GPU: {torch.cuda.get_device_name(0)}")
            print(f"   CUDA version: {torch.version.cuda}")
            print(f"   PyTorch version: {torch.__version__}")
        else:
            selected_device = "cpu"
            print("âš ï¸  GPU requested but not available, using CPU")
            print("   Check:")
            print("   1. NVIDIA drivers installed")
            print("   2. CUDA toolkit installed")
            print("   3. PyTorch with CUDA support installed")
    else:
        selected_device = "cpu"
        print("â„¹ï¸  Using CPU (GPU not requested)")
    return selected_device

def check_and_install_tts():
    """æ£€æŸ¥å¹¶å®‰è£… TTS æ¨¡å—"""
    try:
        import TTS
        return True
    except ImportError:
        print("âš ï¸  TTS module not found. Attempting to install...")
        try:
            import subprocess
            import sys
            subprocess.check_call([sys.executable, "-m", "pip", "install", "TTS"])
            print("âœ… TTS module installed successfully")
            return True
        except Exception as e:
            print(f"âŒ Failed to install TTS module: {e}")
            print("\nPlease install manually:")
            print("  pip install TTS")
            return False

def load_model(model_path, device="cpu"):
    """åŠ è½½ YourTTS æ¨¡å‹"""
    global tts_model
    
    # æ£€æŸ¥å¹¶å®‰è£… TTS æ¨¡å—
    if not check_and_install_tts():
        raise ImportError("TTS module is required but not available")
    
    try:
        from TTS.api import TTS
        
        print(f"ğŸ“ Loading YourTTS model from: {model_path}")
        print(f"ğŸ”§ Device: {device}")
        
        # æ¨¡å‹å¿…é¡»ä»æ¨¡å‹åº“ä¸‹è½½ï¼Œä¸å…è®¸è‡ªåŠ¨ä¸‹è½½
        # æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
        if model_path is None:
            raise FileNotFoundError(
                "Model path not provided. "
                "Please download models from the model hub first. "
                "Models should be in: model-hub/models/tts/your_tts"
            )
        
        model_path_obj = Path(model_path) if not isinstance(model_path, Path) else model_path
        
        if not model_path_obj.exists():
            raise FileNotFoundError(
                f"Model path not found: {model_path_obj}\n"
                "Please download models from the model hub first. "
                "Models should be in: model-hub/models/tts/your_tts"
            )
        
        # æ£€æŸ¥å¿…éœ€çš„æ–‡ä»¶
        if not model_path_obj.is_dir():
            raise ValueError(f"Model path must be a directory: {model_path_obj}")
        
        config_file = model_path_obj / "config.json"
        model_file = model_path_obj / "model.pth"
        
        if not config_file.exists():
            raise FileNotFoundError(
                f"Config file not found: {config_file}\n"
                "Please ensure the model is correctly downloaded from the model hub."
            )
        
        if not model_file.exists():
            raise FileNotFoundError(
                f"Model checkpoint not found: {model_file}\n"
                "Please ensure the model is correctly downloaded from the model hub."
            )
        
        # è®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨è‡ªåŠ¨ä¸‹è½½
        model_path_str = str(model_path_obj.absolute())
        os.environ["TTS_OFFLINE"] = "1"  # ç¦ç”¨åœ¨çº¿åŠŸèƒ½
        
        print(f"  Config file: {config_file}")
        print(f"  Model checkpoint: {model_file}")
        print(f"  Model directory: {model_path_str}")
        
        # æŒ‰ç…§åŸé¡¹ç›®çš„æ–¹å¼åŠ è½½æ¨¡å‹ï¼Œä½†ç¡®ä¿ä¸è§¦å‘è‡ªåŠ¨ä¸‹è½½
        # æ–¹å¼1ï¼šå°è¯•ä½¿ç”¨æ¨¡å‹è·¯å¾„ç›´æ¥åŠ è½½ï¼ˆæ¨èï¼Œç›´æ¥ä½¿ç”¨ model-hub ä¸­çš„æ¨¡å‹ï¼‰
        try:
            tts_model = TTS(model_path=model_path_str, progress_bar=False, gpu=(device == "cuda"))
            print("âœ… YourTTS model loaded via TTS API (using model path from model-hub)")
        except Exception as e1:
            # æ–¹å¼2ï¼šå¦‚æœæ–¹å¼1å¤±è´¥ï¼Œä½¿ç”¨ Synthesizer API ç›´æ¥åŠ è½½æœ¬åœ°æ–‡ä»¶
            # è¿™æ ·å¯ä»¥ç¡®ä¿ä¸ä¼šè§¦å‘è‡ªåŠ¨ä¸‹è½½ï¼Œç›´æ¥ä½¿ç”¨ model-hub ä¸­çš„æ¨¡å‹æ–‡ä»¶
            print(f"âš ï¸  TTS API loading from path failed: {e1}")
            print("âš ï¸  Trying to load using Synthesizer API with explicit file paths...")
            print("âš ï¸  This method directly loads local files and will NOT trigger downloads")
            
            try:
                from TTS.utils.synthesizer import Synthesizer
                
                # Synthesizer API çš„ tts_checkpoint å‚æ•°å¯èƒ½éœ€è¦ç›®å½•è·¯å¾„
                # æ ¹æ®é”™è¯¯ä¿¡æ¯ï¼Œå®ƒå¯èƒ½åœ¨ checkpoint è·¯å¾„åé¢è¿½åŠ  model.pth
                # æ‰€ä»¥ä¼ é€’ç›®å½•è·¯å¾„ï¼Œè®©å®ƒåœ¨ç›®å½•ä¸­æŸ¥æ‰¾ model.pth
                print(f"  Attempting to load with directory path: {model_path_str}")
                tts_model = Synthesizer(
                    tts_checkpoint=str(model_path_str),  # ä½¿ç”¨ç›®å½•è·¯å¾„ï¼ŒSynthesizer ä¼šåœ¨é‡Œé¢æ‰¾ model.pth
                    tts_config_path=str(config_file),
                    use_cuda=(device == "cuda")
                )
                print("âœ… YourTTS model loaded using Synthesizer API (direct file loading, no download)")
            except Exception as e2:
                error_msg = str(e2)
                # å¦‚æœé‡åˆ° transformers ç‰ˆæœ¬é—®é¢˜
                if "BeamSearchScorer" in error_msg or "cannot import name" in error_msg:
                    print("  âš ï¸  transformers version compatibility issue detected")
                    print("  TTS library requires transformers<=4.42.4 (current version may be too new)")
                    print("  Please downgrade transformers: pip install 'transformers>=4.21.0,<=4.42.4'")
                    raise RuntimeError(
                        f"transformers library version incompatibility: {e2}\n"
                        f"TTS library is not compatible with transformers>4.42.4\n"
                        f"Please run: pip install 'transformers>=4.21.0,<=4.42.4'\n"
                        f"Then restart the service."
                    )
                else:
                    raise RuntimeError(
                        f"Failed to load YourTTS model using both methods.\n"
                        f"Method 1 (TTS API with model_path) error: {e1}\n"
                        f"Method 2 (Synthesizer API with explicit paths) error: {e2}\n"
                        f"Model directory: {model_path_str}\n"
                        f"Config file: {config_file}\n"
                        f"Model checkpoint: {model_file}\n"
                        f"Please ensure all model files are correctly downloaded from the model hub."
                    )
        
        # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆå¦‚æœ TTS API æ²¡æœ‰è‡ªåŠ¨å¤„ç†ï¼‰
        if hasattr(tts_model, 'to') and device == "cuda":
            try:
                tts_model = tts_model.to(device)
                print(f"âœ… Model moved to {device}")
            except Exception as e:
                print(f"âš ï¸  Warning: Failed to move model to {device}: {e}")
                print("   Model may still work on CPU")
        
        print(f"âœ… YourTTS model loaded successfully")
        print(f"   Device: {device}")
        print(f"   Supports zero-shot: Yes")
        
        return tts_model
    except Exception as e:
        print(f"âŒ Failed to load model: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    with speaker_cache_lock:
        cache_size = len(speaker_cache)
    return jsonify({
        "status": "ok",
        "model_loaded": tts_model is not None,
        "device": device,
        "cached_speakers": cache_size
    })

@app.route('/register_speaker', methods=['POST'])
def register_speaker():
    """æ³¨å†Œè¯´è¯è€…ï¼ˆå¼‚æ­¥æ¥æ”¶ reference_audioï¼‰"""
    try:
        data = request.json
        if data is None:
            return jsonify({"error": "Invalid JSON"}), 400
        
        speaker_id = data.get('speaker_id')
        if not speaker_id:
            return jsonify({"error": "Missing 'speaker_id' field"}), 400
        
        reference_audio = data.get('reference_audio')
        if not reference_audio:
            return jsonify({"error": "Missing 'reference_audio' field"}), 400
        
        reference_sample_rate = data.get('reference_sample_rate', 16000)
        voice_embedding = data.get('voice_embedding')  # å¯é€‰
        
        # å°†å‚è€ƒéŸ³é¢‘è½¬æ¢ä¸º numpy æ•°ç»„
        ref_audio_array = np.array(reference_audio, dtype=np.float32)
        
        # YourTTS éœ€è¦ 22050 Hz çš„å‚è€ƒéŸ³é¢‘ï¼Œé¢„å…ˆé‡é‡‡æ ·
        target_sample_rate = 22050
        if reference_sample_rate != target_sample_rate:
            num_samples = int(len(ref_audio_array) * target_sample_rate / reference_sample_rate)
            ref_audio_array = signal.resample(ref_audio_array, num_samples)
            print(f"[YourTTS Service] Resampled reference audio from {reference_sample_rate} Hz to {target_sample_rate} Hz for speaker {speaker_id}")
        
        # ä¿å­˜ voice_embeddingï¼ˆå¦‚æœæä¾›ï¼‰
        embedding_array = None
        if voice_embedding:
            embedding_array = np.array(voice_embedding, dtype=np.float32)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        with speaker_cache_lock:
            speaker_cache[speaker_id] = {
                "reference_audio": ref_audio_array,
                "sample_rate": target_sample_rate,
                "voice_embedding": embedding_array
            }
            cache_size = len(speaker_cache)
        
        print(f"[YourTTS Service] âœ… Registered speaker '{speaker_id}' (reference_audio: {len(ref_audio_array)} samples @ {target_sample_rate} Hz, cache size: {cache_size})")
        
        return jsonify({
            "status": "ok",
            "speaker_id": speaker_id,
            "message": "Speaker registered successfully",
            "cache_size": cache_size
        })
    
    except Exception as e:
        print(f"[YourTTS Service] âŒ Failed to register speaker: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

@app.route('/synthesize', methods=['POST'])
def synthesize():
    """è¯­éŸ³åˆæˆï¼ˆæ”¯æŒ zero-shotï¼‰"""
    try:
        data = request.json
        if data is None:
            return jsonify({"error": "Invalid JSON"}), 400
        
        if 'text' not in data:
            return jsonify({"error": "Missing 'text' field"}), 400
        
        text = data['text']
        speaker_id = data.get('speaker_id')
        reference_audio = data.get('reference_audio')
        reference_sample_rate = data.get('reference_sample_rate', 16000)
        voice_embedding = data.get('voice_embedding')
        speaker = data.get('speaker')
        language = data.get('language', 'en')
        speech_rate = data.get('speech_rate')
        
        if not text or len(text.strip()) == 0:
            return jsonify({"error": "Empty text"}), 400
        
        if tts_model is None:
            return jsonify({"error": "Model not loaded"}), 500
        
        # å‡†å¤‡å‚è€ƒéŸ³é¢‘
        speaker_wav = None
        cached_ref_audio = None
        cached_sample_rate = None
        
        if speaker_id:
            with speaker_cache_lock:
                cached_entry = speaker_cache.get(speaker_id)
                if cached_entry:
                    cached_ref_audio = cached_entry["reference_audio"]
                    cached_sample_rate = cached_entry["sample_rate"]
                    print(f"[YourTTS Service] âœ… Using cached reference_audio for speaker_id '{speaker_id}'")
        
        use_cached = cached_ref_audio is not None
        ref_audio_to_use = cached_ref_audio if use_cached else reference_audio
        ref_sample_rate_to_use = cached_sample_rate if use_cached else reference_sample_rate
        
        try:
            if ref_audio_to_use is not None:
                if use_cached:
                    ref_audio_array = ref_audio_to_use
                else:
                    ref_audio_array = np.array(ref_audio_to_use, dtype=np.float32)
                
                target_sample_rate = 22050
                if not use_cached and ref_sample_rate_to_use != target_sample_rate:
                    num_samples = int(len(ref_audio_array) * target_sample_rate / ref_sample_rate_to_use)
                    ref_audio_array = signal.resample(ref_audio_array, num_samples)
                
                tmp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
                tmp_file.close()
                try:
                    sf.write(tmp_file.name, ref_audio_array, target_sample_rate)
                    speaker_wav = tmp_file.name
                except Exception as e:
                    if os.path.exists(tmp_file.name):
                        os.unlink(tmp_file.name)
                    raise
            
            # åˆæˆè¯­éŸ³
            if speaker_wav:
                wav = tts_model.tts(
                    text=text,
                    speaker_wav=speaker_wav,
                    language=language
                )
            elif speaker:
                wav = tts_model.tts(
                    text=text,
                    speaker=speaker,
                    language=language
                )
            else:
                # ä½¿ç”¨é»˜è®¤è¯´è¯è€…
                wav = tts_model.tts(
                    text=text,
                    language=language
                )
        finally:
            if speaker_wav and os.path.exists(speaker_wav):
                try:
                    os.unlink(speaker_wav)
                except Exception as e:
                    print(f"Warning: Failed to delete temp file {speaker_wav}: {e}")
        
        # è½¬æ¢ä¸ºåˆ—è¡¨
        if isinstance(wav, np.ndarray):
            audio_list = [float(x) for x in wav.flatten()]
        elif isinstance(wav, torch.Tensor):
            audio_array = wav.cpu().numpy()
            audio_list = [float(x) for x in audio_array.flatten()]
        else:
            audio_list = [float(x) for x in wav]
        
        used_reference = speaker_wav is not None
        
        return jsonify({
            "audio": audio_list,
            "sample_rate": 22050,
            "text": text,
            "used_reference": used_reference,
            "speaker_applied": used_reference
        })
        
    except Exception as e:
        import traceback
        error_msg = str(e)
        traceback.print_exc()
        return jsonify({
            "error": error_msg,
            "type": type(e).__name__
        }), 500

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="YourTTS HTTP Service")
    parser.add_argument('--gpu', action='store_true', help='Use GPU if available')
    parser.add_argument('--port', type=int, default=5004, help='Server port (default: 5004)')
    parser.add_argument('--host', type=str, default='127.0.0.1', help='Server host (default: 127.0.0.1)')
    parser.add_argument('--model-dir', type=str, help='Model directory path')
    args = parser.parse_args()
    
    print("=" * 60)
    print("  YourTTS HTTP Service (Zero-shot TTS)")
    print("=" * 60)
    
    # ç¡®å®šæ¨¡å‹è·¯å¾„ï¼ˆå‚è€ƒåŸé¡¹ç›®ï¼‰
    # æ¨¡å‹å¿…é¡»ä»æ¨¡å‹åº“ä¸‹è½½ï¼Œä¸å…è®¸è‡ªåŠ¨ä¸‹è½½
    if args.model_dir:
        model_path = Path(args.model_dir)
    else:
        # é»˜è®¤ä½¿ç”¨é¡¹ç›®ä¸­çš„æ¨¡å‹è·¯å¾„ï¼ˆä¼˜å…ˆä½¿ç”¨ node-inferenceï¼Œè¿™æ˜¯èŠ‚ç‚¹æœ¬åœ°æ¨¡å‹åº“ï¼‰
        model_path = project_root / "node-inference" / "models" / "tts" / "your_tts"
        if not model_path.exists():
            model_path = project_root / "model-hub" / "models" / "tts" / "your_tts"
    
    # éªŒè¯æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not model_path.exists():
        print(f"âŒ Error: Model path not found: {model_path}")
        print("")
        print("Please download models from the model hub first:")
        print("  1. Start the model hub service: .\\scripts\\start_model_hub.ps1")
        print("  2. Download YourTTS models through the model hub")
        print("  3. Ensure models are in: model-hub/models/tts/your_tts")
        print("")
        sys.exit(1)
    
    # è·å–è®¾å¤‡ï¼ˆåœ¨æ¨¡å—çº§åˆ«ï¼Œä¸éœ€è¦ global å£°æ˜ï¼‰
    device = get_device(args.gpu)
    
    # åŠ è½½æ¨¡å‹ï¼ˆload_model å‡½æ•°å†…éƒ¨ä¼šå¤„ç†è·¯å¾„ä¸å­˜åœ¨çš„æƒ…å†µï¼‰
    try:
        load_model(model_path, device)
    except Exception as e:
        print(f"\nâŒ Failed to start service: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    print(f"\nğŸš€ Starting server on http://{args.host}:{args.port}")
    print("   Endpoints:")
    print("     GET  /health          - Health check")
    print("     POST /synthesize      - Synthesize speech (zero-shot supported)")
    print("     POST /register_speaker - Register speaker")
    print(f"   Device: {device}")
    print("\n   Press Ctrl+C to stop")
    print("=" * 60)
    
    app.run(host=args.host, port=args.port, debug=False)
