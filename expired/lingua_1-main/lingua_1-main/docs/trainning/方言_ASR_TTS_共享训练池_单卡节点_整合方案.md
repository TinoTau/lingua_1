# 方言 ASR / TTS 训练方案（共享训练池 + 单卡节点）决策整合版

## 1. 前提与共识（来自讨论结论）

- 训练文本为**固定脚本、照本宣科**，不涉及真实对话内容  
- 用户日常贡献极少（1–2 句录音，10–20 句互评）  
- 节点端为**个人 PC，单机单卡**，训练 job 以 **1 小时 timebox** 为单位  
- 公司服务器 **仅负责任务调度、聚合、门禁与版本发布**，不承担 GPU 训练  
- 不采用“可逆加噪”方案，不将其视为水印或隐私保护手段  

结论：  
**隐私风险在当前场景下为低优先级，真正的系统风险集中在：**
1. TTS 训练数据质量不足  
2. 训练结果刷奖励 / 投毒  
3. 算力利用效率与失败止损  

---

## 2. 总体架构原则

### 2.1 训练模式
- 共享训练池（非单用户私有）
- 多节点并行贡献
- 中心侧做 **轻量聚合 + 强门禁**

### 2.2 模型形式
- 基座模型固定
- 仅训练 **LoRA / Adapter**
- 节点只上传 Adapter，不上传全量模型

---

## 3. 数据池分层设计（核心）

在同一个 dialect_id 内，建立三层数据池：

### T0：拒收池
- 自动 QC 或互评不通过
- 不参与任何训练

### T1：可用训练池（ASR 优先）
- 内容对齐基本正确
- 音质一般
- 主要用于 ASR 方言适配

### T2：高质量 TTS 池（严格）
- 内容对齐高
- 方言纯度高
- 音质可用性高
- **仅 T2 数据允许用于 TTS 训练**

---

## 4. 自动 QC（最低成本、必须实现）

### 4.1 硬门禁（直接拒收）
- 采样率不合规
- 时长异常（<1.5s 或 >15s）
- 静音比例过高
- 明显 clipping
- SNR 过低

### 4.2 软门禁（影响分层）
- 混响过强
- 音量波动过大
- 背景人声/音乐

示例分层：
- quality_score ≥ 0.85 → T2
- 0.65–0.85 → T1
- <0.65 → T0

---

## 5. 互评机制补充（为 TTS 服务）

在现有互评维度上，**必须增加一项**：

- 音质可用性（TTS）

T2 池建议准入条件：
- 内容匹配 ≥ 4/5
- 方言纯度 ≥ 4/5
- 音质可用性 ≥ 4/5
- 评分人数 ≥ 5（加权）

---

## 6. 脚本文本设计要求（经常被忽略但极关键）

- 覆盖主要音素/声调组合
- 句长稳定（4–12 秒为主）
- 避免复杂数字、外来词
- 标点与断句规范化
- 避免过长段落（降低疲劳与音质下降）

---

## 7. 训练 Job 设计（1 小时时间盒）

### 7.1 Job 输入
- dialect_id
- dataset_version（manifest + shard）
- base_model_version
- adapter_version
- timebox = 3600s
- resource_profile

### 7.2 Job 输出
- adapter / LoRA 权重
- 训练指标（loss、吞吐）
- data_used_summary

### 7.3 训练链
- 多个 1h job 串成一条 run
- 每 6–12 个 job 才产生候选版本

---

## 8. TTS 专属止损机制（必须）

每个 1h job 结束后：
1. 固定测试文本合成
2. ASR 反识别校验内容
3. 检测爆音/静音/异常频谱

不通过 → 立即停止该训练链

---

## 9. 调度侧最低治理要求（反刷奖励 / 投毒）

- Adapter 结构与统计检查
- 快速评估门禁（CER/WER 或可用性）
- 节点信誉与配额
- 低信誉节点结果仅进入实验分支

---

## 10. 安全与隐私的现实取舍结论

- 不采用加噪/可逆遮蔽
- 不把短句朗读当高隐私内容
- 仅保留：
  - TLS
  - 短期下载凭证（TTL）
  - 最小分片
  - 规则治理

---

## 11. 实施优先级建议

1. ASR：T1 数据池 + LoRA 微调（先闭环）
2. TTS：T2 数据池 + 严格门禁 + 小规模训练
3. 再逐步扩大共享训练池规模

---

## 12. 决策总结（一句话）

> **在共享训练池 + 单卡节点条件下，  
> 能否训练出可用的方言 TTS，  
> 不取决于算力，而取决于数据分层与质量门禁是否足够严格。**
