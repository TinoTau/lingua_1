# 文本去重功能增强

**日期**: 2025-12-25  
**状态**: ✅ **已增强**

---

## 问题描述

用户报告的ASR识别结果问题：

```
现在让我们来试试看大模型的功能

已经上下温功能有没有生效

上下温功能有没有生效?

上下温功能有没有生效? 上下温功能有没有生效?

刚才出现了一些问题 导致没有办法播

那些问题 导致没有办法播

但是现在应该会好一点 这是

至少服务部还会报错崩溃了

我还会报错崩溃了

我还会报错崩溃了
```

**问题**:
1. 单个utterance内的重复（例如："上下温功能有没有生效? 上下温功能有没有生效?"）
2. 开头和结尾的重复（例如："导致没有办法播 那些问题 导致没有办法播"）
3. 多个utterance之间的重复（例如："我还会报错崩溃了" 出现多次）

---

## 增强内容

### 新增方法3：检测开头和结尾的重复

**问题场景**: 
- 输入: `"导致没有办法播 那些问题 导致没有办法播"`
- 原去重逻辑: 无法处理（因为中间有"那些问题"）
- 新去重逻辑: 检测到开头和结尾都是"导致没有办法播"，移除结尾的重复

**实现逻辑**:
```python
# 方法3：检测开头和结尾的重复
# 检查文本开头和结尾是否有相同的短语（允许中间有其他文本）
for phrase_len in range(min(15, text_len // 2), 2, -1):
    start_phrase = text_trimmed[:phrase_len]
    end_phrase = text_trimmed[-phrase_len:]
    
    if start_phrase == end_phrase and text_len > phrase_len * 2:
        # 移除结尾的重复短语
        text_trimmed = text_trimmed[:-phrase_len].rstrip()
        return deduplicate_text(text_trimmed, trace_id)
```

---

## 测试结果

### 增强前

```python
输入: "导致没有办法播 那些问题 导致没有办法播"
输出: "导致没有办法播 那些问题 导致没有办法播"  # ❌ 未去重
```

### 增强后

```python
输入: "导致没有办法播 那些问题 导致没有办法播"
输出: "导致没有办法播 那些问题"  # ✅ 已去重

输入: "我还会报错崩溃了 我还会报错崩溃了"
输出: "我还会报错崩溃了"  # ✅ 已去重

输入: "上下温功能有没有生效? 上下温功能有没有生效?"
输出: "上下温功能有没有生效?"  # ✅ 已去重
```

---

## 去重方法总结

### 方法1：完全重复检测
- **场景**: `"这边能不能用这边能不能用"` → `"这边能不能用"`
- **支持**: 多重重复（例如："测试测试测试" → "测试"）

### 方法2：相邻重复检测
- **场景**: `"这个地方我觉得还行这个地方我觉得还行"` → `"这个地方我觉得还行"`
- **支持**: 允许中间有空格

### 方法3：开头结尾重复检测（新增）
- **场景**: `"导致没有办法播 那些问题 导致没有办法播"` → `"导致没有办法播 那些问题"`
- **支持**: 允许中间有其他文本

---

## 限制

### 当前无法处理的场景

1. **跨utterance的重复**:
   - 问题: 多个utterance返回了相同的文本
   - 示例: 
     - Utterance 1: "我还会报错崩溃了"
     - Utterance 2: "我还会报错崩溃了"
   - 当前处理: 每个utterance单独去重，但不会跨utterance去重
   - 建议: 如果需要，可以在Web端添加去重逻辑

2. **部分重叠的重复**:
   - 问题: 文本部分重叠但不在开头或结尾
   - 示例: `"测试A测试B测试A"`（中间的"测试A"和结尾的"测试A"重复）
   - 当前处理: 可能无法完全去重

---

## 架构原则

### 去重逻辑完全在服务端完成 ✅

**决定**: **不在Web端添加去重逻辑**

**原因**:
- 去重逻辑应该在服务端完成，保持架构清晰
- Web端只负责显示服务端返回的结果
- 如果多个utterance返回了相同的文本，这是正常的（用户可能确实说了相同的话）

**服务端去重流程**:
1. Step 9.2: 对ASR识别结果进行去重处理
2. Step 11: 使用去重后的文本更新上下文缓存
3. 返回去重后的文本给Web端

### 继续优化去重算法（可选）

如果需要处理更复杂的重复模式，可以：
- 添加模糊匹配（允许少量字符差异）
- 优化开头结尾重复检测的准确性
- 添加部分重叠的重复检测

---

## 验证

运行单元测试验证增强后的去重功能：

```bash
python test_text_deduplicator.py
```

**预期结果**: 所有测试通过 ✅

---

## 相关文档

- [文本去重测试报告](./TEXT_DEDUPLICATOR_TEST_REPORT.md)
- [上下文重复问题说明](./CONTEXT_DUPLICATE_ISSUE_EXPLANATION.md)

