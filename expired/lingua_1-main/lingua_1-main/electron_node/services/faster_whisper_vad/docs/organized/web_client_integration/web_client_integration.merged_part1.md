# Web Client Integration (Part 1/2)

# Web Client Integration

æœ¬æ–‡æ¡£åˆå¹¶äº†æ‰€æœ‰ç›¸å…³æ–‡æ¡£ã€‚

---

## WEB_CLIENT_AUDIO_BUFFER_AND_ASR_CONTEXT_ISSUES.md

# Webç«¯éŸ³é¢‘ç¼“å­˜å’ŒASRä¸Šä¸‹æ–‡é—®é¢˜åˆ†æ

**æ—¥æœŸ**: 2025-12-25  
**çŠ¶æ€**: ğŸ” **é—®é¢˜åˆ†æä¸­**

---

## é—®é¢˜æè¿°

ç”¨æˆ·åé¦ˆï¼š
1. **Webç«¯æ²¡æœ‰å°†è°ƒåº¦æœåŠ¡å™¨è¿”å›çš„éŸ³é¢‘æ”¾å…¥ç¼“å­˜åŒº**
2. **å¤§é‡å·²ç»è¢«ç¿»è¯‘å¥½çš„å†…å®¹è¢«ä¸¢å¼ƒ**
3. **è¯­éŸ³è¯†åˆ«çš„å‡†ç¡®åº¦éœ€è¦æŸ¥çœ‹ä¸Šä¸‹æ–‡ç›¸å…³çš„æ—¥å¿—**

---

## æ—¥å¿—åˆ†æ

### 1. è°ƒåº¦æœåŠ¡å™¨æ—¥å¿—

**æˆåŠŸå‘é€çš„ç»“æœ**ï¼š
```
"Sending translation result to session (single mode)"
"tts_audio_len=228752"
"Successfully sent translation result to session"
```

**è¢«è·³è¿‡çš„ç©ºç»“æœ**ï¼š
```
"Skipping empty translation result (silence detected), not forwarding to web client"
```

**ç»“æœé˜Ÿåˆ—çŠ¶æ€**ï¼š
```
expected_index=12, queue_size=9, queue_indices=[0, 1, 2, 3, 4, 5, 6, 7, 10]
```

**åˆ†æ**ï¼š
- âœ… è°ƒåº¦æœåŠ¡å™¨æˆåŠŸå‘é€äº†ç¿»è¯‘ç»“æœï¼ˆ`tts_audio_len=228752`ï¼‰
- âš ï¸ æœ‰å¾ˆå¤šç©ºç»“æœè¢«è·³è¿‡ï¼ˆé™éŸ³æ£€æµ‹ï¼‰
- âš ï¸ ç»“æœé˜Ÿåˆ—ä¸­æœ‰ç»“æœä½†æ²¡æœ‰è¢«é‡Šæ”¾ï¼ˆ`expected_index=12`ï¼Œä½†é˜Ÿåˆ—ä¸­åªæœ‰ `[0, 1, 2, 3, 4, 5, 6, 7, 10]`ï¼‰

---

### 2. ASRæœåŠ¡æ—¥å¿—

**ä¸Šä¸‹æ–‡å‚æ•°**ï¼š
```
has_initial_prompt=True, initial_prompt_length=17
initial_prompt_preview='æ´æ—‡éˆå¤Œâ€–é—å›ªæ©æ–¿æ´–æµœ?æµ£å—˜æ§¸æ©æ¨»ç—…éˆå¤‹æ¨‰ç»€?'
condition_on_previous_text=True  # âš ï¸ åº”è¯¥æ˜¯ False
```

**é—®é¢˜**ï¼š
- âš ï¸ `condition_on_previous_text=True` åº”è¯¥è¢«è®¾ç½®ä¸º `False`ï¼Œä»¥é¿å…é‡å¤è¯†åˆ«
- âš ï¸ æ—¥å¿—æ˜¾ç¤ºä¹±ç ï¼Œå¯èƒ½æ˜¯æ—¥å¿—ç¼–ç é—®é¢˜ï¼ˆä½†å®é™…æ•°æ®å¯èƒ½æ˜¯æ­£ç¡®çš„ï¼‰

---

## ä»£ç æ£€æŸ¥

### 1. ASR Worker é»˜è®¤å€¼é—®é¢˜

**æ–‡ä»¶**: `electron_node/services/faster_whisper_vad/asr_worker_process.py`

**é—®é¢˜**ï¼š
```python
condition_on_previous_text = task.get("condition_on_previous_text", True)  # âŒ é»˜è®¤å€¼æ˜¯ True
```

**åº”è¯¥æ”¹ä¸º**ï¼š
```python
condition_on_previous_text = task.get("condition_on_previous_text", False)  # âœ… é»˜è®¤å€¼æ”¹ä¸º False
```

**åŸå› **ï¼š
- `faster_whisper_vad_service.py` ä¸­ `UtteranceRequest.condition_on_previous_text: bool = False`
- ä½†å¦‚æœä»»åŠ¡ä¸­æ²¡æœ‰ä¼ é€’è¿™ä¸ªå‚æ•°ï¼Œ`asr_worker_process.py` ä¼šä½¿ç”¨é»˜è®¤å€¼ `True`
- è¿™ä¼šå¯¼è‡´ ASR é‡å¤è¯†åˆ«é—®é¢˜

---

### 2. Webç«¯éŸ³é¢‘ç¼“å­˜é€»è¾‘

**æ–‡ä»¶**: `webapp/web-client/src/app.ts`

**å½“å‰å®ç°**ï¼š
```typescript
case 'translation_result':
  // æ£€æŸ¥ç»“æœæ˜¯å¦ä¸ºç©º
  if (asrEmpty && translatedEmpty && ttsEmpty) {
    console.log('[App] æ”¶åˆ°ç©ºæ–‡æœ¬ç»“æœï¼ˆé™éŸ³æ£€æµ‹ï¼‰ï¼Œè·³è¿‡ç¼“å­˜å’Œæ’­æ”¾');
    return;  // âŒ ç›´æ¥è¿”å›ï¼Œä¸å¤„ç†
  }
  
  // å¤„ç† TTS éŸ³é¢‘
  if (message.tts_audio && message.tts_audio.length > 0) {
    this.ttsPlayer.addAudioChunk(message.tts_audio, message.utterance_index).then(() => {
      console.log('[App] TTS éŸ³é¢‘å—å·²æ·»åŠ åˆ°ç¼“å†²åŒº');
    });
  }
```

**å¯èƒ½çš„é—®é¢˜**ï¼š
1. **Webç«¯æ²¡æœ‰æ”¶åˆ°æ¶ˆæ¯**ï¼š
   - WebSocket è¿æ¥æ–­å¼€
   - æ¶ˆæ¯è·¯ç”±é”™è¯¯
   - æ¶ˆæ¯è¢«è¿‡æ»¤

2. **æ¶ˆæ¯è¢«è¿‡æ»¤**ï¼š
   - ç©ºç»“æœæ£€æŸ¥ï¼š`if (asrEmpty && translatedEmpty && ttsEmpty)` å¯èƒ½è¿‡äºä¸¥æ ¼
   - ä¼šè¯çŠ¶æ€æ£€æŸ¥ï¼š`if (!this.isSessionActive)` å¯èƒ½è¿‡æ—©ç»“æŸä¼šè¯

3. **éŸ³é¢‘æ·»åŠ å¤±è´¥**ï¼š
   - `addAudioChunk()` æŠ›å‡ºé”™è¯¯ä½†è¢«æ•è·
   - base64 è§£ç å¤±è´¥
   - éŸ³é¢‘æ ¼å¼ä¸åŒ¹é…

---

## ä¿®å¤æ–¹æ¡ˆ

### 1. ä¿®å¤ ASR Worker é»˜è®¤å€¼

**æ–‡ä»¶**: `electron_node/services/faster_whisper_vad/asr_worker_process.py`

**ä¿®æ”¹**ï¼š
```python
condition_on_previous_text = task.get("condition_on_previous_text", False)  # é»˜è®¤å€¼æ”¹ä¸º False
```

---

### 2. å¢å¼º Webç«¯æ—¥å¿—

**æ–‡ä»¶**: `webapp/web-client/src/app.ts`

**æ·»åŠ è¯¦ç»†æ—¥å¿—**ï¼š
```typescript
case 'translation_result':
  console.log('[App] æ”¶åˆ° translation_result æ¶ˆæ¯:', {
    utterance_index: message.utterance_index,
    has_text_asr: !!message.text_asr,
    has_text_translated: !!message.text_translated,
    has_tts_audio: !!message.tts_audio,
    tts_audio_length: message.tts_audio?.length || 0,
    is_session_active: this.isSessionActive
  });
  
  // ... ç°æœ‰é€»è¾‘ ...
  
  if (message.tts_audio && message.tts_audio.length > 0) {
    console.log('[App] å‡†å¤‡æ·»åŠ  TTS éŸ³é¢‘åˆ°ç¼“å†²åŒº:', {
      utterance_index: message.utterance_index,
      base64_length: message.tts_audio.length
    });
    
    this.ttsPlayer.addAudioChunk(message.tts_audio, message.utterance_index)
      .then(() => {
        console.log('[App] âœ… TTS éŸ³é¢‘å—å·²æˆåŠŸæ·»åŠ åˆ°ç¼“å†²åŒº');
      })
      .catch((error) => {
        console.error('[App] âŒ æ·»åŠ  TTS éŸ³é¢‘å—å¤±è´¥:', error);
      });
  } else {
    console.warn('[App] âš ï¸ ç¿»è¯‘ç»“æœä¸­æ²¡æœ‰ TTS éŸ³é¢‘');
  }
```

---

### 3. æ£€æŸ¥ç»“æœé˜Ÿåˆ—é—®é¢˜

**é—®é¢˜**ï¼š`expected_index=12`ï¼Œä½†é˜Ÿåˆ—ä¸­åªæœ‰ `[0, 1, 2, 3, 4, 5, 6, 7, 10]`

**å¯èƒ½çš„åŸå› **ï¼š
- ç»“æœ 8, 9, 11 ä¸¢å¤±æˆ–å»¶è¿Ÿ
- ç»“æœé˜Ÿåˆ—çš„ gap tolerance æœºåˆ¶å¯èƒ½æœ‰é—®é¢˜

**éœ€è¦æ£€æŸ¥**ï¼š
- ç»“æœé˜Ÿåˆ—çš„ `gap_timeout_ms` é…ç½®
- `MissingResult` æ¶ˆæ¯æ˜¯å¦è¢«æ­£ç¡®å¤„ç†

---

## è¯Šæ–­æ­¥éª¤

### 1. æ£€æŸ¥æµè§ˆå™¨æ§åˆ¶å°

**æ‰“å¼€æµè§ˆå™¨å¼€å‘è€…å·¥å…·ï¼ˆF12ï¼‰ï¼ŒæŸ¥çœ‹æ§åˆ¶å°æ—¥å¿—**ï¼š

**é¢„æœŸæ—¥å¿—**ï¼š
```
[App] æ”¶åˆ° translation_result æ¶ˆæ¯: {utterance_index: 10, has_tts_audio: true, ...}
æ”¶åˆ° TTS éŸ³é¢‘ï¼Œç´¯ç§¯åˆ°ç¼“å†²åŒºï¼Œä¸è‡ªåŠ¨æ’­æ”¾ base64é•¿åº¦: 228752
TtsPlayer: æ·»åŠ éŸ³é¢‘å—ï¼Œå½“å‰çŠ¶æ€: input_recording base64é•¿åº¦: 228752 utteranceIndex: 10
TtsPlayer: éŸ³é¢‘å—å·²æ·»åŠ åˆ°ç¼“å†²åŒºï¼Œç¼“å†²åŒºå¤§å°: 1 utteranceIndex: 10
[App] âœ… TTS éŸ³é¢‘å—å·²æˆåŠŸæ·»åŠ åˆ°ç¼“å†²åŒº
```

**å¦‚æœæ²¡æœ‰çœ‹åˆ°è¿™äº›æ—¥å¿—**ï¼š
- âŒ Webç«¯æ²¡æœ‰æ”¶åˆ° `translation_result` æ¶ˆæ¯
- âš ï¸ æ£€æŸ¥ WebSocket è¿æ¥çŠ¶æ€
- âš ï¸ æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦è¢«è¿‡æ»¤

---

### 2. æ£€æŸ¥ ASR ä¸Šä¸‹æ–‡æ—¥å¿—

**æŸ¥çœ‹ ASR æœåŠ¡æ—¥å¿—**ï¼š
```bash
tail -f electron_node/services/faster_whisper_vad/logs/faster-whisper-vad-service.log | grep -i "ASR.*ä¸Šä¸‹æ–‡\|condition_on_previous_text"
```

**é¢„æœŸæ—¥å¿—**ï¼š
```
ASR ä¸Šä¸‹æ–‡å‚æ•°: has_initial_prompt=True, initial_prompt_length=17, condition_on_previous_text=False
```

**å¦‚æœçœ‹åˆ° `condition_on_previous_text=True`**ï¼š
- âŒ ASR Worker é»˜è®¤å€¼é—®é¢˜
- âš ï¸ éœ€è¦ä¿®å¤ `asr_worker_process.py`

---

## ä¸‹ä¸€æ­¥

1. âœ… **ä¿®å¤ ASR Worker é»˜è®¤å€¼**ï¼šå°† `condition_on_previous_text` é»˜è®¤å€¼æ”¹ä¸º `False`
2. â³ **å¢å¼º Webç«¯æ—¥å¿—**ï¼šæ·»åŠ è¯¦ç»†çš„æ¥æ”¶å’Œå¤„ç†æ—¥å¿—
3. â³ **æ£€æŸ¥æµè§ˆå™¨æ§åˆ¶å°**ï¼šç¡®è®¤ Webç«¯æ˜¯å¦æ”¶åˆ°æ¶ˆæ¯
4. â³ **æ£€æŸ¥ç»“æœé˜Ÿåˆ—**ï¼šç¡®è®¤ä¸ºä»€ä¹ˆ `expected_index` ä¸åŒ¹é…



---

## WEB_CLIENT_AUDIO_FORMAT_ANALYSIS.md

# Webç«¯éŸ³é¢‘æ ¼å¼åˆ†æ

**æ—¥æœŸ**: 2025-12-24  
**é—®é¢˜**: Webç«¯å‘é€ä¸¤ç§ä¸åŒæ ¼å¼çš„éŸ³é¢‘æ•°æ®  
**çŠ¶æ€**: âœ… **é—®é¢˜å·²å®šä½**

---

## æ ¸å¿ƒå‘ç°

### Webç«¯ä½¿ç”¨ä¸¤ç§æ¶ˆæ¯ç±»å‹

1. **`audio_chunk`æ¶ˆæ¯**ï¼ˆæµå¼å‘é€ï¼‰
   - ä½¿ç”¨`sendAudioChunk()`æ–¹æ³•
   - åœ¨å½•éŸ³è¿‡ç¨‹ä¸­æŒç»­å‘é€éŸ³é¢‘å—
   - **é—®é¢˜**ï¼šä½¿ç”¨`encode()`æ–¹æ³•ï¼Œç”Ÿæˆ**è¿ç»­å­—èŠ‚æµ**ï¼ˆépacketæ ¼å¼ï¼‰

2. **`utterance`æ¶ˆæ¯**ï¼ˆä¸€æ¬¡æ€§å‘é€ï¼‰
   - ä½¿ç”¨`sendUtterance()`æ–¹æ³•
   - åœ¨ç”¨æˆ·åœæ­¢è¯´è¯æ—¶å‘é€å®Œæ•´éŸ³é¢‘
   - **æ­£ç¡®**ï¼šä½¿ç”¨`encodePackets()`æ–¹æ³•ï¼Œç”Ÿæˆ**packetæ ¼å¼**

---

## ä»£ç åˆ†æ

### 1. Webç«¯å‘é€é€»è¾‘

#### `sendAudioChunk()` - æµå¼å‘é€ï¼ˆâŒ é—®é¢˜ï¼‰

**æ–‡ä»¶**: `webapp/web-client/src/websocket_client.ts`

```typescript
// ç¬¬662è¡Œï¼šsendAudioChunkJSON()
private async sendAudioChunkJSON(audioData: Float32Array, isFinal: boolean = false) {
  if (this.audioEncoder && this.audioCodecConfig?.codec === 'opus') {
    // âŒ ä½¿ç”¨ encode() æ–¹æ³•ï¼Œç”Ÿæˆè¿ç»­å­—èŠ‚æµ
    encodedAudio = await this.audioEncoder.encode(audioData);
  }
  
  const message: AudioChunkMessage = {
    type: 'audio_chunk',
    session_id: this.sessionId,
    seq: this.sequence++,
    is_final: isFinal,
    payload: base64,  // è¿ç»­å­—èŠ‚æµï¼Œépacketæ ¼å¼
  };
}
```

**é—®é¢˜**ï¼š
- ä½¿ç”¨`encode()`æ–¹æ³•ï¼Œå°†æ‰€æœ‰éŸ³é¢‘å¸§åˆå¹¶æˆè¿ç»­å­—èŠ‚æµ
- æ²¡æœ‰ä½¿ç”¨`encodePackets()`æ–¹æ³•
- æ²¡æœ‰æ·»åŠ packeté•¿åº¦å‰ç¼€

#### `sendUtterance()` - ä¸€æ¬¡æ€§å‘é€ï¼ˆâœ… æ­£ç¡®ï¼‰

**æ–‡ä»¶**: `webapp/web-client/src/websocket_client.ts`

```typescript
// ç¬¬775è¡Œï¼šsendUtterance()
async sendUtterance(audioData: Float32Array, ...) {
  if (encoder.encodePackets && typeof encoder.encodePackets === 'function') {
    // âœ… ä½¿ç”¨ encodePackets() æ–¹æ³•ï¼Œç”Ÿæˆpacketæ•°ç»„
    opusPackets = await encoder.encodePackets(audioData);
    
    // âœ… ä¸ºæ¯ä¸ªpacketæ·»åŠ é•¿åº¦å‰ç¼€ï¼ˆPlan Aæ ¼å¼ï¼‰
    for (const packet of opusPackets) {
      const lenBuffer = new ArrayBuffer(2);
      const lenView = new DataView(lenBuffer);
      lenView.setUint16(0, packet.length, true); // little-endian
      // ...
    }
  }
}
```

**æ­£ç¡®**ï¼š
- ä½¿ç”¨`encodePackets()`æ–¹æ³•ï¼Œç”Ÿæˆpacketæ•°ç»„
- ä¸ºæ¯ä¸ªpacketæ·»åŠ é•¿åº¦å‰ç¼€ï¼ˆPlan Aæ ¼å¼ï¼‰

---

### 2. è°ƒåº¦æœåŠ¡å™¨å¤„ç†é€»è¾‘

#### `audio_chunk`æ¶ˆæ¯å¤„ç†

**æ–‡ä»¶**: `central_server/scheduler/src/websocket/session_actor/actor.rs`

```rust
// ç¬¬197è¡Œï¼šhandle_audio_chunk()
async fn handle_audio_chunk(&mut self, chunk: Vec<u8>, ...) {
  // æ·»åŠ éŸ³é¢‘å—åˆ°ç¼“å†²åŒº
  self.state.audio_buffer.add_chunk(&self.session_id, utterance_index, chunk).await;
  
  // å¦‚æœæ˜¯æœ€ç»ˆå—ï¼Œç«‹å³ finalize
  if is_final {
    self.try_finalize(utterance_index, "IsFinal").await?;
  }
}
```

**å¤„ç†æµç¨‹**ï¼š
1. æ¥æ”¶`audio_chunk`æ¶ˆæ¯
2. Base64è§£ç å¾—åˆ°`chunk: Vec<u8>`
3. æ·»åŠ åˆ°`audio_buffer`ï¼ˆç®€å•ç´¯ç§¯ï¼‰
4. åœ¨finalizeæ—¶ï¼Œ`audio_buffer.get_combined()`åˆå¹¶æ‰€æœ‰chunk
5. åˆ›å»ºjobå¹¶å‘é€ç»™èŠ‚ç‚¹

**é—®é¢˜**ï¼š
- `audio_buffer.get_combined()`åªæ˜¯ç®€å•è¿æ¥chunkï¼š`combined.extend_from_slice(chunk)`
- å¦‚æœchunkæ˜¯è¿ç»­å­—èŠ‚æµï¼Œåˆå¹¶åä»ç„¶æ˜¯è¿ç»­å­—èŠ‚æµ
- **æ²¡æœ‰packetæ ¼å¼ä¿¡æ¯**

#### `utterance`æ¶ˆæ¯å¤„ç†

**æ–‡ä»¶**: `central_server/scheduler/src/websocket/session_message_handler/utterance.rs`

```rust
// ç¬¬9è¡Œï¼šhandle_utterance()
pub(super) async fn handle_utterance(..., audio: String, ...) {
  // è§£ç éŸ³é¢‘
  let audio_data = general_purpose::STANDARD.decode(&audio)?;
  
  // ç›´æ¥åˆ›å»ºjobï¼ˆä¸ç»è¿‡audio_bufferï¼‰
  let jobs = create_translation_jobs(..., audio_data, ...).await?;
}
```

**å¤„ç†æµç¨‹**ï¼š
1. æ¥æ”¶`utterance`æ¶ˆæ¯
2. Base64è§£ç å¾—åˆ°`audio_data: Vec<u8>`
3. **ç›´æ¥åˆ›å»ºjob**ï¼ˆä¸ç»è¿‡`audio_buffer`ï¼‰
4. å‘é€ç»™èŠ‚ç‚¹

**æ­£ç¡®**ï¼š
- æ•°æ®ç›´æ¥ä¼ é€’ï¼Œä¸ç»è¿‡åˆå¹¶
- å¦‚æœWebç«¯å‘é€çš„æ˜¯packetæ ¼å¼ï¼ŒèŠ‚ç‚¹ç«¯æ¥æ”¶åˆ°çš„ä¹Ÿæ˜¯packetæ ¼å¼

---

### 3. åŸnode-inferenceå¤„ç†æ–¹å¼

**æ–‡ä»¶**: `electron_node/services/node-inference/src/audio_codec.rs`

```rust
// ç¬¬42è¡Œï¼šOpusDecoder::decode()
pub fn decode(&mut self, opus_data: &[u8]) -> Result<Vec<u8>> {
  // å°è¯•è§£ç æ•´ä¸ªæ•°æ®å—ï¼ˆå¦‚æœæ•°æ®æ˜¯å•ä¸ªå¸§ï¼‰
  match self.decoder.decode(opus_data, &mut pcm_buffer, false) {
    Ok(decoded_samples) => {
      // æˆåŠŸè§£ç 
    }
    Err(e) => {
      // å¦‚æœæ•´ä½“è§£ç å¤±è´¥ï¼Œå°è¯•åˆ†å¸§è§£ç ï¼ˆç®€åŒ–å¤„ç†ï¼šå‡è®¾æ¯å¸§æœ€å¤§ 400 å­—èŠ‚ï¼‰
      let mut offset = 0;
      while offset < opus_data.len() {
        let chunk_size = std::cmp::min(400, opus_data.len() - offset);
        let chunk = &opus_data[offset..offset + chunk_size];
        // å°è¯•è§£ç chunk
      }
    }
  }
}
```

**ç‰¹ç‚¹**ï¼š
- ä½¿ç”¨`opus-rs`åº“ï¼Œå¯ä»¥å¤„ç†è¿ç»­å­—èŠ‚æµ
- å…ˆå°è¯•æ•´ä½“è§£ç ï¼Œå¤±è´¥ååˆ†å¸§è§£ç ï¼ˆæ¯å¸§æœ€å¤§400å­—èŠ‚ï¼‰
- **ä¸ä¾èµ–packetæ ¼å¼**ï¼Œå¯ä»¥å¤„ç†è¿ç»­å­—èŠ‚æµï¼ˆè™½ç„¶ä¸å®Œç¾ï¼‰

---

## é—®é¢˜æ ¹æº

### é—®é¢˜1: Webç«¯`sendAudioChunk()`æ²¡æœ‰ä½¿ç”¨Plan Aæ ¼å¼

**åŸå› **ï¼š
- `sendAudioChunk()`ä½¿ç”¨`encode()`æ–¹æ³•ï¼Œç”Ÿæˆè¿ç»­å­—èŠ‚æµ
- æ²¡æœ‰ä½¿ç”¨`encodePackets()`æ–¹æ³•
- æ²¡æœ‰æ·»åŠ packeté•¿åº¦å‰ç¼€

**å½±å“**ï¼š
- `audio_chunk`æ¶ˆæ¯ â†’ `audio_buffer` â†’ finalize â†’ åˆ›å»ºjob
- èŠ‚ç‚¹ç«¯æ¥æ”¶åˆ°çš„æ˜¯è¿ç»­å­—èŠ‚æµï¼Œæ— æ³•æ£€æµ‹åˆ°packetæ ¼å¼
- æœåŠ¡ç«¯å°è¯•è¿ç»­å­—èŠ‚æµè§£ç ï¼Œå¤±è´¥

### é—®é¢˜2: è°ƒåº¦æœåŠ¡å™¨`audio_buffer`åˆå¹¶é€»è¾‘

**åŸå› **ï¼š
- `audio_buffer.get_combined()`åªæ˜¯ç®€å•è¿æ¥chunk
- ä¸æ£€æŸ¥æˆ–ä¿®æ”¹æ•°æ®æ ¼å¼
- å¦‚æœchunkæ˜¯è¿ç»­å­—èŠ‚æµï¼Œåˆå¹¶åä»ç„¶æ˜¯è¿ç»­å­—èŠ‚æµ

**å½±å“**ï¼š
- å³ä½¿Webç«¯å‘é€packetæ ¼å¼çš„chunkï¼Œåˆå¹¶åå¯èƒ½ç ´åæ ¼å¼
- ä½†æ›´å¯èƒ½çš„æ˜¯ï¼šWebç«¯å‘é€çš„å°±æ˜¯è¿ç»­å­—èŠ‚æµ

---

## è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ1: ä¿®å¤Webç«¯`sendAudioChunk()`ï¼ˆæ¨èï¼‰

**ä¿®æ”¹**: `webapp/web-client/src/websocket_client.ts`

```typescript
// ä¿®æ”¹ sendAudioChunkJSON() æ–¹æ³•
private async sendAudioChunkJSON(audioData: Float32Array, isFinal: boolean = false) {
  if (this.audioEncoder && this.audioCodecConfig?.codec === 'opus') {
    const encoder = this.audioEncoder as any;
    
    // âœ… ä½¿ç”¨ encodePackets() æ–¹æ³•ï¼ˆPlan Aæ ¼å¼ï¼‰
    if (encoder.encodePackets && typeof encoder.encodePackets === 'function') {
      const opusPackets = await encoder.encodePackets(audioData);
      
      // âœ… ä¸ºæ¯ä¸ªpacketæ·»åŠ é•¿åº¦å‰ç¼€
      const packetDataParts: Uint8Array[] = [];
      for (const packet of opusPackets) {
        if (packet.length === 0) continue;
        
        const lenBuffer = new ArrayBuffer(2);
        const lenView = new DataView(lenBuffer);
        lenView.setUint16(0, packet.length, true);
        
        packetDataParts.push(new Uint8Array(lenBuffer));
        packetDataParts.push(packet);
      }
      
      // åˆå¹¶æ‰€æœ‰packetæ•°æ®
      const totalSize = packetDataParts.reduce((sum, part) => sum + part.length, 0);
      encodedAudio = new Uint8Array(totalSize);
      let offset = 0;
      for (const part of packetDataParts) {
        encodedAudio.set(part, offset);
        offset += part.length;
      }
    } else {
      throw new Error('Opus encoder does not support encodePackets(). Plan A format requires encodePackets() method.');
    }
  }
}
```

### æ–¹æ¡ˆ2: ç¡®ä¿è°ƒåº¦æœåŠ¡å™¨æ­£ç¡®åˆå¹¶packetæ ¼å¼

**æ£€æŸ¥**: `central_server/scheduler/src/managers/audio_buffer.rs`

- `get_combined()`åªæ˜¯ç®€å•è¿æ¥ï¼Œåº”è¯¥æ²¡é—®é¢˜
- ä½†éœ€è¦ç¡®ä¿Webç«¯å‘é€çš„æ˜¯packetæ ¼å¼

---

## æ•°æ®æµå¯¹æ¯”