"""
Faster Whisper + Silero VAD Service - API Routes
FastAPI è·¯ç”±å®šä¹‰
"""
import logging
import os
from fastapi import HTTPException
from typing import Optional

from config import PORT
from vad import vad_state
from context import reset_context_buffer, reset_text_context
from asr_worker_manager import ASRWorkerManager
from api_models import UtteranceRequest, UtteranceResponse, ResetRequest
from utterance_processor import (
    decode_and_preprocess_audio,
    prepare_audio_with_context,
    perform_asr,
    update_context_buffer_if_needed,
)
from audio_validation import (
    validate_audio_format,
    log_audio_validation_info,
    check_audio_quality,
)
from shared_types import SegmentInfo as SharedSegmentInfo
from text_processing import (
    SegmentInfo,
    process_text_deduplication,
    filter_context_substring,
    update_segments_after_deduplication,
    update_text_context_if_needed,
)
from text_filter import is_meaningless_transcript
from context import get_text_context

logger = logging.getLogger(__name__)


# å…¨å±€ ASR Worker Manager
_asr_worker_manager: Optional[ASRWorkerManager] = None


def get_asr_worker_manager() -> ASRWorkerManager:
    """è·å–å…¨å±€ ASR Worker Manager å®ä¾‹"""
    global _asr_worker_manager
    if _asr_worker_manager is None:
        _asr_worker_manager = ASRWorkerManager()
    return _asr_worker_manager


async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼ŒåŒ…å«ASR WorkerçŠ¶æ€"""
    manager = get_asr_worker_manager()
    stats = manager.get_stats()
    return {
        "status": "ok",
        "asr_model_loaded": stats.get("worker_pid") is not None,
        "vad_model_loaded": True,
        "asr_worker": {
            "is_running": stats["is_running"],
            "worker_state": stats["worker_state"],
            "worker_pid": stats["worker_pid"],
            "queue_depth": stats["queue_depth"],
            "total_tasks": stats["total_tasks"],
            "completed_tasks": stats["completed_tasks"],
            "failed_tasks": stats["failed_tasks"],
            "worker_restarts": stats["worker_restarts"],
            "avg_wait_ms": round(stats["avg_wait_ms"], 2),
            "pending_results": stats["pending_results"],
        }
    }


def reset_state(req: ResetRequest):
    """é‡ç½® VAD çŠ¶æ€å’Œä¸Šä¸‹æ–‡ç¼“å†²åŒº"""
    if req.reset_vad:
        vad_state.reset()
        logger.info("âœ… VAD state reset")
    
    if req.reset_context:
        reset_context_buffer()
        logger.info("âœ… Context buffer reset")
    
    if req.reset_text_context:
        reset_text_context()
        logger.info("âœ… Text context cache reset")
    
    return {"status": "ok"}


async def startup():
    """å¯åŠ¨ASR Worker Manager"""
    try:
        logger.info("=" * 80)
        logger.info("ğŸš€ Starting Faster Whisper + Silero VAD Service")
        logger.info(f"   Main process PID: {os.getpid()}")
        logger.info(f"   Port: {PORT}")
        logger.info("=" * 80)
        
        manager = get_asr_worker_manager()
        await manager.start()
        logger.info("âœ… ASR Worker Manager started on startup")
    except Exception as e:
        logger.critical(f"âŒ Failed to start ASR Worker Manager: {e}", exc_info=True)
        raise


async def shutdown():
    """åœæ­¢ASR Worker Manager"""
    try:
        logger.info("=" * 80)
        logger.info("ğŸ›‘ Shutting down Faster Whisper + Silero VAD Service")
        logger.info(f"   Main process PID: {os.getpid()}")
        logger.info("=" * 80)
        
        global _asr_worker_manager
        if _asr_worker_manager:
            await _asr_worker_manager.stop()
            _asr_worker_manager = None
        logger.info("âœ… ASR Worker Manager stopped on shutdown")
    except Exception as e:
        logger.error(f"âŒ Error during shutdown: {e}", exc_info=True)


async def process_utterance(req: UtteranceRequest) -> UtteranceResponse:
    """
    å¤„ç† Utterance ä»»åŠ¡
    ä¸¥æ ¼æŒ‰ç…§ç°æœ‰å®ç°ï¼Œä¸ node-inference æ¥å£ä¿æŒä¸€è‡´ï¼š
    1. è§£ç éŸ³é¢‘ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
    2. å‰ç½®ä¸Šä¸‹æ–‡éŸ³é¢‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    3. ä½¿ç”¨ VAD æ£€æµ‹æœ‰æ•ˆè¯­éŸ³æ®µ
    4. ä½¿ç”¨ Faster Whisper è¿›è¡Œ ASR
    5. æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒº
    """
    trace_id = req.trace_id or req.job_id
    logger.info(f"[{trace_id}] Received utterance request: job_id={req.job_id}, audio_format={req.audio_format}, sample_rate={req.sample_rate}")
    
    logger.info(f"[{trace_id}] ========== ASR æ¥å£å…¥å‚ ==========")
    logger.info(
        f"[{trace_id}] ASR è¯·æ±‚å‚æ•°: "
        f"job_id={req.job_id}, "
        f"src_lang={req.src_lang}, "
        f"audio_format={req.audio_format}, "
        f"sample_rate={req.sample_rate}, "
        f"use_context_buffer={req.use_context_buffer}, "
        f"use_text_context={req.use_text_context}, "
        f"condition_on_previous_text={req.condition_on_previous_text}"
    )
    logger.debug(
        f"[{trace_id}] "
        f"trace_id={trace_id} "
        f"job_id={req.job_id} "
        f"'å¼€å§‹å¤„ç†æ¨ç†è¯·æ±‚'"
    )
    
    try:
        # 1. è§£ç å’Œé¢„å¤„ç†éŸ³é¢‘
        audio_format = req.audio_format or "pcm16"
        sample_rate = req.sample_rate or 16000
        audio, sr = decode_and_preprocess_audio(
            req.audio, audio_format, sample_rate, req.padding_ms, trace_id
        )
        
        # 2. ç¡®å®šè¯­è¨€ï¼ˆå¦‚æœ src_lang == "auto"ï¼Œåˆ™ä½¿ç”¨ language æˆ–è‡ªåŠ¨æ£€æµ‹ï¼‰
        asr_language = None
        if req.src_lang != "auto":
            asr_language = req.src_lang
        elif req.language:
            asr_language = req.language
        
        logger.debug(f"[{trace_id}] trace_id={trace_id} src_lang={req.src_lang} 'å¼€å§‹ ASR è¯­éŸ³è¯†åˆ«'")
        
        # 3. å‡†å¤‡å¸¦ä¸Šä¸‹æ–‡çš„éŸ³é¢‘å¹¶è¿›è¡ŒVADæ£€æµ‹
        processed_audio, vad_segments = prepare_audio_with_context(
            audio, sr, req.use_context_buffer, trace_id
        )
        
        # 4. è·å–æ–‡æœ¬ä¸Šä¸‹æ–‡ï¼ˆç”¨äº Faster Whisper çš„ initial_promptï¼‰
        text_context = ""
        if req.use_text_context:
            text_context = get_text_context()
            if text_context:
                logger.info(
                    f"[{trace_id}] "
                    f"Using text context ({len(text_context)} chars): \"{text_context[:100]}...\""
                )
                logger.info(f"[{trace_id}] ASR æ–‡æœ¬ä¸Šä¸‹æ–‡ (å®Œæ•´): \"{text_context}\"")
            else:
                logger.info(
                    f"[{trace_id}] No text context available (first utterance or context was reset)"
                )
        
        # 5. éªŒè¯éŸ³é¢‘æ•°æ®æ ¼å¼
        processed_audio = validate_audio_format(processed_audio, trace_id)
        
        # 6. è®°å½•éŸ³é¢‘æ•°æ®ä¿¡æ¯
        audio_std, audio_rms, audio_dynamic_range, audio_duration = log_audio_validation_info(
            processed_audio, sr, trace_id
        )
        
        # 7. éŸ³é¢‘è´¨é‡æ£€æŸ¥
        is_quality_ok, audio_quality_issues = check_audio_quality(
            processed_audio, sr, trace_id
        )
        
        if not is_quality_ok:
            return UtteranceResponse(
                text="",
                segments=[],
                language=asr_language or "unknown",
                duration=audio_duration,
                vad_segments=vad_segments,
            )
        
        # 8. ä½¿ç”¨ ASR Worker Manager è¿›è¡Œ ASRï¼ˆè¿›ç¨‹éš”ç¦»æ¶æ„ï¼‰
        manager = get_asr_worker_manager()
        
        full_text, detected_language, language_probabilities, segments_info, duration_sec = await perform_asr(
            processed_audio=processed_audio,
            sample_rate=sr,
            asr_language=asr_language,
            task=req.task,
            beam_size=req.beam_size,
            text_context=text_context if text_context else None,
            condition_on_previous_text=req.condition_on_previous_text,
            trace_id=trace_id,
            manager=manager,
            best_of=req.best_of,
            temperature=req.temperature,
            patience=req.patience,
            compression_ratio_threshold=req.compression_ratio_threshold,
            log_prob_threshold=req.log_prob_threshold,
            no_speech_threshold=req.no_speech_threshold,
        )
        
        # è®¡ç®—æ£€æµ‹åˆ°çš„è¯­è¨€çš„æ¦‚ç‡
        language_probability = None
        if language_probabilities and detected_language:
            language_probability = language_probabilities.get(detected_language)
            if language_probability is not None:
                logger.info(
                    f"[{trace_id}] ASR è¯­è¨€æ£€æµ‹æ¦‚ç‡: language={detected_language}, "
                    f"probability={language_probability:.4f}"
                )
        
        info_language = detected_language
        info_duration = duration_sec
        
        logger.info(f"[{trace_id}] Step 9: Starting ASR result processing")
        
        # 9. ASR è¯†åˆ«å®Œæˆï¼Œè®°å½•ç»“æœ
        try:
            full_text_trimmed = full_text.strip()
            logger.info(f"[{trace_id}] Step 9.1: Text trimmed, len={len(full_text_trimmed)}")
            
            # 9.2. å»é‡å¤„ç†
            if full_text_trimmed:
                full_text_trimmed = process_text_deduplication(full_text_trimmed, trace_id)
                
                # 9.3. è¿‡æ»¤ä¸Šä¸‹æ–‡å­ä¸²
                if text_context and full_text_trimmed:
                    full_text_trimmed = filter_context_substring(
                        full_text_trimmed, text_context, audio_rms, audio_duration, trace_id
                    )
        except Exception as e:
            logger.error(f"[{trace_id}] Step 9.1: Failed to trim text: {e}", exc_info=True)
            raise
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‹¬å·ï¼ˆç”¨äºè°ƒè¯•ï¼Œä¸ node-inference ä¸€è‡´ï¼‰
        try:
            if '(' in full_text_trimmed or 'ï¼ˆ' in full_text_trimmed or '[' in full_text_trimmed or 'ã€' in full_text_trimmed:
                logger.warning(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"transcript='{full_text_trimmed}' "
                    f"transcript_len={len(full_text_trimmed)} "
                    f"'âš ï¸ [ASR Filter Check] Transcript contains brackets before setting to context!'"
                )
        except Exception as e:
            logger.error(f"[{trace_id}] Step 9.2: Failed to check brackets: {e}", exc_info=True)
        
        logger.info(
            f"[{trace_id}] trace_id={trace_id} "
            f"transcript_len={len(full_text)} "
            f"transcript_preview='{full_text[:50]}' "
            f"transcript_trimmed_len={len(full_text_trimmed)} "
            f"transcript_deduplicated_preview='{full_text_trimmed[:50]}' "
            f"'âœ… ASR è¯†åˆ«å®Œæˆ'"
        )
        # è®°å½•æœ€ç»ˆè¿”å›ç»™ NMT çš„æ–‡æœ¬ï¼ˆç”¨äºè¯Šæ–­ "R" å¼€å¤´é—®é¢˜ï¼‰
        logger.info(
            f"[{trace_id}] Step 9.4: Final text to be sent to NMT (full): '{full_text_trimmed}' "
            f"(len={len(full_text_trimmed)}, first_char='{full_text_trimmed[0] if full_text_trimmed else 'N/A'}')"
        )
        
        # åœ¨å»é‡åï¼Œé‡æ–°ç”Ÿæˆ segments_infoï¼ˆä½¿ç”¨å»é‡åçš„æ–‡æœ¬ï¼‰
        # å°† dataclass è½¬æ¢ä¸º Pydantic æ¨¡å‹
        segments_info_pydantic = [
            SegmentInfo(
                text=seg.text,
                start=seg.start,
                end=seg.end,
                no_speech_prob=seg.no_speech_prob,
            )
            for seg in segments_info
        ]
        segments_info_pydantic = update_segments_after_deduplication(
            segments_info_pydantic, full_text, full_text_trimmed
        )
        segments_info = segments_info_pydantic
        
        logger.info(f"[{trace_id}] Step 10: Starting text validation")
        
        # 10. æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ä¸ºæ— æ„ä¹‰çš„è¯†åˆ«ç»“æœ
        try:
            if not full_text_trimmed:
                logger.warning(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"transcript='{full_text}' "
                    f"'ASR transcript is empty, skipping NMT and TTS, and NOT updating context buffer'"
                )
                logger.info(f"[{trace_id}] Step 10.1: Returning empty response (empty transcript)")
                return UtteranceResponse(
                    text="",
                    segments=[],
                    language=info_language,
                    duration=info_duration,
                    vad_segments=[],
                )
        except Exception as e:
            logger.error(f"[{trace_id}] Step 10.1: Failed to check empty text: {e}", exc_info=True)
            raise
        
        try:
            logger.info(f"[{trace_id}] Step 10.2: Checking if transcript is meaningless")
            is_meaningless = is_meaningless_transcript(full_text_trimmed)
            logger.info(f"[{trace_id}] Step 10.2: Meaningless check result: {is_meaningless}")
        except Exception as e:
            logger.error(f"[{trace_id}] Step 10.2: Failed to check meaningless transcript: {e}", exc_info=True)
            raise
        
        if is_meaningless:
            logger.warning(
                f"[{trace_id}] trace_id={trace_id} "
                f"transcript='{full_text_trimmed}' "
                f"transcript_len={len(full_text_trimmed)} "
                f"'ASR transcript is meaningless (likely silence misrecognition), skipping NMT and TTS, and NOT updating context buffer'"
            )
            logger.info(f"[{trace_id}] Step 10.3: Returning empty response (meaningless transcript)")
            return UtteranceResponse(
                text="",
                segments=[],
                language=info_language,
                duration=info_duration,
                vad_segments=[],
            )
        
        logger.info(f"[{trace_id}] Step 11: Starting text context update (use_text_context={req.use_text_context})")
        
        # 11. æ›´æ–°æ–‡æœ¬ä¸Šä¸‹æ–‡ç¼“å­˜
        update_text_context_if_needed(full_text_trimmed, req.use_text_context, trace_id)
        
        # 12. æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒº
        update_context_buffer_if_needed(audio, req.use_context_buffer, trace_id)
        
        logger.info(f"[{trace_id}] Step 13: Starting response construction")
        
        # 13. è¿”å›ç»“æœ
        try:
            response = UtteranceResponse(
                text=full_text_trimmed,
                segments=segments_info,
                language=info_language,
                language_probability=language_probability,
                language_probabilities=language_probabilities,
                duration=info_duration,
                vad_segments=vad_segments,
            )
            logger.info(f"[{trace_id}] Step 13: Response constructed successfully, returning deduplicated text (len={len(full_text_trimmed)})")
            return response
        except Exception as e:
            logger.error(f"[{trace_id}] Step 13: Failed to construct response: {e}", exc_info=True)
            raise
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Utterance processing error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Utterance processing failed: {str(e)}")
