#!/usr/bin/env python3
"""
Speaker Embedding HTTP æœåŠ¡

ç”¨äºä» Rust ä»£ç è°ƒç”¨ SpeechBrain ECAPA-TDNN æ¨¡å‹æå–è¯´è¯è€…ç‰¹å¾å‘é‡ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
    python speaker_embedding_service.py [--gpu] [--port PORT] [--host HOST]

å‚æ•°ï¼š
    --gpu: ä½¿ç”¨ GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
    --port: æœåŠ¡ç«¯å£ï¼ˆé»˜è®¤ï¼š5003ï¼‰
    --host: æœåŠ¡åœ°å€ï¼ˆé»˜è®¤ï¼š127.0.0.1ï¼‰

æœåŠ¡å°†åœ¨ http://127.0.0.1:5003 å¯åŠ¨

API ç«¯ç‚¹ï¼š
    GET  /health - å¥åº·æ£€æŸ¥
    POST /extract - æå– speaker embedding
    Body: {"audio": [0.1, 0.2, ...]}  # 16kHz å•å£°é“éŸ³é¢‘æ•°æ®ï¼ˆf32ï¼‰
    Response: {"embedding": [0.1, 0.2, ...], "dimension": 192, ...}
"""

import sys
import os
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# ä¿®å¤ torchaudio å…¼å®¹æ€§é—®é¢˜ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ SpeechBrain ä¹‹å‰ï¼‰
def fix_torchaudio_compatibility():
    """ä¿®å¤ torchaudio 2.9+ å…¼å®¹æ€§é—®é¢˜"""
    try:
        import torchaudio
        # torchaudio 2.9+ ç§»é™¤äº† list_audio_backends æ–¹æ³•
        if not hasattr(torchaudio, 'list_audio_backends'):
            # åˆ›å»ºæ¨¡æ‹Ÿå‡½æ•°
            def mock_list_audio_backends():
                return ['soundfile']  # é»˜è®¤åç«¯
            torchaudio.list_audio_backends = mock_list_audio_backends
    except ImportError:
        pass  # torchaudio æœªå®‰è£…ï¼Œç¨åä¼šæŠ¥é”™

# åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—ä¹‹å‰åº”ç”¨ä¿®å¤
fix_torchaudio_compatibility()

# è¿›ä¸€æ­¥ä¿®å¤ï¼šåœ¨ SpeechBrain å¯¼å…¥å‰ä¿®è¡¥å…¶ backend æ£€æŸ¥æ¨¡å—
def patch_speechbrain_backend_check():
    """åœ¨ SpeechBrain å¯¼å…¥å‰ä¿®è¡¥ backend æ£€æŸ¥"""
    import types
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„ backend æ£€æŸ¥æ¨¡å—
    backend_module_name = 'speechbrain.utils.torch_audio_backend'
    
    # å¦‚æœæ¨¡å—è¿˜æœªå¯¼å…¥ï¼Œåˆ›å»ºå¹¶æ³¨å†Œ
    if backend_module_name not in sys.modules:
        backend_module = types.ModuleType(backend_module_name)
        
        def patched_check_torchaudio_backend():
            """ä¿®è¡¥çš„æ£€æŸ¥å‡½æ•°ï¼Œè·³è¿‡ list_audio_backends è°ƒç”¨"""
            try:
                import torchaudio
                if not hasattr(torchaudio, '__version__'):
                    raise RuntimeError("torchaudio not properly installed")
            except ImportError:
                raise RuntimeError("torchaudio is not installed. Install it with: pip install torchaudio")

        def patched_validate_backend():
            return patched_check_torchaudio_backend()

        def get_audio_backend():
            return "soundfile"

        def set_audio_backend(_backend: str):
            return None

        backend_module.check_torchaudio_backend = patched_check_torchaudio_backend
        backend_module.validate_backend = patched_validate_backend
        backend_module.get_audio_backend = get_audio_backend
        backend_module.set_audio_backend = set_audio_backend
        sys.modules[backend_module_name] = backend_module

# åº”ç”¨ä¿®è¡¥ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ SpeechBrain ä¹‹å‰ï¼‰
patch_speechbrain_backend_check()

# ä¿®å¤ huggingface_hub å…¼å®¹æ€§é—®é¢˜
def patch_huggingface_hub():
    """ä¿®å¤ huggingface_hub çš„ use_auth_token å‚æ•°å…¼å®¹æ€§é—®é¢˜"""
    try:
        import huggingface_hub
        import functools
        
        original_hf_hub_download = huggingface_hub.hf_hub_download
        
        @functools.wraps(original_hf_hub_download)
        def patched_hf_hub_download(*args, **kwargs):
            """ä¿®è¡¥çš„ hf_hub_downloadï¼Œå°† use_auth_token è½¬æ¢ä¸º token"""
            if 'use_auth_token' in kwargs:
                token = kwargs.pop('use_auth_token')
                if token is not None and 'token' not in kwargs:
                    kwargs['token'] = token
            return original_hf_hub_download(*args, **kwargs)
        
        huggingface_hub.hf_hub_download = patched_hf_hub_download
    except ImportError:
        pass
    except Exception as e:
        print(f"âš ï¸  Failed to patch huggingface_hub: {e}")

# åº”ç”¨ huggingface_hub ä¿®è¡¥
patch_huggingface_hub()

# ç°åœ¨å¯ä»¥å®‰å…¨å¯¼å…¥å…¶ä»–æ¨¡å—
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List
import numpy as np
import torch

app = FastAPI(title="Speaker Embedding Service", version="1.0.0")

# æ·»åŠ  CORS æ”¯æŒ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

classifier = None
device = None

def get_device(use_gpu=False):
    """è·å–è®¡ç®—è®¾å¤‡"""
    if use_gpu and torch.cuda.is_available():
        device = "cuda"
        print(f"âœ… Using GPU: {torch.cuda.get_device_name(0)}")
    else:
        device = "cpu"
        if use_gpu:
            print("âš ï¸  GPU requested but not available, using CPU")
        else:
            print("â„¹ï¸  Using CPU")
    return device

def load_model(model_path, device="cpu"):
    """åŠ è½½ SpeechBrain ECAPA-TDNN æ¨¡å‹"""
    global classifier
    
    # ç¡®ä¿å…¼å®¹æ€§ä¿®å¤å·²åº”ç”¨
    fix_torchaudio_compatibility()
    patch_speechbrain_backend_check()
    patch_huggingface_hub()
    
    try:
        from speechbrain.inference.speaker import EncoderClassifier
        
        if not model_path.exists():
            raise FileNotFoundError(f"Model not found at {model_path}")
        
        print(f"ğŸ“ Loading model from: {model_path}")
        print(f"ğŸ”§ Device: {device}")
        
        classifier = EncoderClassifier.from_hparams(
            source=str(model_path),
            run_opts={"device": device}
        )
        
        print("âœ… Speaker Embedding model loaded successfully")
        print(f"   Model output dimension: 192")
        print(f"   Device: {device}")
        
        return classifier
    except Exception as e:
        print(f"âŒ Failed to load model: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

class ExtractRequest(BaseModel):
    audio: List[float]

class ExtractResponse(BaseModel):
    embedding: Optional[List[float]] = None
    dimension: Optional[int] = None
    input_samples: Optional[int] = None
    sample_rate: Optional[int] = None
    too_short: Optional[bool] = None
    use_default: Optional[bool] = None
    estimated_gender: Optional[str] = None
    message: Optional[str] = None

@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "ok",
        "model_loaded": classifier is not None
    }

@app.post("/extract", response_model=ExtractResponse)
async def extract_embedding(request: ExtractRequest):
    """æå–è¯´è¯è€…ç‰¹å¾å‘é‡"""
    try:
        # è·å–éŸ³é¢‘æ•°æ®
        try:
            audio_data = np.array(request.audio, dtype=np.float32)
        except (ValueError, TypeError) as e:
            raise HTTPException(status_code=400, detail=f"Invalid audio data: {str(e)}")
        
        # éªŒè¯éŸ³é¢‘æ•°æ®
        if len(audio_data) == 0:
            raise HTTPException(status_code=400, detail="Empty audio data")
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŠ è½½
        if classifier is None:
            raise HTTPException(status_code=500, detail="Model not loaded")
        
        # æ£€æŸ¥éŸ³é¢‘é•¿åº¦ï¼ŒECAPA-TDNN éœ€è¦è‡³å°‘ 1 ç§’çš„éŸ³é¢‘ï¼ˆ16000 æ ·æœ¬ï¼‰
        min_samples = 16000  # 1 ç§’ @ 16kHz
        if len(audio_data) < min_samples:
            # éŸ³é¢‘å¤ªçŸ­ï¼Œæ— æ³•æå– embeddingï¼Œè¿”å›æ ‡è®°ä½¿ç”¨é»˜è®¤å£°éŸ³
            # å°è¯•ç®€å•åˆ¤æ–­æ€§åˆ«ï¼ˆåŸºäºéŸ³é¢‘èƒ½é‡å’Œé¢‘ç‡ç‰¹å¾ï¼‰
            audio_array = np.array(audio_data, dtype=np.float32)
            rms = np.sqrt(np.mean(audio_array ** 2))
            estimated_gender = "male" if rms > 0.01 else "female"
            
            return ExtractResponse(
                embedding=None,
                too_short=True,
                use_default=True,
                estimated_gender=estimated_gender,
                input_samples=len(audio_data),
                sample_rate=16000,
                message=f"Audio too short ({len(audio_data)} samples < {min_samples} required), using default voice"
            )
        
        # è½¬æ¢ä¸º tensor [batch, samples]
        audio_tensor = torch.from_numpy(audio_data).unsqueeze(0)
        
        # ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
        current_device = device if device else "cpu"
        if current_device != "cpu":
            audio_tensor = audio_tensor.to(current_device)
        
        # æå– embedding
        # è¾“å‡ºå½¢çŠ¶ï¼š[batch, 1, 192]
        embeddings = classifier.encode_batch(audio_tensor)
        
        # è½¬æ¢ä¸ºåˆ—è¡¨ [192]ï¼ˆç¡®ä¿ç§»å› CPUï¼‰
        embedding = embeddings.squeeze().cpu().numpy()
        
        # ç¡®ä¿æ˜¯ 1D æ•°ç»„
        if embedding.ndim > 1:
            embedding = embedding.flatten()
        
        embedding_list = embedding.tolist()
        
        return ExtractResponse(
            embedding=embedding_list,
            dimension=len(embedding_list),
            input_samples=len(audio_data),
            sample_rate=16000,
            too_short=False,
            use_default=False,
            estimated_gender=None,
            message=None
        )
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        error_msg = str(e)
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=error_msg)

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Speaker Embedding HTTP Service")
    parser.add_argument('--gpu', action='store_true', help='Use GPU if available')
    parser.add_argument('--port', type=int, default=5003, help='Server port (default: 5003)')
    parser.add_argument('--host', type=str, default='127.0.0.1', help='Server host (default: 127.0.0.1)')
    args = parser.parse_args()
    
    print("=" * 60)
    print("  Speaker Embedding HTTP Service")
    print("=" * 60)
    
    # ç¡®å®šæ¨¡å‹è·¯å¾„ - åªåœ¨è‡ªå·±çš„æœåŠ¡ç›®å½•ä¸‹æŸ¥æ‰¾ï¼Œæ‰¾ä¸åˆ°ç›´æ¥æŠ¥é”™
    service_dir = Path(__file__).parent
    model_path = service_dir / "models" / "speaker_embedding" / "cache"
    if not model_path.exists():
        print(f"âŒ Model not found at {model_path}")
        print(f"   Please ensure the Speaker Embedding model is placed in the service directory.")
        print(f"   Expected path: {model_path.resolve()}")
        sys.exit(1)
    
    # è·å–è®¾å¤‡
    device = get_device(args.gpu)
    
    # åŠ è½½æ¨¡å‹
    try:
        print("\nğŸ”§ Applying compatibility fixes...")
        fix_torchaudio_compatibility()
        patch_speechbrain_backend_check()
        print("âœ… Compatibility fixes applied")
        
        load_model(model_path, device)
    except Exception as e:
        print(f"\nâŒ Failed to start service: {e}")
        print("\nğŸ’¡ Troubleshooting:")
        print("   1. Install dependencies: pip install speechbrain torch 'torchaudio<2.9' soundfile fastapi uvicorn")
        print("   2. Download model using: python download_speaker_embedding_model.py")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    print(f"\nğŸš€ Starting server on http://{args.host}:{args.port}")
    print("   Endpoints:")
    print("     GET  /health  - Health check")
    print("     POST /extract - Extract speaker embedding")
    print(f"   Device: {device}")
    print("\n   Press Ctrl+C to stop")
    print("=" * 60)
    
    import uvicorn
    uvicorn.run(app, host=args.host, port=args.port, log_level="info")

