# æ¨¡å—åŒ–åŠŸèƒ½è®¾è®¡æ–‡æ¡£

## å¿«é€Ÿå‚è€ƒ

**æ˜¯çš„ï¼Œå½“å‰æ¶æ„å®Œå…¨æ”¯æŒå®æ—¶åœç”¨æˆ–åˆ‡æ¢å¯é€‰åŠŸèƒ½æ¨¡å—ï¼Œä¸”ä¸ä¼šå½±å“å…¶ä»–åŠŸèƒ½ã€‚**

### æ ¸å¿ƒç‰¹æ€§

âœ… **æ¨¡å—ç‹¬ç«‹æ€§**: æ¯ä¸ªæ¨¡å—å¯ä»¥ç‹¬ç«‹å¯ç”¨/ç¦ç”¨ï¼Œäº’ä¸å½±å“  
âœ… **è¿è¡Œæ—¶åˆ‡æ¢**: æ— éœ€é‡å¯æœåŠ¡å³å¯åˆ‡æ¢æ¨¡å—çŠ¶æ€  
âœ… **ä¼˜é›…é™çº§**: æ¨¡å—ç¦ç”¨æ—¶ï¼Œç³»ç»Ÿä»èƒ½æ­£å¸¸å·¥ä½œ  
âœ… **æŒ‰éœ€åŠ è½½**: æ¨¡å—åªåœ¨éœ€è¦æ—¶åŠ è½½æ¨¡å‹ï¼ŒèŠ‚çœèµ„æº  
âœ… **å®¢æˆ·ç«¯æ§åˆ¶**: å®¢æˆ·ç«¯å¯ä»¥æŒ‰éœ€é€‰æ‹©åŠŸèƒ½

### å·¥ä½œæµç¨‹

```
ç”¨æˆ·ï¼ˆWeb/ç§»åŠ¨ç«¯ï¼‰â†’ é€‰æ‹©éœ€è¦çš„å¯é€‰åŠŸèƒ½
    â†“
å®¢æˆ·ç«¯è¯·æ±‚ â†’ å°†ç”¨æˆ·é€‰æ‹©çš„åŠŸèƒ½åŒ…å«åœ¨è¯·æ±‚ä¸­
    â†“
è°ƒåº¦æœåŠ¡å™¨ â†’ é€‰æ‹©æ”¯æŒè¿™äº›åŠŸèƒ½çš„èŠ‚ç‚¹
    â†“
èŠ‚ç‚¹å¤„ç† â†’ æ ¹æ®è¯·æ±‚åŠ¨æ€å¯ç”¨/ç¦ç”¨ç›¸åº”æ¨¡å—ï¼ˆè¿è¡Œæ—¶ï¼‰
    â†“
è¿”å›ç»“æœ â†’ åŒ…å«å¯é€‰åŠŸèƒ½çš„å¤„ç†ç»“æœ
```

**é‡è¦è¯´æ˜**ï¼š
- **åŠŸèƒ½é€‰æ‹©**ï¼šç”± Web/ç§»åŠ¨ç«¯çš„**ç”¨æˆ·**å†³å®šï¼Œè€Œä¸æ˜¯èŠ‚ç‚¹ç«¯
- **èŠ‚ç‚¹ç«¯èŒè´£**ï¼šä¸‹è½½æ¨¡å‹ã€æä¾›ç®—åŠ›ã€æ ¹æ®ä»»åŠ¡éœ€æ±‚åŠ¨æ€å¯ç”¨æ¨¡å—
- **èŠ‚ç‚¹ç«¯ UI**ï¼šä»…æä¾›æ¨¡å‹ç®¡ç†ï¼ˆä¸‹è½½/å®‰è£…ï¼‰ï¼Œä¸æä¾›åŠŸèƒ½å¼€å…³

### ä½¿ç”¨ç¤ºä¾‹

#### èŠ‚ç‚¹ç«¯è¿è¡Œæ—¶æ¨¡å—ç®¡ç†ï¼ˆæ ¹æ®ä»»åŠ¡éœ€æ±‚åŠ¨æ€å¯ç”¨ï¼‰

èŠ‚ç‚¹ç«¯ä¸éœ€è¦æ‰‹åŠ¨å¯ç”¨/ç¦ç”¨æ¨¡å—ï¼Œè€Œæ˜¯æ ¹æ®è°ƒåº¦æœåŠ¡å™¨ä¸‹å‘çš„ä»»åŠ¡éœ€æ±‚è‡ªåŠ¨å¯ç”¨ï¼š

```rust
// èŠ‚ç‚¹ç«¯æ ¹æ®ä»»åŠ¡è¯·æ±‚ä¸­çš„ features åŠ¨æ€å¯ç”¨æ¨¡å—
// è¿™æ˜¯è¿è¡Œæ—¶è¡Œä¸ºï¼Œä¸éœ€è¦ UI å¼€å…³
if request.features.speaker_identification {
    // è‡ªåŠ¨å¯ç”¨éŸ³è‰²è¯†åˆ«æ¨¡å—ï¼ˆå¦‚æœæ¨¡å‹å·²å®‰è£…ï¼‰
    inference_service.enable_module("speaker_identification").await?;
}
```

#### å®¢æˆ·ç«¯è¯·æ±‚æŒ‡å®šåŠŸèƒ½ï¼ˆç”±ç”¨æˆ·é€‰æ‹©ï¼‰

**Web/ç§»åŠ¨ç«¯å®¢æˆ·ç«¯**æ ¹æ®ç”¨æˆ·çš„é€‰æ‹©ï¼Œåœ¨è¯·æ±‚ä¸­åŒ…å«åŠŸèƒ½éœ€æ±‚ï¼š

```typescript
// Web/ç§»åŠ¨ç«¯ï¼šç”¨æˆ·é€šè¿‡ UI é€‰æ‹©åŠŸèƒ½
const userSelectedFeatures = {
    speaker_identification: userWantsSpeakerId,  // ç”¨æˆ·é€‰æ‹©
    speech_rate_detection: userWantsSpeechRate,  // ç”¨æˆ·é€‰æ‹©
    emotion_detection: userWantsEmotion,         // ç”¨æˆ·é€‰æ‹©
    // ... å…¶ä»–åŠŸèƒ½
};

// å‘é€è¯·æ±‚æ—¶åŒ…å«ç”¨æˆ·é€‰æ‹©çš„åŠŸèƒ½
const message = {
    type: 'utterance',
    session_id: 's-123',
    utterance_index: 1,
    src_lang: 'zh',
    tgt_lang: 'en',
    audio: base64Audio,
    features: userSelectedFeatures  // ç”¨æˆ·é€‰æ‹©çš„åŠŸèƒ½
};
```

**èŠ‚ç‚¹ç«¯**ï¼šæ ¹æ®è¯·æ±‚ä¸­çš„ `features` è‡ªåŠ¨å¯ç”¨ç›¸åº”æ¨¡å—ï¼Œæ— éœ€ç”¨æˆ·å¹²é¢„ã€‚

---

## æ¦‚è¿°

æœ¬æ–‡æ¡£æè¿°å¦‚ä½•å®ç°**å®æ—¶åœç”¨æˆ–åˆ‡æ¢å¯é€‰åŠŸèƒ½æ¨¡å—**ï¼Œç¡®ä¿å„æ¨¡å—ä¹‹é—´äº’ä¸å½±å“ã€‚

## è®¾è®¡åŸåˆ™

1. **æ¨¡å—åŒ–è®¾è®¡**: æ¯ä¸ªåŠŸèƒ½æ¨¡å—ç‹¬ç«‹ï¼Œå¯æ’æ‹”
2. **è¿è¡Œæ—¶åˆ‡æ¢**: æ”¯æŒä¸é‡å¯æœåŠ¡çš„æƒ…å†µä¸‹å¯ç”¨/ç¦ç”¨æ¨¡å—
3. **ä¼˜é›…é™çº§**: æ¨¡å—ç¦ç”¨æ—¶ï¼Œç³»ç»Ÿä»èƒ½æ­£å¸¸å·¥ä½œ
4. **é…ç½®é©±åŠ¨**: é€šè¿‡é…ç½®å’Œè¿è¡Œæ—¶å‘½ä»¤æ§åˆ¶æ¨¡å—çŠ¶æ€

## å·²å®ç°çš„ä»£ç 

- âœ… æ¨¡å—æ¥å£å®šä¹‰ (`node-inference/src/modules.rs`)
- âœ… éŸ³è‰²è¯†åˆ«å’Œç”Ÿæˆæ¨¡å— (`node-inference/src/speaker.rs`)
- âœ… è¯­é€Ÿè¯†åˆ«å’Œæ§åˆ¶æ¨¡å— (`node-inference/src/speech_rate.rs`)
- âœ… æ¨ç†æœåŠ¡é›†æˆ (`node-inference/src/main.rs`)
- âœ… æ¨¡å—ç®¡ç†å™¨ (`node-inference/src/modules.rs`)

## æ”¯æŒçš„å¯é€‰åŠŸèƒ½æ¨¡å—

### æ ¸å¿ƒæ¨¡å—ï¼ˆå¿…éœ€ï¼‰
- âœ… **ASR** (è¯­éŸ³è¯†åˆ«) - Whisper
- âœ… **NMT** (æœºå™¨ç¿»è¯‘) - M2M100
- âœ… **TTS** (è¯­éŸ³åˆæˆ) - Piper TTS
- âœ… **VAD** (è¯­éŸ³æ´»åŠ¨æ£€æµ‹) - Silero VAD

### å¯é€‰æ¨¡å—ï¼ˆå¯åŠ¨æ€å¯ç”¨/ç¦ç”¨ï¼‰
- ğŸ”§ **Speaker Identification** (éŸ³è‰²è¯†åˆ«)
- ğŸ”§ **Voice Cloning** (éŸ³è‰²ç”Ÿæˆ/å…‹éš†)
- ğŸ”§ **Speech Rate Detection** (è¯­é€Ÿè¯†åˆ«)
- ğŸ”§ **Speech Rate Control** (è¯­é€Ÿç”Ÿæˆ/æ§åˆ¶)
- ğŸ”§ **Emotion Detection** (æƒ…æ„Ÿåˆ†æ) - å·²æœ‰åŸºç¡€
- ğŸ”§ **Persona Adaptation** (ä¸ªæ€§åŒ–é€‚é…) - å·²æœ‰åŸºç¡€

## æ¶æ„è®¾è®¡

### 1. èŠ‚ç‚¹èƒ½åŠ›æ³¨å†Œ

èŠ‚ç‚¹åœ¨æ³¨å†Œæ—¶ä¸ŠæŠ¥æ”¯æŒçš„åŠŸèƒ½æ¨¡å—ï¼š

```rust
// scheduler/src/node_registry.rs
pub struct NodeCapabilities {
    // æ ¸å¿ƒèƒ½åŠ›ï¼ˆå¿…éœ€ï¼‰
    pub asr: bool,
    pub nmt: bool,
    pub tts: bool,
    pub vad: bool,
    
    // å¯é€‰èƒ½åŠ›
    pub speaker_identification: bool,
    pub voice_cloning: bool,
    pub speech_rate_detection: bool,
    pub speech_rate_control: bool,
    pub emotion_detection: bool,
    pub persona_adaptation: bool,
}
```

### 2. æ¨¡å—çŠ¶æ€ç®¡ç†

æ¯ä¸ªèŠ‚ç‚¹ç»´æŠ¤æ¨¡å—çš„å¯ç”¨/ç¦ç”¨çŠ¶æ€ï¼š

```rust
pub struct ModuleState {
    pub enabled: bool,
    pub model_loaded: bool,
    pub last_used: Option<chrono::DateTime<chrono::Utc>>,
}
```

### 3. ä»»åŠ¡è¯·æ±‚ä¸­çš„åŠŸèƒ½æ ‡è®°

å®¢æˆ·ç«¯åœ¨å‘é€ä»»åŠ¡æ—¶æŒ‡å®šéœ€è¦çš„å¯é€‰åŠŸèƒ½ï¼š

```typescript
interface UtteranceMessage {
    type: 'utterance';
    session_id: string;
    utterance_index: number;
    src_lang: string;
    tgt_lang: string;
    audio: string;
    
    // å¯é€‰åŠŸèƒ½è¯·æ±‚
    features?: {
        speaker_identification?: boolean;
        voice_cloning?: boolean;
        speech_rate_detection?: boolean;
        speech_rate_control?: boolean;
        emotion_detection?: boolean;
        persona_adaptation?: boolean;
    };
}
```

### 4. èŠ‚ç‚¹é€‰æ‹©ç­–ç•¥

è°ƒåº¦æœåŠ¡å™¨æ ¹æ®ä»»åŠ¡éœ€æ±‚å’ŒèŠ‚ç‚¹èƒ½åŠ›é€‰æ‹©èŠ‚ç‚¹ï¼š

```rust
fn select_node(
    &self,
    required_features: &FeatureSet,
    src_lang: &str,
    tgt_lang: &str,
) -> Option<String> {
    // 1. ç­›é€‰æ”¯æŒæ‰€æœ‰å¿…éœ€åŠŸèƒ½çš„èŠ‚ç‚¹
    // 2. ä¼˜å…ˆé€‰æ‹©å·²å¯ç”¨ç›¸å…³æ¨¡å—çš„èŠ‚ç‚¹
    // 3. è´Ÿè½½å‡è¡¡
}
```

## å®ç°æ–¹æ¡ˆ

### æ–¹æ¡ˆä¸€ï¼šæ’ä»¶å¼æ¶æ„ï¼ˆæ¨èï¼‰

#### èŠ‚ç‚¹æ¨ç†æœåŠ¡æ”¹é€ 

```rust
// node-inference/src/main.rs
pub trait InferenceModule: Send + Sync {
    fn name(&self) -> &str;
    fn is_enabled(&self) -> bool;
    fn enable(&mut self) -> Result<()>;
    fn disable(&mut self) -> Result<()>;
    fn process(&self, input: &ModuleInput) -> Result<ModuleOutput>;
}

pub struct InferenceService {
    // æ ¸å¿ƒæ¨¡å—ï¼ˆå¿…éœ€ï¼‰
    asr: Arc<dyn ASREngine>,
    nmt: Arc<dyn NMTEngine>,
    tts: Arc<dyn TTSEngine>,
    vad: Arc<dyn VADEngine>,
    
    // å¯é€‰æ¨¡å—ï¼ˆå¯åŠ¨æ€å¯ç”¨/ç¦ç”¨ï¼‰
    speaker_identifier: Option<Arc<dyn SpeakerIdentifier>>,
    voice_cloner: Option<Arc<dyn VoiceCloner>>,
    speech_rate_detector: Option<Arc<dyn SpeechRateDetector>>,
    speech_rate_controller: Option<Arc<dyn SpeechRateController>>,
    emotion_detector: Option<Arc<dyn EmotionDetector>>,
    persona_adapter: Option<Arc<dyn PersonaAdapter>>,
    
    // æ¨¡å—çŠ¶æ€ç®¡ç†
    module_states: Arc<RwLock<HashMap<String, ModuleState>>>,
}
```

#### åŠ¨æ€å¯ç”¨/ç¦ç”¨æ¨¡å—

```rust
impl InferenceService {
    pub async fn enable_module(&self, module_name: &str) -> Result<()> {
        let mut states = self.module_states.write().await;
        
        match module_name {
            "speaker_identification" => {
                if self.speaker_identifier.is_none() {
                    // åŠ è½½æ¨¡å‹
                    let module = SpeakerIdentifier::new().await?;
                    // æ›´æ–°çŠ¶æ€
                    states.insert(module_name.to_string(), ModuleState {
                        enabled: true,
                        model_loaded: true,
                        last_used: None,
                    });
                }
            }
            // ... å…¶ä»–æ¨¡å—
            _ => return Err(anyhow!("Unknown module: {}", module_name)),
        }
        
        Ok(())
    }
    
    pub async fn disable_module(&self, module_name: &str) -> Result<()> {
        let mut states = self.module_states.write().await;
        
        // æ ‡è®°ä¸ºç¦ç”¨ï¼ˆä¸ç«‹å³å¸è½½æ¨¡å‹ï¼Œä¿ç•™åœ¨å†…å­˜ä¸­ä»¥ä¾¿å¿«é€Ÿé‡æ–°å¯ç”¨ï¼‰
        if let Some(state) = states.get_mut(module_name) {
            state.enabled = false;
        }
        
        Ok(())
    }
}
```

#### å¤„ç†æµç¨‹ä¸­çš„æ¡ä»¶è°ƒç”¨

```rust
impl InferenceService {
    pub async fn process(&self, request: InferenceRequest) -> Result<InferenceResult> {
        // 1. ASR (å¿…éœ€)
        let transcript = self.asr.transcribe(&request.audio_data, &request.src_lang).await?;
        
        // 2. å¯é€‰ï¼šéŸ³è‰²è¯†åˆ«
        let speaker_id = if request.features.speaker_identification {
            self.speaker_identifier.as_ref()
                .and_then(|m| m.identify(&request.audio_data).ok())
        } else {
            None
        };
        
        // 3. å¯é€‰ï¼šè¯­é€Ÿè¯†åˆ«
        let speech_rate = if request.features.speech_rate_detection {
            self.speech_rate_detector.as_ref()
                .and_then(|m| m.detect(&request.audio_data).ok())
        } else {
            None
        };
        
        // 4. å¯é€‰ï¼šæƒ…æ„Ÿåˆ†æ
        let emotion = if request.features.emotion_detection {
            self.emotion_detector.as_ref()
                .and_then(|m| m.detect(&transcript).ok())
        } else {
            None
        };
        
        // 5. å¯é€‰ï¼šä¸ªæ€§åŒ–é€‚é…
        let adapted_text = if request.features.persona_adaptation {
            self.persona_adapter.as_ref()
                .map(|m| m.adapt(&transcript, &emotion))
                .unwrap_or(transcript)
        } else {
            transcript
        };
        
        // 6. NMT (å¿…éœ€)
        let translation = self.nmt.translate(&adapted_text, &request.src_lang, &request.tgt_lang).await?;
        
        // 7. å¯é€‰ï¼šè¯­é€Ÿæ§åˆ¶
        let tts_params = if request.features.speech_rate_control && speech_rate.is_some() {
            TtsParams {
                speech_rate: speech_rate.unwrap(),
                ..Default::default()
            }
        } else {
            TtsParams::default()
        };
        
        // 8. å¯é€‰ï¼šéŸ³è‰²å…‹éš†
        let voice_id = if request.features.voice_cloning && speaker_id.is_some() {
            speaker_id
        } else {
            None
        };
        
        // 9. TTS (å¿…éœ€)
        let audio = self.tts.synthesize(&translation, &request.tgt_lang, &tts_params, voice_id).await?;
        
        Ok(InferenceResult {
            transcript,
            translation,
            audio,
            // å¯é€‰ç»“æœ
            speaker_id,
            speech_rate,
            emotion,
        })
    }
}
```

### æ–¹æ¡ˆäºŒï¼šäº‹ä»¶é©±åŠ¨æ¶æ„

å‚è€ƒä¹‹å‰ç‰ˆæœ¬çš„äº‹ä»¶é©±åŠ¨è®¾è®¡ï¼Œä½¿ç”¨ EventBus å®ç°æ¨¡å—è§£è€¦ï¼š

```rust
// äº‹ä»¶ç±»å‹
pub enum InferenceEvent {
    ASRComplete { transcript: String },
    SpeakerIdentified { speaker_id: String },
    SpeechRateDetected { rate: f32 },
    EmotionDetected { emotion: String },
    PersonaAdapted { text: String },
    NMTComplete { translation: String },
    TTSComplete { audio: Vec<u8> },
}

// æ¨¡å—è®¢é˜…äº‹ä»¶
impl InferenceService {
    pub fn setup_event_handlers(&self) {
        // æ ¸å¿ƒæµç¨‹
        self.event_bus.subscribe("asr.complete", |event| {
            // è§¦å‘åç»­å¤„ç†
        });
        
        // å¯é€‰æ¨¡å—åªåœ¨å¯ç”¨æ—¶è®¢é˜…
        if self.is_module_enabled("speaker_identification") {
            self.event_bus.subscribe("audio.received", |event| {
                // éŸ³è‰²è¯†åˆ«
            });
        }
    }
}
```

## Electron Node å®¢æˆ·ç«¯ UI

### æ¨¡å‹ç®¡ç†ç•Œé¢ï¼ˆä¸æä¾›åŠŸèƒ½å¼€å…³ï¼‰

**é‡è¦**ï¼šElectron èŠ‚ç‚¹ç«¯**ä¸æä¾›åŠŸèƒ½å¼€å…³ UI**ï¼Œåªæä¾›æ¨¡å‹ç®¡ç†ï¼ˆä¸‹è½½/å®‰è£…ï¼‰ã€‚

èŠ‚ç‚¹ç«¯æ ¹æ®ä»»åŠ¡è¯·æ±‚ä¸­çš„ `features` è‡ªåŠ¨å¯ç”¨ç›¸åº”æ¨¡å—ï¼Œæ— éœ€ç”¨æˆ·å¹²é¢„ã€‚

```typescript
// electron-node/renderer/src/components/ModelManagement.tsx
// åªæä¾›æ¨¡å‹ä¸‹è½½å’Œç®¡ç†ï¼Œä¸æä¾›åŠŸèƒ½å¼€å…³
export function ModelManagement() {
    const [models, setModels] = useState<Model[]>([]);
    
    const downloadModel = async (modelId: string) => {
        await window.electronAPI.downloadModel(modelId);
    };
    
    return (
        <div className="model-management">
            <h2>æ¨¡å‹ç®¡ç†</h2>
            {models.map(model => (
                <div key={model.id} className="model-item">
                    <div className="model-info">
                        <h3>{model.name}</h3>
                        <p>{model.description}</p>
                        <span className="model-status">
                            {model.installed ? 'å·²å®‰è£…' : 'æœªå®‰è£…'}
                        </span>
                    </div>
                    {!model.installed && (
                        <button onClick={() => downloadModel(model.id)}>
                            ä¸‹è½½æ¨¡å‹
                        </button>
                    )}
                </div>
            ))}
        </div>
    );
}
```

### è¿è¡Œæ—¶æ¨¡å—ç®¡ç†ï¼ˆæ— éœ€ UIï¼‰

èŠ‚ç‚¹ç«¯æ ¹æ®ä»»åŠ¡è¯·æ±‚è‡ªåŠ¨å¯ç”¨/ç¦ç”¨æ¨¡å—ï¼š

```rust
// node-inference/src/inference.rs
impl InferenceService {
    pub async fn process(&self, request: InferenceRequest) -> Result<InferenceResult> {
        // æ ¹æ®è¯·æ±‚ä¸­çš„ features åŠ¨æ€å¯ç”¨æ¨¡å—
        if request.features.speaker_identification {
            // è‡ªåŠ¨å¯ç”¨éŸ³è‰²è¯†åˆ«æ¨¡å—ï¼ˆå¦‚æœæ¨¡å‹å·²å®‰è£…ï¼‰
            self.enable_module("speaker_identification").await?;
        }
        // ... å¤„ç†é€»è¾‘
    }
}
```

## è°ƒåº¦æœåŠ¡å™¨æ”¯æŒ

### èŠ‚ç‚¹èƒ½åŠ›æŸ¥è¯¢

```rust
// scheduler/src/dispatcher.rs
pub async fn select_node_with_features(
    &self,
    required_features: &FeatureSet,
    src_lang: &str,
    tgt_lang: &str,
) -> Option<String> {
    let nodes = self.node_registry.get_available_nodes().await;
    
    // ç­›é€‰æ”¯æŒæ‰€éœ€åŠŸèƒ½çš„èŠ‚ç‚¹
    let candidates: Vec<_> = nodes
        .iter()
        .filter(|node| {
            // æ£€æŸ¥æ ¸å¿ƒèƒ½åŠ›
            node.capabilities.asr && node.capabilities.nmt && node.capabilities.tts
            // æ£€æŸ¥å¯é€‰åŠŸèƒ½
            && (!required_features.speaker_identification || node.capabilities.speaker_identification)
            && (!required_features.voice_cloning || node.capabilities.voice_cloning)
            // ... å…¶ä»–åŠŸèƒ½æ£€æŸ¥
        })
        .collect();
    
    // è´Ÿè½½å‡è¡¡é€‰æ‹©
    select_best_node(candidates)
}
```

## ç§»åŠ¨ç«¯å®¢æˆ·ç«¯æ”¯æŒ

### åŠŸèƒ½é€‰æ‹©ç•Œé¢

```typescript
// mobile-app/src/components/FeatureSelector.tsx
export function FeatureSelector({ onFeaturesChange }: Props) {
    const [features, setFeatures] = useState({
        speaker_identification: false,
        voice_cloning: false,
        speech_rate_detection: false,
        speech_rate_control: false,
        emotion_detection: false,
        persona_adaptation: false,
    });
    
    return (
        <View>
            <Text>å¯é€‰åŠŸèƒ½</Text>
            <Switch
                value={features.speaker_identification}
                onValueChange={(value) => {
                    setFeatures({ ...features, speaker_identification: value });
                    onFeaturesChange(features);
                }}
            />
            <Text>éŸ³è‰²è¯†åˆ«</Text>
            {/* å…¶ä»–åŠŸèƒ½å¼€å…³ */}
        </View>
    );
}
```

## ä¼˜åŠ¿

1. **æ¨¡å—ç‹¬ç«‹æ€§**: æ¯ä¸ªæ¨¡å—å¯ä»¥ç‹¬ç«‹å¯ç”¨/ç¦ç”¨ï¼Œäº’ä¸å½±å“
2. **è¿è¡Œæ—¶åˆ‡æ¢**: æ— éœ€é‡å¯æœåŠ¡å³å¯åˆ‡æ¢æ¨¡å—çŠ¶æ€
3. **èµ„æºä¼˜åŒ–**: ç¦ç”¨æ¨¡å—ä¸å ç”¨è®¡ç®—èµ„æº
4. **çµæ´»é…ç½®**: Web/ç§»åŠ¨ç«¯ç”¨æˆ·å¯ä»¥æŒ‰éœ€é€‰æ‹©åŠŸèƒ½
5. **ä¼˜é›…é™çº§**: æ¨¡å—ä¸å¯ç”¨æ—¶ï¼Œç³»ç»Ÿä»èƒ½æ­£å¸¸å·¥ä½œ

## å®æ–½æ­¥éª¤

1. **é˜¶æ®µä¸€**: å®ç°æ¨¡å—æ¥å£å’ŒçŠ¶æ€ç®¡ç†
2. **é˜¶æ®µäºŒ**: å®ç°æ ¸å¿ƒå¯é€‰æ¨¡å—ï¼ˆéŸ³è‰²è¯†åˆ«ã€è¯­é€Ÿè¯†åˆ«ï¼‰
3. **é˜¶æ®µä¸‰**: å®ç°é«˜çº§å¯é€‰æ¨¡å—ï¼ˆéŸ³è‰²ç”Ÿæˆã€è¯­é€Ÿæ§åˆ¶ï¼‰
4. **é˜¶æ®µå››**: å®Œå–„ UI å’Œé…ç½®ç®¡ç†
5. **é˜¶æ®µäº”**: æµ‹è¯•å’Œä¼˜åŒ–

## å·²å®ç°çš„ä»£ç 

- âœ… æ¨¡å—æ¥å£å®šä¹‰ (`node-inference/src/modules.rs`)
- âœ… éŸ³è‰²è¯†åˆ«å’Œç”Ÿæˆæ¨¡å— (`node-inference/src/speaker.rs`)
- âœ… è¯­é€Ÿè¯†åˆ«å’Œæ§åˆ¶æ¨¡å— (`node-inference/src/speech_rate.rs`)
- âœ… æ¨ç†æœåŠ¡é›†æˆ (`node-inference/src/main.rs`)
- âœ… æ¨¡å—ç®¡ç†å™¨ (`node-inference/src/modules.rs`)

## ä¸‹ä¸€æ­¥

1. âœ… å®Œå–„æ¨¡å—çš„æ¨¡å‹åŠ è½½é€»è¾‘ï¼ˆå·²å®Œæˆï¼‰
2. âœ… å®ç°è°ƒåº¦æœåŠ¡å™¨çš„åŠŸèƒ½æ„ŸçŸ¥èŠ‚ç‚¹é€‰æ‹©ï¼ˆå·²å®Œæˆï¼‰
3. [ ] å®ç° Web/ç§»åŠ¨ç«¯çš„åŠŸèƒ½é€‰æ‹© UIï¼ˆç”±ç”¨æˆ·é€‰æ‹©åŠŸèƒ½ï¼‰
4. [ ] æ·»åŠ æ¨¡å—çŠ¶æ€ç›‘æ§å’Œæ—¥å¿—
5. [ ] å¯é€‰æ¨¡å—æ¨¡å‹é›†æˆï¼ˆå¾…å…·ä½“æ¨¡å‹å®ç°ï¼‰

## æ€»ç»“

å½“å‰æ¶æ„**å®Œå…¨æ”¯æŒ**å®æ—¶åœç”¨æˆ–åˆ‡æ¢å¯é€‰åŠŸèƒ½æ¨¡å—ã€‚é€šè¿‡æ’ä»¶å¼è®¾è®¡å’Œè¿è¡Œæ—¶çŠ¶æ€ç®¡ç†ï¼Œå¯ä»¥å®ç°ï¼š

- âœ… åŠ¨æ€å¯ç”¨/ç¦ç”¨æ¨¡å—
- âœ… ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½
- âœ… ä¸å½±å“å…¶ä»–å¯é€‰æ¨¡å—
- âœ… Web/ç§»åŠ¨ç«¯ç”¨æˆ·æŒ‰éœ€é€‰æ‹©åŠŸèƒ½
- âœ… èŠ‚ç‚¹ç«¯æ ¹æ®ä»»åŠ¡éœ€æ±‚åŠ¨æ€å¯ç”¨æ¨¡å—
- âœ… èŠ‚ç‚¹æŒ‰èƒ½åŠ›æä¾›æœåŠ¡

