# Web 端半双工实时语音翻译交互与上下文拼接设计说明（v2）

版本：v2.0  
作者：Tino（产品规划）  
适用对象：前端开发、服务端调度开发、算法团队

---

## 1. 背景与目标

实时语音翻译在 Web 环境下存在两个主要挑战：

1. 声学回响：TTS 外放音频被麦克风再次采集并送入 ASR，导致“机器听到自己说话”。  
2. 对话节奏：用户的自然说话习惯与“轮询式”输入机制（固定时长录音）不匹配，体验生硬。

本设计采用：

- 半双工自动切换模式（Half-duplex Auto Switching）；  
- 输出阶段完全关闭麦克风（不采集、不上传）；  
- 按语义组（Utterance Groups）进行上下文拼接，而不是拼接音频波形；

目标是：

- 提供简单、清晰、可解释的交互体验；  
- 在不引入复杂 AEC 的前提下规避声学回响；  
- 支持用户在播放结束后继续围绕同一话题补充内容。

---

## 2. 模式定义：输入模式 / 输出模式

系统存在两种主模式：

### 2.1 输入模式（Input Mode）

- 麦克风开启。  
- 浏览器使用 Web Audio API 采集音频。  
- 前端按 100–200ms 分片向服务端发送 PCM16 音频数据。  
- 用户可通过 Send 按钮主动结束本轮输入。  

### 2.2 输出模式（Output Mode）

- 麦克风完全关闭（停止采集，释放对应 MediaStream）。  
- 浏览器播放 TTS 音频（可为流式）。  
- 播放期间用户说话不会被系统采集，也不会上传到服务端。

设计原则：

> 任何时刻系统要么处于“只听不说”（输入模式），要么处于“只说不听”（输出模式），避免物理和逻辑上的回声问题。

---

## 3. 状态机定义

### 3.1 状态列表

| 状态              | 描述                                                         |
|-------------------|--------------------------------------------------------------|
| INPUT_READY       | 输入准备就绪，麦克风已开启，用户尚未开始说话                 |
| INPUT_RECORDING   | 正在采集并上传音频，等待用户完成本轮发言                     |
| WAITING_RESULT    | 已结束录音，麦克风关闭，等待 ASR + 翻译 + TTS 结果           |
| PLAYING_TTS       | 正在播放翻译结果音频，麦克风保持关闭                         |

### 3.2 状态流转（文本版）

```text
[INPUT_READY]
   │ （检测到语音活动 / 用户开始说话）
   ▼
[INPUT_RECORDING]
   │ （用户点击 Send 按钮 或 静音时间 > 静音阈值）
   ▼
[WAITING_RESULT]
   │ （收到翻译文本 + TTS 音频）
   ▼
[PLAYING_TTS]
   │ （TTS 播放结束）
   ▼
[INPUT_READY]
```

### 3.3 静音自动结束逻辑

在 `INPUT_RECORDING` 状态下，如果满足以下条件：

- 检测到连续静音时间 > `silence_timeout_ms`（例如 1000ms）；  
- 并追加 200–300ms 尾部缓冲，以确保尾音被完整收录；

则自动触发一次“结束本轮发言”：

- 停止录音；  
- 关闭麦克风；  
- 切换到 `WAITING_RESULT`；  
- 将本轮音频标记为完成并发送给服务端。

---

## 4. Send 按钮行为

### 4.1 行为定义

按钮：`Send`（可在中文界面展示为“结束本轮 / 发送”）

可用状态：仅在 `INPUT_RECORDING` 时可点击。

点击后动作：

1. 立即停止录音（停止 Web Audio 采集并停止向服务端发送新音频帧）；  
2. 关闭麦克风（释放 MediaStream）；  
3. 将当前已缓存/已上传的音频标记为“本轮音频结束”；  
4. 切换状态为 `WAITING_RESULT`；  
5. UI 显示“正在翻译 / 等待结果”。

### 4.2 与自动结束的关系

- 如果用户说话时间较短，可随时点击 Send 主动结束。  
- 如果用户不点击 Send，则由静音检测自动结束本轮。  
- Send 和自动结束的效果完全等价，保证交互一致性。

---

## 5. 输出模式下的行为（播放期间）

### 5.1 麦克风行为

在 `WAITING_RESULT` 与 `PLAYING_TTS` 状态中：

- 浏览器不再采集音频（`getUserMedia` 停止，或相关 track 停用）；  
- 不做本地监听、不做本地缓存、不做上传。

因此：

- 用户在播放期间说话的内容一律不会进入系统；  
- 播放期间不参与任何 ASR、翻译、TTS 处理。

### 5.2 用户体验说明

对用户的可视化说明（示例）：

- 播放阶段在界面顶部或显著位置提示：  
  “对方在说话，请稍候再发言” 或 “正在播报译文，请稍后继续说话”。

这与真实的对讲机、翻译机体验一致：  
> 一旦轮到“机器说话”，请不要同时说话，等机器说完再继续。

---

## 6. 用户在播放期间说话的处理策略

由于输出阶段完全关闭麦克风：

- 播放期间用户说话不会进入系统，等同于被丢弃；  
- 不存在“被打断前的半句音频”的保留问题。

从产品规则上：

> 系统只在认为“本轮发言已经结束”之后才会进入输出模式，一旦进入输出模式，该轮发言已被视为完整提交。

如果用户发现忘说了什么：

- 需要等本轮播放完成后，在下一轮发言中作为补充；  
- 由后端的“上下文拼接机制”在语义层面进行连接。

---

## 7. 上下文拼接机制（Utterance Groups）

### 7.1 概念定义

一个 **Utterance Group（话语组）** 表示用户围绕同一话题的多轮补充发言，例如：

- 第一次： “我想订一张明天去奥克兰的机票。”  
- 第二次： “最好是早上十点以前出发的。”  
- 第三次： “如果可以的话靠窗座位更好。”

这三轮可以归属于同一个 Group：`G1`。

### 7.2 Group 归属规则（建议）

新一轮发言开始时，后端根据以下规则决定是否归入上一 Group：

- 当前时间与上一次 TTS 播放结束时间的间隔 < `group_timeout_sec`（例如 30 秒）；  
- 当前发言在语义上是对上一轮的继续/补充（可由规则或 LLM 辅助判断）；  
- 没有显式“新话题”指示（例如 UI 中的“开始新话题”按钮）。

满足条件则归入同一 Group（例如 `G1.part2`）；否则创建新 Group（例如 `G2.part1`）。

### 7.3 翻译时的上下文使用

翻译时不拼接音频，而是：

- 在文本层面将 Group 内所有 part 作为上下文输入：  
  - `G1.part1_text` + `G1.part2_text` + ...  
- 或在 LLM Prompt 中显示为多轮历史对话：  
  - “上一轮用户这样说……本轮是补充说明，请在翻译时参考前文。”

这允许翻译引擎生成更连贯、上下文一致的目标语言表达，而不必在音频层做复杂拼接。

---

## 8. 关键参数建议

| 参数名                 | 默认值    | 说明                             |
|------------------------|-----------|----------------------------------|
| silence_timeout_ms     | 1000 ms   | 静音超过该值视为本轮结束         |
| tail_buffer_ms         | 200–300ms | 为尾音保留的额外缓冲时间         |
| group_timeout_sec      | 30 s      | 超过该间隔视为新话题             |

---

## 9. 设计小结

- 系统采用“半双工 + 输出阶段关麦”的模式，彻底杜绝 TTS 回流 ASR 的声学回响问题。  
- 通过 Send 按钮 + 静音自动结束，兼顾主动性与易用性。  
- 上下文拼接在“语义层”完成，而非音频层，既简化实现，又利于大模型处理。  
- 播放期间用户说话不会被采集，用户如果需要补充，必须等待播放结束后在下一轮发言中补充，由 Group 机制保证语义连续性。
