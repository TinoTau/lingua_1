# 0. 清理日志
cd D:\Programs\github\lingua_1

# 快速清理（总共3秒）
.\scripts\cleanup_orphaned_processes_simple.ps1
.\scripts\clear_code_cache_comprehensive.ps1
.\scripts\maintenance\clear_logs_simple.ps1

# 1. 节点端
cd D:\Programs\github\lingua_1\electron_node\electron-node
npm run clear-cache
npm run build
cd D:\Programs\github\lingua_1
.\scripts\start_electron_node.ps1




# 2. 调度服务器（在新窗口）
cd D:\Programs\github\lingua_1\central_server\scheduler
cargo clean
powershell -ExecutionPolicy Bypass -File .\scripts\redis_clear_lingua.ps1
cd D:\Programs\github\lingua_1
.\scripts\start_scheduler.ps1

# 3. 模型管理
cd D:\Programs\github\lingua_1
.\scripts\start_model_hub.ps1

# redis 集群
cd D:\Programs\github\lingua_1\central_server\scheduler
.\scripts\phase2_cluster_acceptance.ps1

# 在仓库根目录执行
cd D:\Programs\github\lingua_1
.\scripts\start_all_services_with_terminals.ps1


访问仪表盘：
http://localhost:5010/dashboard
查看统计数据 API：
http://localhost:5010/api/v1/stats


# 4. Web 客户端（在新窗口）
cd D:\Programs\github\lingua_1\webapp\web-client
.\clean_cache.ps1
npm install
npm run build
cd D:\Programs\github\lingua_1
.\scripts\start_webapp.ps1

#导出日志：http://localhost:9001/export-logs-simple.html



cd D:\Programs\github\lingua_1\electron_node\electron-node 
Get-Location   
npm run build:main  

0.
1.（重构服务发现）语义修复服务合并
2.embedding实装，服务模式+连续播放
3.yourtts实装
1.model hub改造成多实例
2.日志服务器，统计节点性能，错误日志
3.公司指定服务器
4.会议室实装，连续播放
4.第三方API，SDK
4.收费模式
5.模型训练

请将D:\Programs\github\lingua_1\central_server\docs和D:\Programs\github\lingua_1\central_server\scheduler\docs的docs文档进行合并整理，按每个模块的docs只放在自己模块里，根据实际代码补充新增功能，移除过期（与当前代码不符）和废弃的内容，并能合并的就合并，文档大小最好不要超过500行。测试报告之类的文件全都移除

现在请对D:\Programs\github\lingua_1\electron_node\services\faster_whisper_vad的代码文件进行整理，拆分超过500行的大文件，合并重复的逻辑，只对代码进行迁移，不要改变任何接口，参数和返回结果，也不要改动任何代码逻辑。异步方法之间如果有必要的话采用状态机进行管理，然后把Import都移动到文件头部,然后进行单元测试，修复单元测试时，不要考虑兼容，不要打补丁或新增代码逻辑来添加保险或者兜底机制，并避免错误调用旧路径旧方法


请实现这个功能，添加流程日志，进行单元测试，并更新文档。

不要考虑兼容，这个项目没有上线，没有用户，只需要保持代码简洁，做好单元测试，然后更新文档

请将现在的utterance聚合流程，从ASR返回结果到发送给语义修复服务，具体到每一个调用的方法，整理出来，看看有没有重复的调用或者错误的调用会导致不必要的开销，然后给我一个文档交给决策部门审议

这个项目的开发力量不足，无法对每个模块每个流程都做到滚瓜烂熟。我希望代码逻辑尽可能简单易懂，方便找到问题，而不是添加一层又一层的保险措施来掩盖问题，或者在应该略有调整的地方直接新增一条业务路径（严格禁止），如果不是必须的逻辑，就不要用打补丁的方式来解决，最好能用架构设计解决，也就是允许存在复杂的“业务现象”，但不允许存在复杂的“控制流”，如果遇到无法避免的问题请先告诉我

请在本次改造中根据实际代码进行谨慎调整，不要新增不必要的流程路径，产生新的重复逻辑或者冗余的处理过程。我希望代码逻辑尽可能简单易懂，方便找到问题，而不是添加一层又一层的保险措施来掩盖问题，也不要考虑兼容，这个项目没有上线，没有用户，只需要保持代码简洁，如果不是必须的逻辑，就不要用打补丁的方式来解决，最好能用架构设计解决，如果遇到无法避免的问题请先告诉我

请把web端对音频的接收和发送、播放按钮的前后流程，具体到每个调用方法，整理成文档，让我交给决策部门

这是本次改造之后的的调度服务器节点注册，节点管理和任务管理流程，请看一下有没有重复或者矛盾的逻辑，有没有遗漏或者可以优化的地方

节点端和调度服务器最近进行了重构，请参考D:\Programs\github\lingua_1\expired\lingua_1-main的备份代码进行接口或者数据格式的调整，备份代码是可以通过集成测试的。我希望代码逻辑尽可能简单易懂，方便找到问题，而不是添加一层又一层的保险措施来掩盖问题，或者在应该略有调整的地方直接新增一条业务路径（严格禁止），如果不是必须的逻辑，就不要用打补丁的方式来解决，最好能用架构设计解决。



现在我们开始进行一次语音识别稳定性测试。
我会先读一两句比较短的话，用来确认系统不会在句子之间随意地把语音切断，或者在没有必要的时候提前结束本次识别。

接下来这一句我会尽量连续地说得长一些，中间只保留自然的呼吸节奏，不做刻意的停顿，看看在超过十秒钟之后，系统会不会因为超时或者静音判定而强行把这句话截断，从而导致前半句和后半句在节点端被拆成两个不同的 job，甚至出现语义上不完整、读起来前后不连贯的情况。

如果这次的长句能够被完整地识别出来，而且不会出现半句话被提前发送或者直接丢失的现象，那就说明我们当前的切分策略和超时规则是基本可用的。
否则，我们还需要继续分析日志，找出到底是在哪一个环节把我的语音吃掉了。



我想对超长语音做出更好的处理，以提升用户体验：假设场景是35秒的长语音，被调度服务器拆成4个job，进入节点端后被AudioAggregator切分成多个片段：job0_1:3秒，job0_2:3秒，job0_3:4秒，job1_1:3秒，job1_2:3秒，job1_3:4秒，job2_1:3秒，job2_2:3秒，job2_3:3秒，job2_4:1秒，job3_1:5秒。这时虽然AudioAggregator会一直等到job3带着手动截断或者pause截断的标识来了才算完成合并，但在这之前，这些片段已经被分别合并送入ASR了，其中job0_1+job0_2=6秒，job0_3+job1_1=7秒，job1_2+job1_3=7秒，job2_1+job2_2=6秒，job2_3+job2_4+job3_1=9秒还是会出现5个语音识别文本的切片，如果utterance拼接需要等到这个5个切片都识别完成再发给语义修复服务，也会有一个很长的延迟，再加上语义修复和NMT和TTS处理的时间，用户可能需要等30秒以上才有结果，这就违背了流式处理的初衷。所以我希望在utterance中，将语音识别文本与job从头部对齐，也就是job0_1+job0_2=6秒作为job0的结果，job0_3+job1_1=7秒和job1_2+job1_3=7秒合并作为job1的结果，job2_1+job2_2=6秒和job2_3+job2_4+job3_1=9秒作为job2的结果进行下一步处理，发送给语义修复/NMT/TTS，返回web端，如果没有语音识别文本是以job3开头的，就把job3视为合并入job2了。也就是audioAggregator会将Job按能量切分，但utterance会将语音识别文本合并，只要第一个文本片段属于哪个job，就将这个文本片段作为该job的结果返回，哪怕这个文本片段是由多个超过5秒语音片段组成的。这样做的目的是确保切片数量不会超过job容器数量，不会产生文本丢失的情况



我完成了本次集成测试，阅读的文本是:"现在我们开始进行一次语音识别稳定性测试。
我会先读一两句比较短的话，用来确认系统不会在句子之间随意地把语音切断，或者在没有必要的时候提前结束本次识别。

接下来这一句我会尽量连续地说得长一些，中间只保留自然的呼吸节奏，不做刻意的停顿，看看在超过十秒钟之后，系统会不会因为超时或者静音判定而强行把这句话截断，从而导致前半句和后半句在节点端被拆成两个不同的 job，甚至出现语义上不完整、读起来前后不连贯的情况。

如果这次的长句能够被完整地识别出来，而且不会出现半句话被提前发送或者直接丢失的现象，那就说明我们当前的切分策略和超时规则是基本可用的。
否则，我们还需要继续分析日志，找出到底是在哪一个环节把我的语音吃掉了。"，返回结果是："",请检查节点端日志，看看每个job在各服务里的处理过程，输入是什么输出是什么




备份代码：
#终端1: 调度服务器
cd D:\Programs\github\lingua_1\expired\lingua_1-main\central_server\scheduler
cargo run --release

#终端2: 节点端
cd D:\Programs\github\lingua_1\expired\lingua_1-main\electron_node\electron-node
npm install
npm run build:main
npm start

#终端3: Web端
cd D:\Programs\github\lingua_1\expired\lingua_1-main\webapp\web-client
npm install
npm run dev



# 运行 Job 清理测试
cargo test job_cleanup_test --no-fail-fast

# 运行所有测试
cargo test --lib

# 编译检查
cargo check --lib

