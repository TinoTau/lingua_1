"""
Faster Whisper + Silero VAD Service
æ•´åˆ ASR å’Œ VAD åŠŸèƒ½ï¼Œæ”¯æŒä¸Šä¸‹æ–‡ç¼“å†²å’Œ Utterance ä»»åŠ¡å¤„ç†
ä¸¥æ ¼æŒ‰ç…§ç°æœ‰ Rust å®ç°
"""
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import numpy as np
import logging
import time
import asyncio
import signal
import sys
import traceback
from typing import Optional, List, Tuple, Dict, Any

# Configure logging (å¿…é¡»åœ¨å¯¼å…¥æ¨¡å—ä¹‹å‰ï¼Œå› ä¸ºå¯¼å…¥æ—¶å¯èƒ½ä½¿ç”¨logger)
# ç¡®ä¿ logs ç›®å½•å­˜åœ¨
import os
log_dir = 'logs'
if not os.path.exists(log_dir):
    os.makedirs(log_dir, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(os.path.join(log_dir, 'faster-whisper-vad-service.log'), encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# å…¨å±€å¼‚å¸¸å¤„ç†
def handle_exception(exc_type, exc_value, exc_traceback):
    """å…¨å±€å¼‚å¸¸å¤„ç†å™¨"""
    if issubclass(exc_type, KeyboardInterrupt):
        sys.__excepthook__(exc_type, exc_value, exc_traceback)
        return
    
    logger.critical("=" * 80)
    logger.critical("ğŸš¨ Uncaught exception in main process, service may crash")
    logger.critical(f"   Exception type: {exc_type.__name__}")
    logger.critical(f"   Exception value: {exc_value}")
    logger.critical("   Traceback:")
    for line in traceback.format_exception(exc_type, exc_value, exc_traceback):
        logger.critical(f"   {line.rstrip()}")
    logger.critical("=" * 80)
    
    # è°ƒç”¨é»˜è®¤å¼‚å¸¸å¤„ç†å™¨
    sys.__excepthook__(exc_type, exc_value, exc_traceback)

sys.excepthook = handle_exception

# ä¿¡å·å¤„ç†ï¼ˆç”¨äºè®°å½•ä¸»è¿›ç¨‹é€€å‡ºï¼‰
def signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å™¨"""
    logger.warning(f"Received signal {signum}, preparing to shutdown...")
    if signum == signal.SIGTERM:
        logger.info("SIGTERM received, graceful shutdown")
    elif signum == signal.SIGINT:
        logger.info("SIGINT received (Ctrl+C), graceful shutdown")
    else:
        logger.warning(f"Unexpected signal {signum} received")

# æ³¨å†Œä¿¡å·å¤„ç†å™¨ï¼ˆWindows ä¸Šå¯èƒ½ä¸æ”¯æŒæ‰€æœ‰ä¿¡å·ï¼‰
try:
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)
except (AttributeError, ValueError):
    # Windows å¯èƒ½ä¸æ”¯æŒæŸäº›ä¿¡å·
    logger.debug("Some signals not available on this platform")

# å¯¼å…¥é…ç½®å’Œæ¨¡å—
from config import (
    PORT,
    MAX_AUDIO_DURATION_SEC,
    CONTEXT_SAMPLE_RATE,
    CONTEXT_DURATION_SEC,
)
# æ³¨æ„ï¼šä¸å†å¯¼å…¥ asr_modelï¼ŒASR æ¨ç†åœ¨ç‹¬ç«‹å­è¿›ç¨‹ä¸­æ‰§è¡Œ
from models import vad_session  # åªå¯¼å…¥ VAD æ¨¡å‹
from vad import vad_state, detect_speech
from context import (
    get_context_audio,
    update_context_buffer,
    reset_context_buffer,
    get_text_context,
    update_text_context,
    reset_text_context,
)
from text_filter import is_meaningless_transcript
from audio_decoder import decode_audio
from asr_worker_manager import ASRWorkerManager, MAX_WAIT_SECONDS

# ---------------------
# FastAPI App
# ---------------------
app = FastAPI(title="Faster Whisper + Silero VAD Service")

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---------------------
# Request/Response Schemas
# ---------------------
class UtteranceRequest(BaseModel):
    """
    Utterance ä»»åŠ¡è¯·æ±‚
    ä¸ node-inference çš„ HttpInferenceRequest ä¿æŒä¸€è‡´
    """
    job_id: str  # ä»»åŠ¡ IDï¼ˆç”¨äºè¿½è¸ªï¼‰
    src_lang: str  # æºè¯­è¨€ï¼ˆæ”¯æŒ "auto" | "zh" | "en" | "ja" | "ko"ï¼‰
    tgt_lang: Optional[str] = None  # ç›®æ ‡è¯­è¨€ï¼ˆå¯é€‰ï¼ŒASR æœåŠ¡ä¸ä½¿ç”¨ï¼‰
    audio: str  # Base64 encoded audioï¼ˆä¸ node-inference ä¸€è‡´ï¼‰
    audio_format: Optional[str] = "pcm16"  # éŸ³é¢‘æ ¼å¼ï¼ˆ"pcm16" | "opus" ç­‰ï¼‰
    sample_rate: Optional[int] = 16000  # é‡‡æ ·ç‡
    # ASR ç‰¹å®šå‚æ•°
    language: Optional[str] = None  # è¯­è¨€ä»£ç ï¼ˆå¦‚æœ src_lang == "auto"ï¼Œåˆ™è‡ªåŠ¨æ£€æµ‹ï¼‰
    task: str = "transcribe"  # "transcribe" or "translate"
    beam_size: int = 5
    condition_on_previous_text: bool = False  # ç¦ç”¨æ¡ä»¶ç”Ÿæˆï¼Œé¿å…é‡å¤è¯†åˆ«ï¼ˆå½“ä¸Šä¸‹æ–‡æ–‡æœ¬å’Œå½“å‰éŸ³é¢‘å†…å®¹ç›¸åŒæ—¶ï¼Œä¼šå¯¼è‡´é‡å¤è¾“å‡ºï¼‰
    use_context_buffer: bool = True  # æ˜¯å¦ä½¿ç”¨ä¸Šä¸‹æ–‡ç¼“å†²åŒº
    use_text_context: bool = True  # æ˜¯å¦ä½¿ç”¨æ–‡æœ¬ä¸Šä¸‹æ–‡
    # å…¶ä»–å‚æ•°ï¼ˆä¸ node-inference ä¿æŒä¸€è‡´ï¼Œä½† ASR æœåŠ¡ä¸ä½¿ç”¨ï¼‰
    features: Optional[dict] = None  # å¯é€‰åŠŸèƒ½è¯·æ±‚ï¼ˆASR æœåŠ¡ä¸ä½¿ç”¨ï¼‰
    mode: Optional[str] = None  # ç¿»è¯‘æ¨¡å¼ï¼ˆASR æœåŠ¡ä¸ä½¿ç”¨ï¼‰
    lang_a: Optional[str] = None  # åŒå‘æ¨¡å¼è¯­è¨€ Aï¼ˆASR æœåŠ¡ä¸ä½¿ç”¨ï¼‰
    lang_b: Optional[str] = None  # åŒå‘æ¨¡å¼è¯­è¨€ Bï¼ˆASR æœåŠ¡ä¸ä½¿ç”¨ï¼‰
    auto_langs: Optional[List[str]] = None  # è‡ªåŠ¨è¯†åˆ«è¯­è¨€èŒƒå›´ï¼ˆASR æœåŠ¡ä¸ä½¿ç”¨ï¼‰
    enable_streaming_asr: Optional[bool] = False  # æ˜¯å¦å¯ç”¨æµå¼ ASRï¼ˆå½“å‰ä¸æ”¯æŒï¼‰
    partial_update_interval_ms: Optional[int] = None  # éƒ¨åˆ†ç»“æœæ›´æ–°é—´éš”ï¼ˆå½“å‰ä¸æ”¯æŒï¼‰
    trace_id: Optional[str] = None  # è¿½è¸ª IDï¼ˆç”¨äºå…¨é“¾è·¯æ—¥å¿—è¿½è¸ªï¼‰
    context_text: Optional[str] = None  # ä¸Šä¸‹æ–‡æ–‡æœ¬ï¼ˆç”¨äº NMTï¼ŒASR æœåŠ¡ä¸ä½¿ç”¨ï¼‰

class UtteranceResponse(BaseModel):
    """Utterance ä»»åŠ¡å“åº”"""
    text: str  # Full transcribed text
    segments: List[str]  # List of segment texts
    language: Optional[str] = None  # Detected language
    duration: float  # Audio duration in seconds
    vad_segments: List[Tuple[int, int]]  # VAD æ£€æµ‹åˆ°çš„è¯­éŸ³æ®µï¼ˆæ ·æœ¬ç´¢å¼•ï¼‰

class ResetRequest(BaseModel):
    """é‡ç½®è¯·æ±‚"""
    reset_vad: bool = True  # é‡ç½® VAD çŠ¶æ€
    reset_context: bool = True  # é‡ç½®ä¸Šä¸‹æ–‡ç¼“å†²åŒº
    reset_text_context: bool = True  # é‡ç½®æ–‡æœ¬ä¸Šä¸‹æ–‡

# ---------------------
# Global ASR Worker Manager
# ---------------------
_asr_worker_manager: Optional[ASRWorkerManager] = None

def get_asr_worker_manager() -> ASRWorkerManager:
    """è·å–å…¨å±€ ASR Worker Manager å®ä¾‹"""
    global _asr_worker_manager
    if _asr_worker_manager is None:
        _asr_worker_manager = ASRWorkerManager()
    return _asr_worker_manager

# ---------------------
# Health Check
# ---------------------
@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼ŒåŒ…å«ASR WorkerçŠ¶æ€"""
    manager = get_asr_worker_manager()
    stats = manager.get_stats()
    return {
        "status": "ok",
        "asr_model_loaded": stats.get("worker_pid") is not None,  # å¦‚æœ worker è¿›ç¨‹å­˜åœ¨ï¼Œè¯´æ˜æ¨¡å‹å·²åŠ è½½
        "vad_model_loaded": True,
        "asr_worker": {
            "is_running": stats["is_running"],
            "worker_state": stats["worker_state"],
            "worker_pid": stats["worker_pid"],
            "queue_depth": stats["queue_depth"],
            "total_tasks": stats["total_tasks"],
            "completed_tasks": stats["completed_tasks"],
            "failed_tasks": stats["failed_tasks"],
            "worker_restarts": stats["worker_restarts"],
            "avg_wait_ms": round(stats["avg_wait_ms"], 2),
            "pending_results": stats["pending_results"],
        }
    }

# ---------------------
# Reset Endpoint
# ---------------------
@app.post("/reset")
def reset_state(req: ResetRequest):
    """é‡ç½® VAD çŠ¶æ€å’Œä¸Šä¸‹æ–‡ç¼“å†²åŒº"""
    if req.reset_vad:
        vad_state.reset()
        logger.info("âœ… VAD state reset")
    
    if req.reset_context:
        reset_context_buffer()
        logger.info("âœ… Context buffer reset")
    
    if req.reset_text_context:
        reset_text_context()
        logger.info("âœ… Text context cache reset")
    
    return {"status": "ok"}

# ---------------------
# Startup/Shutdown Events
# ---------------------
@app.on_event("startup")
async def startup():
    """å¯åŠ¨ASR Worker Manager"""
    try:
        logger.info("=" * 80)
        logger.info("ğŸš€ Starting Faster Whisper + Silero VAD Service")
        logger.info(f"   Main process PID: {os.getpid()}")
        logger.info(f"   Port: {PORT}")
        logger.info("=" * 80)
        
        manager = get_asr_worker_manager()
        await manager.start()
        logger.info("âœ… ASR Worker Manager started on startup")
    except Exception as e:
        logger.critical(f"âŒ Failed to start ASR Worker Manager: {e}", exc_info=True)
        raise

@app.on_event("shutdown")
async def shutdown():
    """åœæ­¢ASR Worker Manager"""
    try:
        logger.info("=" * 80)
        logger.info("ğŸ›‘ Shutting down Faster Whisper + Silero VAD Service")
        logger.info(f"   Main process PID: {os.getpid()}")
        logger.info("=" * 80)
        
        global _asr_worker_manager
        if _asr_worker_manager:
            await _asr_worker_manager.stop()
            _asr_worker_manager = None
        logger.info("âœ… ASR Worker Manager stopped on shutdown")
    except Exception as e:
        logger.error(f"âŒ Error during shutdown: {e}", exc_info=True)

# ---------------------
# Utterance Endpoint
# ---------------------
@app.post("/utterance", response_model=UtteranceResponse)
async def process_utterance(req: UtteranceRequest):
    """
    å¤„ç† Utterance ä»»åŠ¡
    ä¸¥æ ¼æŒ‰ç…§ç°æœ‰å®ç°ï¼Œä¸ node-inference æ¥å£ä¿æŒä¸€è‡´ï¼š
    1. è§£ç éŸ³é¢‘ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
    2. å‰ç½®ä¸Šä¸‹æ–‡éŸ³é¢‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    3. ä½¿ç”¨ VAD æ£€æµ‹æœ‰æ•ˆè¯­éŸ³æ®µ
    4. ä½¿ç”¨ Faster Whisper è¿›è¡Œ ASR
    5. æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒº
    """
    trace_id = req.trace_id or req.job_id
    # ä¸¥æ ¼æŒ‰ç…§ node-inference çš„æ—¥å¿—æ ¼å¼
    logger.info(f"[{trace_id}] Received utterance request: job_id={req.job_id}, audio_format={req.audio_format}, sample_rate={req.sample_rate}")
    logger.debug(
        f"[{trace_id}] "
        f"trace_id={trace_id} "
        f"job_id={req.job_id} "
        f"'å¼€å§‹å¤„ç†æ¨ç†è¯·æ±‚'"
    )
    
    try:
        # 1. è§£ç éŸ³é¢‘
        audio_format = req.audio_format or "pcm16"
        sample_rate = req.sample_rate or 16000
        
        logger.info(f"[{trace_id}] Audio format: {audio_format}, sample_rate: {sample_rate}")
        
        try:
            audio, sr = decode_audio(req.audio, audio_format, sample_rate, trace_id)
        except ValueError as e:
            logger.error(f"[{trace_id}] Audio decoding failed: {e}")
            raise HTTPException(status_code=400, detail=str(e))
        except Exception as e:
            # æ•è·æ‰€æœ‰å…¶ä»–å¼‚å¸¸ï¼ˆåŒ…æ‹¬å¯èƒ½çš„segfaultå‰çš„å¼‚å¸¸ï¼‰
            logger.critical(
                f"[{trace_id}] ğŸš¨ CRITICAL: Audio decoding raised unexpected exception: {e}, "
                f"error_type={type(e).__name__}",
                exc_info=True
            )
            raise HTTPException(status_code=500, detail=f"Audio decoding error: {str(e)}")
        
        # 2. æ£€æŸ¥éŸ³é¢‘é•¿åº¦é™åˆ¶ï¼ˆé˜²æ­¢ GPU å†…å­˜æº¢å‡ºå’Œæ ˆç¼“å†²åŒºæº¢å‡ºï¼‰
        audio_duration = len(audio) / sr
        if audio_duration > MAX_AUDIO_DURATION_SEC:
            logger.warning(
                f"[{trace_id}] Audio duration ({audio_duration:.2f}s) exceeds maximum ({MAX_AUDIO_DURATION_SEC}s), "
                f"truncating to {MAX_AUDIO_DURATION_SEC}s"
            )
            max_samples = int(MAX_AUDIO_DURATION_SEC * sr)
            audio = audio[:max_samples]
        
        # 3. é‡é‡‡æ ·åˆ°æŒ‡å®šé‡‡æ ·ç‡ï¼ˆé»˜è®¤ 16kHzï¼‰
        if sr != sample_rate:
            logger.warning(f"[{trace_id}] Audio sample rate is {sr}Hz, expected {sample_rate}Hz. Resampling...")
            from scipy import signal
            num_samples = int(len(audio) * sample_rate / sr)
            audio = signal.resample(audio, num_samples).astype(np.float32)
            sr = sample_rate
        
        # 3.1 é‡é‡‡æ ·åå†æ¬¡æ£€æŸ¥éŸ³é¢‘é•¿åº¦é™åˆ¶
        audio_duration = len(audio) / sr
        if audio_duration > MAX_AUDIO_DURATION_SEC:
            logger.warning(
                f"[{trace_id}] Audio duration after resampling ({audio_duration:.2f}s) exceeds maximum ({MAX_AUDIO_DURATION_SEC}s), "
                f"truncating to {MAX_AUDIO_DURATION_SEC}s"
            )
            max_samples = int(MAX_AUDIO_DURATION_SEC * sr)
            audio = audio[:max_samples]
        
        # ç¡®ä¿éŸ³é¢‘æ˜¯è¿ç»­çš„
        if not audio.flags['C_CONTIGUOUS']:
            audio = np.ascontiguousarray(audio)
        
        # 4. ç¡®å®šè¯­è¨€ï¼ˆå¦‚æœ src_lang == "auto"ï¼Œåˆ™ä½¿ç”¨ language æˆ–è‡ªåŠ¨æ£€æµ‹ï¼‰
        asr_language = None
        if req.src_lang != "auto":
            asr_language = req.src_lang
        elif req.language:
            asr_language = req.language
        # å¦‚æœéƒ½æ˜¯ Noneï¼ŒFaster Whisper ä¼šè‡ªåŠ¨æ£€æµ‹
        
        # ä¸¥æ ¼æŒ‰ç…§ node-inference çš„æ—¥å¿—æ ¼å¼
        logger.debug(f"[{trace_id}] trace_id={trace_id} src_lang={req.src_lang} 'å¼€å§‹ ASR è¯­éŸ³è¯†åˆ«'")
        
        # 5. å‰ç½®ä¸Šä¸‹æ–‡éŸ³é¢‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        # ä¸¥æ ¼æŒ‰ç…§ node-inference çš„æ—¥å¿—æ ¼å¼
        if req.use_context_buffer:
            context_audio = get_context_audio()
            if len(context_audio) > 0:
                audio_with_context = np.concatenate([context_audio, audio])
                context_duration_sec = len(context_audio) / sr
                original_duration_sec = len(audio) / sr
                total_duration_sec = len(audio_with_context) / sr
                logger.info(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"context_samples={len(context_audio)} "
                    f"context_duration_sec={context_duration_sec:.3f} "
                    f"original_samples={len(audio)} "
                    f"original_duration_sec={original_duration_sec:.3f} "
                    f"total_samples={len(audio_with_context)} "
                    f"total_duration_sec={total_duration_sec:.3f} "
                    f"'âœ… å‰ç½®ä¸Šä¸‹æ–‡éŸ³é¢‘åˆ°å½“å‰utteranceï¼ˆä¸Šä¸‹æ–‡ç¼“å†²åŒºä¸ä¸ºç©ºï¼‰'"
                )
            else:
                audio_with_context = audio
                logger.info(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"original_samples={len(audio)} "
                    f"original_duration_sec={len(audio)/sr:.3f} "
                    f"'â„¹ï¸ ä¸Šä¸‹æ–‡ç¼“å†²åŒºä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘ï¼ˆç¬¬ä¸€ä¸ªutteranceæˆ–ä¸Šä¸‹æ–‡å·²æ¸…ç©ºï¼‰'"
                )
        else:
            audio_with_context = audio
        
        # 6. ä½¿ç”¨ VAD æ£€æµ‹æœ‰æ•ˆè¯­éŸ³æ®µï¼ˆLevel 2æ–­å¥ï¼‰
        # ä¸¥æ ¼æŒ‰ç…§ node-inference çš„æ—¥å¿—æ ¼å¼
        try:
            vad_segments = detect_speech(audio_with_context)
        except Exception as e:
            # VADæ£€æµ‹å¤±è´¥ï¼Œå›é€€åˆ°å®Œæ•´éŸ³é¢‘
            logger.warning(
                f"[{trace_id}] trace_id={trace_id} "
                f"error='{str(e)}' "
                f"'VADæ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨å®Œæ•´éŸ³é¢‘è¿›è¡ŒASR'"
            )
            vad_segments = []
        
        if len(vad_segments) == 0:
            logger.warning(
                f"[{trace_id}] trace_id={trace_id} "
                f"'VADæœªæ£€æµ‹åˆ°è¯­éŸ³æ®µï¼Œä½¿ç”¨å®Œæ•´éŸ³é¢‘è¿›è¡ŒASR'"
            )
            processed_audio = audio_with_context
        else:
            # æå–æœ‰æ•ˆè¯­éŸ³æ®µï¼ˆå»é™¤é™éŸ³éƒ¨åˆ†ï¼‰
            processed_audio_parts = []
            for start, end in vad_segments:
                processed_audio_parts.append(audio_with_context[start:end])
            processed_audio = np.concatenate(processed_audio_parts)
            
            logger.info(
                f"[{trace_id}] trace_id={trace_id} "
                f"segments_count={len(vad_segments)} "
                f"original_samples={len(audio_with_context)} "
                f"processed_samples={len(processed_audio)} "
                f"removed_samples={len(audio_with_context) - len(processed_audio)} "
                f"'VADæ£€æµ‹åˆ°{len(vad_segments)}ä¸ªè¯­éŸ³æ®µï¼Œå·²æå–æœ‰æ•ˆè¯­éŸ³'"
            )
            
            # å¦‚æœå¤„ç†åçš„éŸ³é¢‘å¤ªçŸ­ï¼ˆ< 0.5ç§’ï¼‰ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘
            MIN_AUDIO_SAMPLES = int(sr * 0.5)  # 0.5ç§’
            if len(processed_audio) < MIN_AUDIO_SAMPLES:
                logger.warning(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"processed_samples={len(processed_audio)} "
                    f"'VADå¤„ç†åçš„éŸ³é¢‘è¿‡çŸ­ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘'"
                )
                processed_audio = audio_with_context
        
        # 6.1 æœ€ç»ˆæ£€æŸ¥ï¼šç¡®ä¿ä¼ é€’ç»™ Faster Whisper çš„éŸ³é¢‘ä¸è¶…è¿‡æœ€å¤§é•¿åº¦
        processed_audio_duration = len(processed_audio) / sr
        if processed_audio_duration > MAX_AUDIO_DURATION_SEC:
            logger.warning(
                f"[{trace_id}] Processed audio duration ({processed_audio_duration:.2f}s) exceeds maximum ({MAX_AUDIO_DURATION_SEC}s), "
                f"truncating to {MAX_AUDIO_DURATION_SEC}s before ASR"
            )
            max_samples = int(MAX_AUDIO_DURATION_SEC * sr)
            processed_audio = processed_audio[:max_samples]
        
        # 7. è·å–æ–‡æœ¬ä¸Šä¸‹æ–‡ï¼ˆç”¨äº Faster Whisper çš„ initial_promptï¼‰
        text_context = ""
        if req.use_text_context:
            text_context = get_text_context()
            if text_context:
                logger.info(
                    f"[{trace_id}] "
                    f"Using text context ({len(text_context)} chars): \"{text_context[:100]}...\""
                )
        
        # 8. éªŒè¯éŸ³é¢‘æ•°æ®æ ¼å¼ï¼ˆé˜²æ­¢Faster Whisperå´©æºƒï¼‰
        # æ£€æŸ¥éŸ³é¢‘æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        if len(processed_audio) == 0:
            logger.error(f"[{trace_id}] Processed audio is empty, cannot perform ASR")
            raise HTTPException(status_code=400, detail="Processed audio is empty")
        
        # æ£€æŸ¥NaNå’ŒInfå€¼
        if np.any(np.isnan(processed_audio)) or np.any(np.isinf(processed_audio)):
            logger.error(f"[{trace_id}] Processed audio contains NaN or Inf values")
            # æ¸…ç†NaNå’ŒInfå€¼
            processed_audio = np.nan_to_num(processed_audio, nan=0.0, posinf=1.0, neginf=-1.0)
            logger.warning(f"[{trace_id}] Cleaned NaN/Inf values from audio")
        
        # ç¡®ä¿éŸ³é¢‘æ•°æ®åœ¨æœ‰æ•ˆèŒƒå›´å†…ï¼ˆ[-1.0, 1.0]ï¼‰
        if np.any(np.abs(processed_audio) > 1.0):
            logger.warning(f"[{trace_id}] Audio values out of range [-1.0, 1.0], clipping")
            processed_audio = np.clip(processed_audio, -1.0, 1.0)
        
        # ç¡®ä¿éŸ³é¢‘æ˜¯è¿ç»­çš„numpyæ•°ç»„
        if not isinstance(processed_audio, np.ndarray):
            processed_audio = np.array(processed_audio, dtype=np.float32)
        if processed_audio.dtype != np.float32:
            processed_audio = processed_audio.astype(np.float32)
        if not processed_audio.flags['C_CONTIGUOUS']:
            processed_audio = np.ascontiguousarray(processed_audio)
        
        # è®°å½•éŸ³é¢‘æ•°æ®ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•å’Œå´©æºƒè¯Šæ–­ï¼‰
        audio_std = np.std(processed_audio)
        audio_rms = np.sqrt(np.mean(processed_audio ** 2))
        audio_dynamic_range = np.max(processed_audio) - np.min(processed_audio)
        audio_duration = len(processed_audio) / sr
        
        logger.info(
            f"[{trace_id}] Audio data validation: "
            f"shape={processed_audio.shape}, "
            f"dtype={processed_audio.dtype}, "
            f"min={np.min(processed_audio):.4f}, "
            f"max={np.max(processed_audio):.4f}, "
            f"mean={np.mean(processed_audio):.4f}, "
            f"std={audio_std:.4f}, "
            f"rms={audio_rms:.4f}, "
            f"dynamic_range={audio_dynamic_range:.4f}, "
            f"duration={audio_duration:.3f}s, "
            f"is_contiguous={processed_audio.flags['C_CONTIGUOUS']}"
        )
        
        # 7.5. éŸ³é¢‘è´¨é‡æ£€æŸ¥ï¼ˆé˜²æ­¢ä½è´¨é‡éŸ³é¢‘è¿›å…¥ ASRï¼‰
        # å¦‚æœéŸ³é¢‘è´¨é‡å¤ªå·®ï¼Œç›´æ¥è¿”å›ç©ºå“åº”ï¼Œé¿å…æµªè´¹ ASR èµ„æº
        # æ³¨æ„ï¼šFaster Whisper é€šå¸¸éœ€è¦è‡³å°‘ 0.5-1 ç§’çš„éŸ³é¢‘æ‰èƒ½æœ‰æ•ˆè¯†åˆ«
        # è™½ç„¶ 0.24 ç§’çš„éŸ³é¢‘å¯èƒ½é€šè¿‡è´¨é‡æ£€æŸ¥ï¼Œä½† Whisper å¯èƒ½æ— æ³•è¯†åˆ«å‡ºæœ‰æ•ˆå†…å®¹
        # è°ƒæ•´é˜ˆå€¼ä»¥é€‚åº”å®é™…ä½¿ç”¨åœºæ™¯å’ŒOpusç¼–ç åçš„éŸ³é¢‘è´¨é‡
        # å…³é”®ä¿®å¤ï¼šæé«˜é˜ˆå€¼ï¼Œè¿‡æ»¤æ›´å¤šä½è´¨é‡éŸ³é¢‘
        # ä»æ—¥å¿—çœ‹ï¼ŒRMS=0.0018ã€STD=0.0018 è™½ç„¶é€šè¿‡äº†é˜ˆå€¼ï¼ˆ0.0005ï¼‰ï¼Œ
        # ä½†Faster Whisperä»ç„¶æ— æ³•è¯†åˆ«å‡ºæ–‡æœ¬ï¼Œè¯´æ˜é˜ˆå€¼å¤ªä½
        # æé«˜é˜ˆå€¼ï¼Œåªè®©é«˜è´¨é‡éŸ³é¢‘è¿›å…¥ASR
        MIN_AUDIO_RMS = 0.002  # æœ€å° RMS èƒ½é‡ï¼ˆä» 0.0005 æé«˜åˆ° 0.002ï¼Œè¿‡æ»¤æ›´å¤šä½è´¨é‡éŸ³é¢‘ï¼‰
        MIN_AUDIO_STD = 0.002  # æœ€å°æ ‡å‡†å·®ï¼ˆä» 0.0005 æé«˜åˆ° 0.002ï¼Œè¿‡æ»¤æ›´å¤šä½è´¨é‡éŸ³é¢‘ï¼‰
        MIN_AUDIO_DYNAMIC_RANGE = 0.01  # æœ€å°åŠ¨æ€èŒƒå›´ï¼ˆä» 0.002 æé«˜åˆ° 0.01ï¼Œè¿‡æ»¤æ›´å¤šä½è´¨é‡éŸ³é¢‘ï¼‰
        # å…³é”®ä¿®å¤ï¼šå¢åŠ æœ€çŸ­éŸ³é¢‘æ—¶é•¿æ£€æŸ¥
        # Faster Whisper é€šå¸¸éœ€è¦è‡³å°‘ 0.5-1 ç§’çš„éŸ³é¢‘æ‰èƒ½æœ‰æ•ˆè¯†åˆ«
        # è™½ç„¶è´¨é‡æ£€æŸ¥å…è®¸ 0.3 ç§’ï¼Œä½†å®é™… ASR è¯†åˆ«éœ€è¦æ›´é•¿çš„éŸ³é¢‘
        MIN_AUDIO_DURATION = 0.5  # æœ€å°æ—¶é•¿ï¼ˆç§’ï¼‰ï¼ŒFaster Whisper éœ€è¦è‡³å°‘ 0.5 ç§’æ‰èƒ½æœ‰æ•ˆè¯†åˆ«
        
        audio_quality_issues = []
        
        if audio_rms < MIN_AUDIO_RMS:
            audio_quality_issues.append(f"RMS too low ({audio_rms:.4f} < {MIN_AUDIO_RMS})")
        
        if audio_std < MIN_AUDIO_STD:
            audio_quality_issues.append(f"std too low ({audio_std:.4f} < {MIN_AUDIO_STD})")
        
        if audio_dynamic_range < MIN_AUDIO_DYNAMIC_RANGE:
            audio_quality_issues.append(f"dynamic_range too small ({audio_dynamic_range:.4f} < {MIN_AUDIO_DYNAMIC_RANGE})")
        
        if audio_duration < MIN_AUDIO_DURATION:
            audio_quality_issues.append(f"duration too short ({audio_duration:.3f}s < {MIN_AUDIO_DURATION}s)")
        
        if audio_quality_issues:
            logger.warning(
                f"[{trace_id}] trace_id={trace_id} "
                f"audio_rms={audio_rms:.4f} "
                f"audio_std={audio_std:.4f} "
                f"audio_dynamic_range={audio_dynamic_range:.4f} "
                f"audio_duration={audio_duration:.3f}s "
                f"issues={', '.join(audio_quality_issues)} "
                f"'Audio quality too poor (likely silence, noise, or decoding issue), skipping ASR and returning empty response'"
            )
            # è¿”å›ç©ºç»“æœï¼Œä¸è°ƒç”¨ ASR
            return UtteranceResponse(
                text="",
                segments=[],
                language=asr_language or "unknown",
                duration=audio_duration,
                vad_segments=vad_segments,
            )
        
        # 8. ä½¿ç”¨ ASR Worker Manager è¿›è¡Œ ASRï¼ˆè¿›ç¨‹éš”ç¦»æ¶æ„ï¼‰
        asr_start_time = time.time()
        
        # è·å–ASR Worker Manager
        manager = get_asr_worker_manager()
        
        # æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å·²æ»¡ï¼ˆèƒŒå‹æ§åˆ¶ï¼‰
        if manager.is_queue_full():
            stats = manager.get_stats()
            logger.warning(
                f"[{trace_id}] ASR queue is full, returning 503 Service Busy. "
                f"queue_depth={stats['queue_depth']}"
            )
            raise HTTPException(
                status_code=503,
                detail="ASR service is busy, please retry later",
                headers={"Retry-After": "1"}
            )
        
        # åœ¨è°ƒç”¨transcribeä¹‹å‰è®°å½•å…³é”®ä¿¡æ¯ï¼ˆåŒ…æ‹¬ä¸Šä¸‹æ–‡ï¼‰
        stats = manager.get_stats()
        logger.info(
            f"[{trace_id}] ========== ASR è¯†åˆ«è¯·æ±‚å¼€å§‹ =========="
        )
        logger.info(
            f"[{trace_id}] ASR å‚æ•°: "
            f"language={asr_language}, "
            f"task={req.task}, "
            f"beam_size={req.beam_size}, "
            f"condition_on_previous_text={req.condition_on_previous_text}, "
            f"queue_depth={stats['queue_depth']}, "
            f"worker_state={stats['worker_state']}"
        )
        logger.info(
            f"[{trace_id}] ASR ä¸Šä¸‹æ–‡å‚æ•°: "
            f"has_initial_prompt={text_context is not None and len(text_context) > 0}, "
            f"initial_prompt_length={len(text_context) if text_context else 0}, "
            f"initial_prompt_preview='{text_context[:100] if text_context else '(None)'}'"
        )
        logger.info(
            f"[{trace_id}] ASR éŸ³é¢‘å‚æ•°: "
            f"audio_len={len(processed_audio)}, "
            f"sample_rate={sr}, "
            f"duration_sec={len(processed_audio) / sr:.2f}"
        )
        
        try:
            # æäº¤ä»»åŠ¡åˆ°ASR Workerè¿›ç¨‹
            asr_result = await manager.submit_task(
                audio=processed_audio,
                sample_rate=sr,
                language=asr_language,
                task=req.task,
                beam_size=req.beam_size,
                initial_prompt=text_context if text_context else None,
                condition_on_previous_text=req.condition_on_previous_text,
                trace_id=trace_id,
                max_wait=MAX_WAIT_SECONDS
            )
            
            # æ£€æŸ¥ç»“æœ
            if asr_result.error:
                logger.error(
                    f"[{trace_id}] ASR Worker returned error: {asr_result.error}",
                    exc_info=True
                )
                raise HTTPException(
                    status_code=500,
                    detail=f"ASR processing failed: {asr_result.error}"
                )
            
            # ä»ç»“æœä¸­è·å–æ–‡æœ¬å’Œè¯­è¨€ä¿¡æ¯
            full_text = asr_result.text or ""
            detected_language = asr_result.language
            duration_sec = asr_result.duration_ms / 1000.0 if asr_result.duration_ms > 0 else 0.0
            
            logger.info(
                f"[{trace_id}] ========== ASR æ¥å£è¾“å‡ºç»“æœ =========="
            )
            logger.info(
                f"[{trace_id}] ASR Worker completed successfully, "
                f"text_len={len(full_text)}, language={detected_language}, "
                f"duration_ms={asr_result.duration_ms}"
            )
            logger.info(
                f"[{trace_id}] ASR æ¥å£è¾“å‡ºåŸå§‹æ–‡æœ¬ (repr): {repr(full_text)}"
            )
            logger.info(
                f"[{trace_id}] ASR æ¥å£è¾“å‡ºåŸå§‹æ–‡æœ¬ (preview): '{full_text[:200]}'"
            )
            logger.info(
                f"[{trace_id}] ASR æ¥å£è¾“å‡ºåŸå§‹æ–‡æœ¬ (bytes): {full_text.encode('utf-8') if full_text else b''}"
            )
            
            # æ³¨æ„ï¼šè¿›ç¨‹éš”ç¦»æ¶æ„ä¸‹ï¼Œsegments å·²ç»åœ¨å­è¿›ç¨‹ä¸­è½¬æ¢ä¸ºæ–‡æœ¬
            # æˆ‘ä»¬ä¸å†éœ€è¦å¤„ç† segments å¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨è¿”å›çš„æ–‡æœ¬
            # ä¸ºäº†å…¼å®¹å“åº”æ ¼å¼ï¼Œæˆ‘ä»¬éœ€è¦å°†æ–‡æœ¬åˆ†å‰²ä¸º segments
            # ç®€å•å¤„ç†ï¼šæŒ‰ç©ºæ ¼åˆ†å‰²ï¼ˆå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´æ™ºèƒ½çš„åˆ†å‰²ï¼‰
            # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨åŸå§‹æ–‡æœ¬ï¼Œå› ä¸ºå»é‡ä¼šåœ¨Step 9.2ä¸­è¿›è¡Œ
            segment_texts = [s.strip() for s in full_text.split() if s.strip()]
            if not segment_texts:
                segment_texts = [full_text] if full_text else []
            
            # ä¿å­˜æ£€æµ‹åˆ°çš„è¯­è¨€å’Œæ—¶é•¿ï¼Œä¾›åç»­ä½¿ç”¨
            info_language = detected_language
            info_duration = duration_sec
            
        except asyncio.TimeoutError:
            stats = manager.get_stats()
            logger.error(
                f"[{trace_id}] ASR task timeout after {MAX_WAIT_SECONDS}s, "
                f"queue_depth={stats['queue_depth']}"
            )
            raise HTTPException(
                status_code=504,
                detail=f"ASR processing timeout after {MAX_WAIT_SECONDS}s"
            )
        except RuntimeError as e:
            # Worker è¿›ç¨‹ä¸å¯ç”¨
            logger.error(
                f"[{trace_id}] ASR Worker process not available: {e}",
                exc_info=True
            )
            raise HTTPException(
                status_code=503,
                detail="ASR service is temporarily unavailable, please retry later",
                headers={"Retry-After": "2"}
            )
        except Exception as e:
            logger.error(
                f"[{trace_id}] ASR Worker exception: {e}",
                exc_info=True
            )
            raise HTTPException(
                status_code=500,
                detail=f"ASR processing failed: {str(e)}"
            )
        
        asr_elapsed = time.time() - asr_start_time
        
        logger.info(f"[{trace_id}] Step 8.1: Text extraction completed, segments={len(segment_texts)}, full_text_len={len(full_text)}")
        
        # è®°å½• ASR å¤„ç†æ—¶é—´ï¼ˆç”¨äºæ€§èƒ½ç›‘æ§ï¼‰
        if asr_elapsed > 1.0:
            audio_duration = len(processed_audio) / sr
            ratio = asr_elapsed / audio_duration if audio_duration > 0 else 0
            logger.warning(
                f"[{trace_id}] "
                f"âš ï¸ ASR processing took {asr_elapsed:.2f}s "
                f"(audio duration: {audio_duration:.2f}s, ratio: {ratio:.2f}x)"
            )
        
        logger.info(f"[{trace_id}] Step 9: Starting ASR result processing")
        
        # 9. ASR è¯†åˆ«å®Œæˆï¼Œè®°å½•ç»“æœ
        # ä¸¥æ ¼æŒ‰ç…§ node-inference çš„æ—¥å¿—æ ¼å¼
        try:
            full_text_trimmed = full_text.strip()
            logger.info(f"[{trace_id}] Step 9.1: Text trimmed, len={len(full_text_trimmed)}")
            
            # 9.2. å»é‡å¤„ç†ï¼šç§»é™¤é‡å¤çš„æ–‡æœ¬ç‰‡æ®µ
            # é—®é¢˜ï¼šASRæ¨¡å‹ä½¿ç”¨initial_promptå’Œcondition_on_previous_textå¯èƒ½å¯¼è‡´é‡å¤è¯†åˆ«
            # ä¾‹å¦‚ï¼š"è¿™è¾¹èƒ½ä¸èƒ½ç”¨è¿™è¾¹èƒ½ä¸èƒ½ç”¨" -> "è¿™è¾¹èƒ½ä¸èƒ½ç”¨"
            if full_text_trimmed:
                from text_deduplicator import deduplicate_text
                original_text = full_text_trimmed
                full_text_trimmed = deduplicate_text(full_text_trimmed, trace_id=trace_id)
                
                # å¦‚æœæ–‡æœ¬è¢«ä¿®æ”¹ï¼Œè®°å½•æ—¥å¿—
                if full_text_trimmed != original_text:
                    logger.info(
                        f"[{trace_id}] Step 9.2: Deduplication applied, "
                        f"original_len={len(original_text)}, "
                        f"deduplicated_len={len(full_text_trimmed)}, "
                        f"original_text=\"{original_text[:100]}\", "
                        f"deduplicated_text=\"{full_text_trimmed[:100]}\""
                    )
        except Exception as e:
            logger.error(f"[{trace_id}] Step 9.1: Failed to trim text: {e}", exc_info=True)
            raise
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‹¬å·ï¼ˆç”¨äºè°ƒè¯•ï¼Œä¸ node-inference ä¸€è‡´ï¼‰
        try:
            if '(' in full_text_trimmed or 'ï¼ˆ' in full_text_trimmed or '[' in full_text_trimmed or 'ã€' in full_text_trimmed:
                logger.warning(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"transcript='{full_text_trimmed}' "
                    f"transcript_len={len(full_text_trimmed)} "
                    f"'âš ï¸ [ASR Filter Check] Transcript contains brackets before setting to context!'"
                )
        except Exception as e:
            logger.error(f"[{trace_id}] Step 9.2: Failed to check brackets: {e}", exc_info=True)
        
        logger.info(
            f"[{trace_id}] trace_id={trace_id} "
            f"transcript_len={len(full_text)} "
            f"transcript_preview='{full_text[:50]}' "
            f"transcript_trimmed_len={len(full_text_trimmed)} "
            f"transcript_deduplicated_preview='{full_text_trimmed[:50]}' "
            f"'âœ… ASR è¯†åˆ«å®Œæˆ'"
        )
        
        # åœ¨å»é‡åï¼Œé‡æ–°ç”Ÿæˆ segment_textsï¼ˆä½¿ç”¨å»é‡åçš„æ–‡æœ¬ï¼‰
        # è¿™æ ·è¿”å›çš„ segments ä¹Ÿæ˜¯å»é‡åçš„
        segment_texts = [s.strip() for s in full_text_trimmed.split() if s.strip()]
        if not segment_texts:
            segment_texts = [full_text_trimmed] if full_text_trimmed else []
        
        logger.info(f"[{trace_id}] Step 10: Starting text validation")
        
        # 10. æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ä¸ºæ— æ„ä¹‰çš„è¯†åˆ«ç»“æœï¼ˆä¸¥æ ¼æŒ‰ç…§ node_inference å®ç°ï¼‰
        # é‡è¦ï¼šåªæœ‰åœ¨æ–‡æœ¬æœ‰æ„ä¹‰æ—¶æ‰æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒºï¼Œé¿å…é™éŸ³éŸ³é¢‘æ±¡æŸ“ä¸Šä¸‹æ–‡
        try:
            if not full_text_trimmed:
                logger.warning(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"transcript='{full_text}' "
                    f"'ASR transcript is empty, skipping NMT and TTS, and NOT updating context buffer'"
                )
                logger.info(f"[{trace_id}] Step 10.1: Returning empty response (empty transcript)")
                # è¿”å›ç©ºç»“æœï¼Œä¸æ›´æ–°ä¸Šä¸‹æ–‡
                return UtteranceResponse(
                    text="",
                    segments=[],
                    language=info_language,
                    duration=info_duration,
                    vad_segments=[],
                )
        except Exception as e:
            logger.error(f"[{trace_id}] Step 10.1: Failed to check empty text: {e}", exc_info=True)
            raise
        
        try:
            logger.info(f"[{trace_id}] Step 10.2: Checking if transcript is meaningless")
            is_meaningless = is_meaningless_transcript(full_text_trimmed)
            logger.info(f"[{trace_id}] Step 10.2: Meaningless check result: {is_meaningless}")
        except Exception as e:
            logger.error(f"[{trace_id}] Step 10.2: Failed to check meaningless transcript: {e}", exc_info=True)
            raise
        
        if is_meaningless:
                logger.warning(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"transcript='{full_text_trimmed}' "
                    f"transcript_len={len(full_text_trimmed)} "
                    f"'ASR transcript is meaningless (likely silence misrecognition), skipping NMT and TTS, and NOT updating context buffer'"
                )
                logger.info(f"[{trace_id}] Step 10.3: Returning empty response (meaningless transcript)")
                # è¿”å›ç©ºç»“æœï¼Œä¸æ›´æ–°ä¸Šä¸‹æ–‡
                return UtteranceResponse(
                    text="",
                    segments=[],
                    language=info_language,
                    duration=info_duration,
                    vad_segments=[],
                )
        
        logger.info(f"[{trace_id}] Step 11: Starting text context update (use_text_context={req.use_text_context})")
        
        # 11. æ›´æ–°æ–‡æœ¬ä¸Šä¸‹æ–‡ç¼“å­˜ï¼ˆåªæ›´æ–°æœ‰æ„ä¹‰çš„æ–‡æœ¬ï¼‰
        # å…³é”®ä¿®å¤ï¼šä½¿ç”¨å»é‡åçš„æ–‡æœ¬æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å­˜ï¼Œé¿å…é‡å¤æ–‡æœ¬è¢«åå¤ä½¿ç”¨
        try:
            if req.use_text_context:
                # åªä¿ç•™æœ€åä¸€å¥
                logger.info(f"[{trace_id}] Step 11.1: Splitting text into sentences")
                sentences = full_text_trimmed.split('.')  # ä½¿ç”¨å»é‡åçš„æ–‡æœ¬
                if len(sentences) > 1:
                    last_sentence = sentences[-1].strip()
                    if last_sentence and not is_meaningless_transcript(last_sentence):
                        logger.info(f"[{trace_id}] Step 11.2: Updating text context with last sentence (deduplicated)")
                        update_text_context(last_sentence)
                        logger.info(f"[{trace_id}] Step 11.2: Text context updated successfully")
                else:
                    if not is_meaningless_transcript(full_text_trimmed):
                        logger.info(f"[{trace_id}] Step 11.3: Updating text context with full text (deduplicated)")
                        update_text_context(full_text_trimmed)
                        logger.info(f"[{trace_id}] Step 11.3: Text context updated successfully")
            logger.info(f"[{trace_id}] Step 11: Text context update completed")
        except Exception as e:
            logger.error(f"[{trace_id}] Step 11: Failed to update text context: {e}", exc_info=True)
            raise
        
        logger.info(f"[{trace_id}] Step 12: Starting context buffer update (use_context_buffer={req.use_context_buffer})")
        
        # 12. æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒºï¼ˆä½¿ç”¨åŸå§‹éŸ³é¢‘ï¼Œä¸å¸¦ä¸Šä¸‹æ–‡ï¼‰
        # é‡è¦ï¼šåªæœ‰åœ¨æ–‡æœ¬æœ‰æ„ä¹‰æ—¶æ‰æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒº
        # ä¸¥æ ¼æŒ‰ç…§ node-inference çš„æ—¥å¿—æ ¼å¼
        try:
            if req.use_context_buffer:
                # ä½¿ç”¨ VAD æ£€æµ‹åŸå§‹éŸ³é¢‘çš„è¯­éŸ³æ®µ
                logger.info(f"[{trace_id}] Step 12.1: Starting VAD detection for context buffer (audio_len={len(audio)})")
                try:
                    original_vad_segments = detect_speech(audio)
                    logger.info(f"[{trace_id}] Step 12.1: VAD detection completed, segments={len(original_vad_segments)}")
                except Exception as e:
                    # VADæ£€æµ‹å¤±è´¥ï¼Œå›é€€åˆ°ç®€å•å°¾éƒ¨ä¿å­˜
                    logger.warning(
                        f"[{trace_id}] trace_id={trace_id} "
                        f"error='{str(e)}' "
                        f"'VADæ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨ç®€å•å°¾éƒ¨ä¿å­˜ä¸Šä¸‹æ–‡'"
                    )
                    original_vad_segments = []
                
                if len(original_vad_segments) > 0:
                    # é€‰æ‹©æœ€åä¸€ä¸ªè¯­éŸ³æ®µ
                    last_start, last_end = original_vad_segments[-1]
                    last_segment = audio[last_start:last_end]
                    context_samples = int(CONTEXT_DURATION_SEC * CONTEXT_SAMPLE_RATE)
                    
                    if len(last_segment) > context_samples:
                        logger.info(
                            f"[{trace_id}] trace_id={trace_id} "
                            f"context_samples={context_samples} "
                            f"context_duration_sec={context_samples/CONTEXT_SAMPLE_RATE:.3f} "
                            f"segment_start={last_start} "
                            f"segment_end={last_end} "
                            f"segment_samples={len(last_segment)} "
                            f"'âœ… æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒºï¼ˆä½¿ç”¨VADé€‰æ‹©çš„æœ€åä¸€ä¸ªè¯­éŸ³æ®µå°¾éƒ¨ï¼‰'"
                        )
                    else:
                        logger.info(
                            f"[{trace_id}] trace_id={trace_id} "
                            f"context_samples={len(last_segment)} "
                            f"context_duration_sec={len(last_segment)/CONTEXT_SAMPLE_RATE:.3f} "
                            f"segment_samples={len(last_segment)} "
                            f"'âœ… æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒºï¼ˆæœ€åä¸€ä¸ªè¯­éŸ³æ®µè¾ƒçŸ­ï¼Œä¿å­˜å…¨éƒ¨ï¼‰'"
                        )
                    
                    logger.info(f"[{trace_id}] Step 12.2: Updating context buffer")
                    update_context_buffer(audio, original_vad_segments)
                    logger.info(f"[{trace_id}] Step 12.2: Context buffer updated successfully")
                else:
                    # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³æ®µï¼Œå›é€€åˆ°ç®€å•å°¾éƒ¨ä¿å­˜
                    context_samples = int(CONTEXT_DURATION_SEC * CONTEXT_SAMPLE_RATE)
                    if len(audio) > context_samples:
                        logger.info(
                            f"[{trace_id}] trace_id={trace_id} "
                            f"context_samples={context_samples} "
                            f"context_duration_sec={context_samples/CONTEXT_SAMPLE_RATE:.3f} "
                            f"original_samples={len(audio)} "
                            f"'âš ï¸ æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒºï¼ˆVADæœªæ£€æµ‹åˆ°è¯­éŸ³æ®µï¼Œä¿å­˜æœ€å{CONTEXT_DURATION_SEC}ç§’ï¼‰'"
                        )
                    else:
                        logger.info(
                            f"[{trace_id}] trace_id={trace_id} "
                            f"context_samples={len(audio)} "
                            f"context_duration_sec={len(audio)/CONTEXT_SAMPLE_RATE:.3f} "
                            f"original_samples={len(audio)} "
                            f"'âš ï¸ æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒºï¼ˆutteranceè¾ƒçŸ­ï¼Œä¿å­˜å…¨éƒ¨ï¼‰'"
                        )
                    
                    logger.info(f"[{trace_id}] Step 12.2: Updating context buffer")
                    update_context_buffer(audio, [])
                    logger.info(f"[{trace_id}] Step 12.2: Context buffer updated successfully")
            logger.info(f"[{trace_id}] Step 12: Context buffer update completed")
        except Exception as e:
            logger.error(f"[{trace_id}] Step 12: Failed to update context buffer: {e}", exc_info=True)
            raise
        
        logger.info(f"[{trace_id}] Step 13: Starting response construction")
        
        # 13. è¿”å›ç»“æœ
        # å…³é”®ä¿®å¤ï¼šè¿”å›å»é‡åçš„æ–‡æœ¬ï¼Œè€Œä¸æ˜¯åŸå§‹æ–‡æœ¬
        try:
            response = UtteranceResponse(
                text=full_text_trimmed,  # ä½¿ç”¨å»é‡åçš„æ–‡æœ¬
                segments=segment_texts,
                language=info_language,
                duration=info_duration,
                vad_segments=vad_segments,
            )
            logger.info(f"[{trace_id}] Step 13: Response constructed successfully, returning deduplicated text (len={len(full_text_trimmed)})")
            return response
        except Exception as e:
            logger.error(f"[{trace_id}] Step 13: Failed to construct response: {e}", exc_info=True)
            raise
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Utterance processing error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Utterance processing failed: {str(e)}")

# ---------------------
# Main
# ---------------------
if __name__ == "__main__":
    import uvicorn
    logger.info(f"Starting Faster Whisper + Silero VAD service on port {PORT}...")
    uvicorn.run(app, host="0.0.0.0", port=PORT)
