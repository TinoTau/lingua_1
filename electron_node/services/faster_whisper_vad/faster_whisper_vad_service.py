"""
Faster Whisper + Silero VAD Service
æ•´åˆ ASR å’Œ VAD åŠŸèƒ½ï¼Œæ”¯æŒä¸Šä¸‹æ–‡ç¼“å†²å’Œ Utterance ä»»åŠ¡å¤„ç†
ä¸¥æ ¼æŒ‰ç…§ç°æœ‰ Rust å®ç°
"""
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import numpy as np
import logging
import time
import asyncio
import signal
import sys
import traceback
from typing import Optional, List, Tuple, Dict, Any

# Configure logging (å¿…é¡»åœ¨å¯¼å…¥æ¨¡å—ä¹‹å‰ï¼Œå› ä¸ºå¯¼å…¥æ—¶å¯èƒ½ä½¿ç”¨logger)
# ç¡®ä¿ logs ç›®å½•å­˜åœ¨
import os
log_dir = 'logs'
if not os.path.exists(log_dir):
    os.makedirs(log_dir, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(os.path.join(log_dir, 'faster-whisper-vad-service.log'), encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# å…¨å±€å¼‚å¸¸å¤„ç†
def handle_exception(exc_type, exc_value, exc_traceback):
    """å…¨å±€å¼‚å¸¸å¤„ç†å™¨"""
    if issubclass(exc_type, KeyboardInterrupt):
        sys.__excepthook__(exc_type, exc_value, exc_traceback)
        return
    
    logger.critical("=" * 80)
    logger.critical("ğŸš¨ Uncaught exception in main process, service may crash")
    logger.critical(f"   Exception type: {exc_type.__name__}")
    logger.critical(f"   Exception value: {exc_value}")
    logger.critical("   Traceback:")
    for line in traceback.format_exception(exc_type, exc_value, exc_traceback):
        logger.critical(f"   {line.rstrip()}")
    logger.critical("=" * 80)
    
    # è°ƒç”¨é»˜è®¤å¼‚å¸¸å¤„ç†å™¨
    sys.__excepthook__(exc_type, exc_value, exc_traceback)

sys.excepthook = handle_exception

# ä¿¡å·å¤„ç†ï¼ˆç”¨äºè®°å½•ä¸»è¿›ç¨‹é€€å‡ºï¼‰
def signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å™¨"""
    logger.warning(f"Received signal {signum}, preparing to shutdown...")
    if signum == signal.SIGTERM:
        logger.info("SIGTERM received, graceful shutdown")
    elif signum == signal.SIGINT:
        logger.info("SIGINT received (Ctrl+C), graceful shutdown")
    else:
        logger.warning(f"Unexpected signal {signum} received")

# æ³¨å†Œä¿¡å·å¤„ç†å™¨ï¼ˆWindows ä¸Šå¯èƒ½ä¸æ”¯æŒæ‰€æœ‰ä¿¡å·ï¼‰
try:
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)
except (AttributeError, ValueError):
    # Windows å¯èƒ½ä¸æ”¯æŒæŸäº›ä¿¡å·
    logger.debug("Some signals not available on this platform")

# å¯¼å…¥é…ç½®å’Œæ¨¡å—
from config import (
    PORT,
    MAX_AUDIO_DURATION_SEC,
    CONTEXT_SAMPLE_RATE,
    CONTEXT_DURATION_SEC,
    BEAM_SIZE,
    TEMPERATURE,
    PATIENCE,
    COMPRESSION_RATIO_THRESHOLD,
    LOG_PROB_THRESHOLD,
    NO_SPEECH_THRESHOLD,
)
# æ³¨æ„ï¼šä¸å†å¯¼å…¥ asr_modelï¼ŒASR æ¨ç†åœ¨ç‹¬ç«‹å­è¿›ç¨‹ä¸­æ‰§è¡Œ
from models import vad_session  # åªå¯¼å…¥ VAD æ¨¡å‹
from vad import vad_state, detect_speech
from context import (
    get_context_audio,
    update_context_buffer,
    reset_context_buffer,
    get_text_context,
    update_text_context,
    reset_text_context,
)
from text_filter import is_meaningless_transcript
from audio_decoder import decode_audio
from asr_worker_manager import ASRWorkerManager, MAX_WAIT_SECONDS

# ---------------------
# FastAPI App
# ---------------------
app = FastAPI(title="Faster Whisper + Silero VAD Service")

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---------------------
# Request/Response Schemas
# ---------------------
class UtteranceRequest(BaseModel):
    """
    Utterance ä»»åŠ¡è¯·æ±‚
    ä¸ node-inference çš„ HttpInferenceRequest ä¿æŒä¸€è‡´
    """
    job_id: str  # ä»»åŠ¡ IDï¼ˆç”¨äºè¿½è¸ªï¼‰
    src_lang: str  # æºè¯­è¨€ï¼ˆæ”¯æŒ "auto" | "zh" | "en" | "ja" | "ko"ï¼‰
    tgt_lang: Optional[str] = None  # ç›®æ ‡è¯­è¨€ï¼ˆå¯é€‰ï¼ŒASR æœåŠ¡ä¸ä½¿ç”¨ï¼‰
    audio: str  # Base64 encoded audioï¼ˆä¸ node-inference ä¸€è‡´ï¼‰
    audio_format: Optional[str] = "pcm16"  # éŸ³é¢‘æ ¼å¼ï¼ˆ"pcm16" | "opus" - Opus å·²åºŸå¼ƒï¼ŒPipeline è´Ÿè´£è§£ç ï¼‰
    sample_rate: Optional[int] = 16000  # é‡‡æ ·ç‡
    # ASR ç‰¹å®šå‚æ•°
    language: Optional[str] = None  # è¯­è¨€ä»£ç ï¼ˆå¦‚æœ src_lang == "auto"ï¼Œåˆ™è‡ªåŠ¨æ£€æµ‹ï¼‰
    task: str = "transcribe"  # "transcribe" or "translate"
    beam_size: int = BEAM_SIZE  # ä»é…ç½®æ–‡ä»¶è¯»å–ï¼Œé»˜è®¤ 10ï¼ˆæé«˜å‡†ç¡®åº¦ï¼Œå‡å°‘åŒéŸ³å­—é”™è¯¯ï¼‰
    condition_on_previous_text: bool = False  # ç¦ç”¨æ¡ä»¶ç”Ÿæˆï¼Œé¿å…é‡å¤è¯†åˆ«ï¼ˆå½“ä¸Šä¸‹æ–‡æ–‡æœ¬å’Œå½“å‰éŸ³é¢‘å†…å®¹ç›¸åŒæ—¶ï¼Œä¼šå¯¼è‡´é‡å¤è¾“å‡ºï¼‰
    # æ–°å¢ï¼šæé«˜å‡†ç¡®åº¦çš„å‚æ•°
    best_of: Optional[int] = 5  # å€™é€‰æ•°é‡ï¼ˆç”¨äºébeam searchæ¨¡å¼ï¼Œå½“å‰ä½¿ç”¨beam searchï¼Œæ­¤å‚æ•°ä¸å½±å“ï¼‰
    temperature: Optional[float] = TEMPERATURE  # ä»é…ç½®æ–‡ä»¶è¯»å–ï¼Œé»˜è®¤ 0.0ï¼ˆæ›´ç¡®å®šï¼Œå‡å°‘éšæœºæ€§ï¼Œæé«˜å‡†ç¡®åº¦ï¼‰
    patience: Optional[float] = PATIENCE  # ä»é…ç½®æ–‡ä»¶è¯»å–ï¼Œé»˜è®¤ 1.0ï¼ˆBeam searchè€å¿ƒå€¼ï¼‰
    compression_ratio_threshold: Optional[float] = COMPRESSION_RATIO_THRESHOLD  # ä»é…ç½®æ–‡ä»¶è¯»å–ï¼Œé»˜è®¤ 2.4ï¼ˆå‹ç¼©æ¯”é˜ˆå€¼ï¼‰
    log_prob_threshold: Optional[float] = LOG_PROB_THRESHOLD  # ä»é…ç½®æ–‡ä»¶è¯»å–ï¼Œé»˜è®¤ -1.0ï¼ˆå¯¹æ•°æ¦‚ç‡é˜ˆå€¼ï¼‰
    no_speech_threshold: Optional[float] = NO_SPEECH_THRESHOLD  # ä»é…ç½®æ–‡ä»¶è¯»å–ï¼Œé»˜è®¤ 0.6ï¼ˆæ— è¯­éŸ³é˜ˆå€¼ï¼‰
    use_context_buffer: bool = True  # æ˜¯å¦ä½¿ç”¨ä¸Šä¸‹æ–‡ç¼“å†²åŒº
    use_text_context: bool = True  # æ˜¯å¦ä½¿ç”¨æ–‡æœ¬ä¸Šä¸‹æ–‡
    # å…¶ä»–å‚æ•°ï¼ˆä¸ node-inference ä¿æŒä¸€è‡´ï¼Œä½† ASR æœåŠ¡ä¸ä½¿ç”¨ï¼‰
    features: Optional[dict] = None  # å¯é€‰åŠŸèƒ½è¯·æ±‚ï¼ˆASR æœåŠ¡ä¸ä½¿ç”¨ï¼‰
    mode: Optional[str] = None  # ç¿»è¯‘æ¨¡å¼ï¼ˆASR æœåŠ¡ä¸ä½¿ç”¨ï¼‰
    lang_a: Optional[str] = None  # åŒå‘æ¨¡å¼è¯­è¨€ Aï¼ˆASR æœåŠ¡ä¸ä½¿ç”¨ï¼‰
    lang_b: Optional[str] = None  # åŒå‘æ¨¡å¼è¯­è¨€ Bï¼ˆASR æœåŠ¡ä¸ä½¿ç”¨ï¼‰
    auto_langs: Optional[List[str]] = None  # è‡ªåŠ¨è¯†åˆ«è¯­è¨€èŒƒå›´ï¼ˆASR æœåŠ¡ä¸ä½¿ç”¨ï¼‰
    enable_streaming_asr: Optional[bool] = False  # æ˜¯å¦å¯ç”¨æµå¼ ASRï¼ˆå½“å‰ä¸æ”¯æŒï¼‰
    partial_update_interval_ms: Optional[int] = None  # éƒ¨åˆ†ç»“æœæ›´æ–°é—´éš”ï¼ˆå½“å‰ä¸æ”¯æŒï¼‰
    trace_id: Optional[str] = None  # è¿½è¸ª IDï¼ˆç”¨äºå…¨é“¾è·¯æ—¥å¿—è¿½è¸ªï¼‰
    context_text: Optional[str] = None  # ä¸Šä¸‹æ–‡æ–‡æœ¬ï¼ˆç”¨äº NMTï¼ŒASR æœåŠ¡ä¸ä½¿ç”¨ï¼‰
    # EDGE-4: Padding é…ç½®
    padding_ms: Optional[int] = None  # å°¾éƒ¨é™éŸ³ paddingï¼ˆæ¯«ç§’ï¼‰ï¼ŒNone è¡¨ç¤ºä¸æ·»åŠ  padding

class SegmentInfo(BaseModel):
    """Segment ä¿¡æ¯ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰"""
    text: str
    start: Optional[float] = None  # å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
    end: Optional[float] = None    # ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
    no_speech_prob: Optional[float] = None  # æ— è¯­éŸ³æ¦‚ç‡ï¼ˆå¯é€‰ï¼‰

class UtteranceResponse(BaseModel):
    """Utterance ä»»åŠ¡å“åº”"""
    text: str  # Full transcribed text
    segments: List[SegmentInfo]  # List of segment info (åŒ…å«æ—¶é—´æˆ³å’Œå…ƒæ•°æ®)
    language: Optional[str] = None  # Detected language
    language_probability: Optional[float] = None  # æ£€æµ‹åˆ°çš„è¯­è¨€çš„æ¦‚ç‡ï¼ˆ0.0-1.0ï¼‰
    language_probabilities: Optional[Dict[str, float]] = None  # æ‰€æœ‰è¯­è¨€çš„æ¦‚ç‡ä¿¡æ¯ï¼ˆå­—å…¸ï¼šè¯­è¨€ä»£ç  -> æ¦‚ç‡ï¼‰
    duration: float  # Audio duration in seconds
    vad_segments: List[Tuple[int, int]]  # VAD æ£€æµ‹åˆ°çš„è¯­éŸ³æ®µï¼ˆæ ·æœ¬ç´¢å¼•ï¼‰

class ResetRequest(BaseModel):
    """é‡ç½®è¯·æ±‚"""
    reset_vad: bool = True  # é‡ç½® VAD çŠ¶æ€
    reset_context: bool = True  # é‡ç½®ä¸Šä¸‹æ–‡ç¼“å†²åŒº
    reset_text_context: bool = True  # é‡ç½®æ–‡æœ¬ä¸Šä¸‹æ–‡

# ---------------------
# Global ASR Worker Manager
# ---------------------
_asr_worker_manager: Optional[ASRWorkerManager] = None

def get_asr_worker_manager() -> ASRWorkerManager:
    """è·å–å…¨å±€ ASR Worker Manager å®ä¾‹"""
    global _asr_worker_manager
    if _asr_worker_manager is None:
        _asr_worker_manager = ASRWorkerManager()
    return _asr_worker_manager

# ---------------------
# Health Check
# ---------------------
@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼ŒåŒ…å«ASR WorkerçŠ¶æ€"""
    manager = get_asr_worker_manager()
    stats = manager.get_stats()
    return {
        "status": "ok",
        "asr_model_loaded": stats.get("worker_pid") is not None,  # å¦‚æœ worker è¿›ç¨‹å­˜åœ¨ï¼Œè¯´æ˜æ¨¡å‹å·²åŠ è½½
        "vad_model_loaded": True,
        "asr_worker": {
            "is_running": stats["is_running"],
            "worker_state": stats["worker_state"],
            "worker_pid": stats["worker_pid"],
            "queue_depth": stats["queue_depth"],
            "total_tasks": stats["total_tasks"],
            "completed_tasks": stats["completed_tasks"],
            "failed_tasks": stats["failed_tasks"],
            "worker_restarts": stats["worker_restarts"],
            "avg_wait_ms": round(stats["avg_wait_ms"], 2),
            "pending_results": stats["pending_results"],
        }
    }

# ---------------------
# Reset Endpoint
# ---------------------
@app.post("/reset")
def reset_state(req: ResetRequest):
    """é‡ç½® VAD çŠ¶æ€å’Œä¸Šä¸‹æ–‡ç¼“å†²åŒº"""
    if req.reset_vad:
        vad_state.reset()
        logger.info("âœ… VAD state reset")
    
    if req.reset_context:
        reset_context_buffer()
        logger.info("âœ… Context buffer reset")
    
    if req.reset_text_context:
        reset_text_context()
        logger.info("âœ… Text context cache reset")
    
    return {"status": "ok"}

# ---------------------
# Startup/Shutdown Events
# ---------------------
@app.on_event("startup")
async def startup():
    """å¯åŠ¨ASR Worker Manager"""
    try:
        logger.info("=" * 80)
        logger.info("ğŸš€ Starting Faster Whisper + Silero VAD Service")
        logger.info(f"   Main process PID: {os.getpid()}")
        logger.info(f"   Port: {PORT}")
        logger.info("=" * 80)
        
        manager = get_asr_worker_manager()
        await manager.start()
        logger.info("âœ… ASR Worker Manager started on startup")
    except Exception as e:
        logger.critical(f"âŒ Failed to start ASR Worker Manager: {e}", exc_info=True)
        raise

@app.on_event("shutdown")
async def shutdown():
    """åœæ­¢ASR Worker Manager"""
    try:
        logger.info("=" * 80)
        logger.info("ğŸ›‘ Shutting down Faster Whisper + Silero VAD Service")
        logger.info(f"   Main process PID: {os.getpid()}")
        logger.info("=" * 80)
        
        global _asr_worker_manager
        if _asr_worker_manager:
            await _asr_worker_manager.stop()
            _asr_worker_manager = None
        logger.info("âœ… ASR Worker Manager stopped on shutdown")
    except Exception as e:
        logger.error(f"âŒ Error during shutdown: {e}", exc_info=True)

# ---------------------
# Utterance Endpoint
# ---------------------
@app.post("/utterance", response_model=UtteranceResponse)
async def process_utterance(req: UtteranceRequest):
    """
    å¤„ç† Utterance ä»»åŠ¡
    ä¸¥æ ¼æŒ‰ç…§ç°æœ‰å®ç°ï¼Œä¸ node-inference æ¥å£ä¿æŒä¸€è‡´ï¼š
    1. è§£ç éŸ³é¢‘ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
    2. å‰ç½®ä¸Šä¸‹æ–‡éŸ³é¢‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    3. ä½¿ç”¨ VAD æ£€æµ‹æœ‰æ•ˆè¯­éŸ³æ®µ
    4. ä½¿ç”¨ Faster Whisper è¿›è¡Œ ASR
    5. æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒº
    """
    trace_id = req.trace_id or req.job_id
    # ä¸¥æ ¼æŒ‰ç…§ node-inference çš„æ—¥å¿—æ ¼å¼
    logger.info(f"[{trace_id}] Received utterance request: job_id={req.job_id}, audio_format={req.audio_format}, sample_rate={req.sample_rate}")
    
    # è¯¦ç»†è®°å½•å…¥å‚ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•é‡å¤é—®é¢˜ï¼‰
    logger.info(
        f"[{trace_id}] ========== ASR æ¥å£å…¥å‚ =========="
    )
    logger.info(
        f"[{trace_id}] ASR è¯·æ±‚å‚æ•°: "
        f"job_id={req.job_id}, "
        f"src_lang={req.src_lang}, "
        f"audio_format={req.audio_format}, "
        f"sample_rate={req.sample_rate}, "
        f"use_context_buffer={req.use_context_buffer}, "
        f"use_text_context={req.use_text_context}, "
        f"condition_on_previous_text={req.condition_on_previous_text}"
    )
    logger.debug(
        f"[{trace_id}] "
        f"trace_id={trace_id} "
        f"job_id={req.job_id} "
        f"'å¼€å§‹å¤„ç†æ¨ç†è¯·æ±‚'"
    )
    
    try:
        # 1. è§£ç éŸ³é¢‘
        audio_format = req.audio_format or "pcm16"
        sample_rate = req.sample_rate or 16000
        
        logger.info(f"[{trace_id}] Audio format: {audio_format}, sample_rate: {sample_rate}")
        
        try:
            audio, sr = decode_audio(req.audio, audio_format, sample_rate, trace_id)
        except ValueError as e:
            logger.error(f"[{trace_id}] Audio decoding failed: {e}")
            raise HTTPException(status_code=400, detail=str(e))
        except Exception as e:
            # æ•è·æ‰€æœ‰å…¶ä»–å¼‚å¸¸ï¼ˆåŒ…æ‹¬å¯èƒ½çš„segfaultå‰çš„å¼‚å¸¸ï¼‰
            logger.critical(
                f"[{trace_id}] ğŸš¨ CRITICAL: Audio decoding raised unexpected exception: {e}, "
                f"error_type={type(e).__name__}",
                exc_info=True
            )
            raise HTTPException(status_code=500, detail=f"Audio decoding error: {str(e)}")
        
        # 2. æ£€æŸ¥éŸ³é¢‘é•¿åº¦é™åˆ¶ï¼ˆé˜²æ­¢ GPU å†…å­˜æº¢å‡ºå’Œæ ˆç¼“å†²åŒºæº¢å‡ºï¼‰
        audio_duration = len(audio) / sr
        if audio_duration > MAX_AUDIO_DURATION_SEC:
            logger.warning(
                f"[{trace_id}] Audio duration ({audio_duration:.2f}s) exceeds maximum ({MAX_AUDIO_DURATION_SEC}s), "
                f"truncating to {MAX_AUDIO_DURATION_SEC}s"
            )
            max_samples = int(MAX_AUDIO_DURATION_SEC * sr)
            audio = audio[:max_samples]
        
        # 3. é‡é‡‡æ ·åˆ°æŒ‡å®šé‡‡æ ·ç‡ï¼ˆé»˜è®¤ 16kHzï¼‰
        if sr != sample_rate:
            logger.warning(f"[{trace_id}] Audio sample rate is {sr}Hz, expected {sample_rate}Hz. Resampling...")
            from scipy import signal
            num_samples = int(len(audio) * sample_rate / sr)
            audio = signal.resample(audio, num_samples).astype(np.float32)
            sr = sample_rate
        
        # 3.1 é‡é‡‡æ ·åå†æ¬¡æ£€æŸ¥éŸ³é¢‘é•¿åº¦é™åˆ¶
        audio_duration = len(audio) / sr
        if audio_duration > MAX_AUDIO_DURATION_SEC:
            logger.warning(
                f"[{trace_id}] Audio duration after resampling ({audio_duration:.2f}s) exceeds maximum ({MAX_AUDIO_DURATION_SEC}s), "
                f"truncating to {MAX_AUDIO_DURATION_SEC}s"
            )
            max_samples = int(MAX_AUDIO_DURATION_SEC * sr)
            audio = audio[:max_samples]
        
        # ç¡®ä¿éŸ³é¢‘æ˜¯è¿ç»­çš„
        if not audio.flags['C_CONTIGUOUS']:
            audio = np.ascontiguousarray(audio)
        
        # EDGE-4: Paddingï¼ˆåœ¨éŸ³é¢‘æœ«å°¾æ·»åŠ é™éŸ³ï¼‰
        if req.padding_ms is not None and req.padding_ms > 0:
            padding_samples = int((req.padding_ms / 1000.0) * sr)
            if padding_samples > 0:
                padding = np.zeros(padding_samples, dtype=np.float32)
                audio = np.concatenate([audio, padding])
                logger.info(
                    f"[{trace_id}] EDGE-4: Applied padding: {req.padding_ms}ms "
                    f"({padding_samples} samples), total_duration={len(audio)/sr:.3f}s"
                )
        
        # 4. ç¡®å®šè¯­è¨€ï¼ˆå¦‚æœ src_lang == "auto"ï¼Œåˆ™ä½¿ç”¨ language æˆ–è‡ªåŠ¨æ£€æµ‹ï¼‰
        asr_language = None
        if req.src_lang != "auto":
            asr_language = req.src_lang
        elif req.language:
            asr_language = req.language
        # å¦‚æœéƒ½æ˜¯ Noneï¼ŒFaster Whisper ä¼šè‡ªåŠ¨æ£€æµ‹
        
        # ä¸¥æ ¼æŒ‰ç…§ node-inference çš„æ—¥å¿—æ ¼å¼
        logger.debug(f"[{trace_id}] trace_id={trace_id} src_lang={req.src_lang} 'å¼€å§‹ ASR è¯­éŸ³è¯†åˆ«'")
        
        # 5. å‰ç½®ä¸Šä¸‹æ–‡éŸ³é¢‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        # ä¸¥æ ¼æŒ‰ç…§ node-inference çš„æ—¥å¿—æ ¼å¼
        if req.use_context_buffer:
            context_audio = get_context_audio()
            if len(context_audio) > 0:
                audio_with_context = np.concatenate([context_audio, audio])
                context_duration_sec = len(context_audio) / sr
                original_duration_sec = len(audio) / sr
                total_duration_sec = len(audio_with_context) / sr
                logger.info(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"context_samples={len(context_audio)} "
                    f"context_duration_sec={context_duration_sec:.3f} "
                    f"original_samples={len(audio)} "
                    f"original_duration_sec={original_duration_sec:.3f} "
                    f"total_samples={len(audio_with_context)} "
                    f"total_duration_sec={total_duration_sec:.3f} "
                    f"'âœ… å‰ç½®ä¸Šä¸‹æ–‡éŸ³é¢‘åˆ°å½“å‰utteranceï¼ˆä¸Šä¸‹æ–‡ç¼“å†²åŒºä¸ä¸ºç©ºï¼‰'"
                )
            else:
                audio_with_context = audio
                logger.info(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"original_samples={len(audio)} "
                    f"original_duration_sec={len(audio)/sr:.3f} "
                    f"'â„¹ï¸ ä¸Šä¸‹æ–‡ç¼“å†²åŒºä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘ï¼ˆç¬¬ä¸€ä¸ªutteranceæˆ–ä¸Šä¸‹æ–‡å·²æ¸…ç©ºï¼‰'"
                )
        else:
            audio_with_context = audio
        
        # 6. ä½¿ç”¨ VAD æ£€æµ‹æœ‰æ•ˆè¯­éŸ³æ®µï¼ˆLevel 2æ–­å¥ï¼‰
        # ä¸¥æ ¼æŒ‰ç…§ node-inference çš„æ—¥å¿—æ ¼å¼
        try:
            vad_segments = detect_speech(audio_with_context)
        except Exception as e:
            # VADæ£€æµ‹å¤±è´¥ï¼Œå›é€€åˆ°å®Œæ•´éŸ³é¢‘
            logger.warning(
                f"[{trace_id}] trace_id={trace_id} "
                f"error='{str(e)}' "
                f"'VADæ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨å®Œæ•´éŸ³é¢‘è¿›è¡ŒASR'"
            )
            vad_segments = []
        
        if len(vad_segments) == 0:
            logger.warning(
                f"[{trace_id}] trace_id={trace_id} "
                f"'VADæœªæ£€æµ‹åˆ°è¯­éŸ³æ®µï¼Œä½¿ç”¨å®Œæ•´éŸ³é¢‘è¿›è¡ŒASR'"
            )
            processed_audio = audio_with_context
        else:
            # æå–æœ‰æ•ˆè¯­éŸ³æ®µï¼ˆå»é™¤é™éŸ³éƒ¨åˆ†ï¼‰
            processed_audio_parts = []
            for start, end in vad_segments:
                processed_audio_parts.append(audio_with_context[start:end])
            processed_audio = np.concatenate(processed_audio_parts)
            
            logger.info(
                f"[{trace_id}] trace_id={trace_id} "
                f"segments_count={len(vad_segments)} "
                f"original_samples={len(audio_with_context)} "
                f"processed_samples={len(processed_audio)} "
                f"removed_samples={len(audio_with_context) - len(processed_audio)} "
                f"'VADæ£€æµ‹åˆ°{len(vad_segments)}ä¸ªè¯­éŸ³æ®µï¼Œå·²æå–æœ‰æ•ˆè¯­éŸ³'"
            )
            
            # å¦‚æœå¤„ç†åçš„éŸ³é¢‘å¤ªçŸ­ï¼ˆ< 0.5ç§’ï¼‰ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘
            MIN_AUDIO_SAMPLES = int(sr * 0.5)  # 0.5ç§’
            if len(processed_audio) < MIN_AUDIO_SAMPLES:
                logger.warning(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"processed_samples={len(processed_audio)} "
                    f"'VADå¤„ç†åçš„éŸ³é¢‘è¿‡çŸ­ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘'"
                )
                processed_audio = audio_with_context
        
        # 6.1 æœ€ç»ˆæ£€æŸ¥ï¼šç¡®ä¿ä¼ é€’ç»™ Faster Whisper çš„éŸ³é¢‘ä¸è¶…è¿‡æœ€å¤§é•¿åº¦
        processed_audio_duration = len(processed_audio) / sr
        if processed_audio_duration > MAX_AUDIO_DURATION_SEC:
            logger.warning(
                f"[{trace_id}] Processed audio duration ({processed_audio_duration:.2f}s) exceeds maximum ({MAX_AUDIO_DURATION_SEC}s), "
                f"truncating to {MAX_AUDIO_DURATION_SEC}s before ASR"
            )
            max_samples = int(MAX_AUDIO_DURATION_SEC * sr)
            processed_audio = processed_audio[:max_samples]
        
        # 7. è·å–æ–‡æœ¬ä¸Šä¸‹æ–‡ï¼ˆç”¨äº Faster Whisper çš„ initial_promptï¼‰
        text_context = ""
        if req.use_text_context:
            text_context = get_text_context()
            if text_context:
                logger.info(
                    f"[{trace_id}] "
                    f"Using text context ({len(text_context)} chars): \"{text_context[:100]}...\""
                )
                # è®°å½•å®Œæ•´çš„æ–‡æœ¬ä¸Šä¸‹æ–‡ï¼ˆç”¨äºè°ƒè¯•é‡å¤é—®é¢˜ï¼‰
                logger.info(
                    f"[{trace_id}] ASR æ–‡æœ¬ä¸Šä¸‹æ–‡ (å®Œæ•´): \"{text_context}\""
                )
            else:
                logger.info(
                    f"[{trace_id}] No text context available (first utterance or context was reset)"
                )
        
        # 8. éªŒè¯éŸ³é¢‘æ•°æ®æ ¼å¼ï¼ˆé˜²æ­¢Faster Whisperå´©æºƒï¼‰
        # æ£€æŸ¥éŸ³é¢‘æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        if len(processed_audio) == 0:
            logger.error(f"[{trace_id}] Processed audio is empty, cannot perform ASR")
            raise HTTPException(status_code=400, detail="Processed audio is empty")
        
        # æ£€æŸ¥NaNå’ŒInfå€¼
        if np.any(np.isnan(processed_audio)) or np.any(np.isinf(processed_audio)):
            logger.error(f"[{trace_id}] Processed audio contains NaN or Inf values")
            # æ¸…ç†NaNå’ŒInfå€¼
            processed_audio = np.nan_to_num(processed_audio, nan=0.0, posinf=1.0, neginf=-1.0)
            logger.warning(f"[{trace_id}] Cleaned NaN/Inf values from audio")
        
        # ç¡®ä¿éŸ³é¢‘æ•°æ®åœ¨æœ‰æ•ˆèŒƒå›´å†…ï¼ˆ[-1.0, 1.0]ï¼‰
        if np.any(np.abs(processed_audio) > 1.0):
            logger.warning(f"[{trace_id}] Audio values out of range [-1.0, 1.0], clipping")
            processed_audio = np.clip(processed_audio, -1.0, 1.0)
        
        # ç¡®ä¿éŸ³é¢‘æ˜¯è¿ç»­çš„numpyæ•°ç»„
        if not isinstance(processed_audio, np.ndarray):
            processed_audio = np.array(processed_audio, dtype=np.float32)
        if processed_audio.dtype != np.float32:
            processed_audio = processed_audio.astype(np.float32)
        if not processed_audio.flags['C_CONTIGUOUS']:
            processed_audio = np.ascontiguousarray(processed_audio)
        
        # è®°å½•éŸ³é¢‘æ•°æ®ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•å’Œå´©æºƒè¯Šæ–­ï¼‰
        audio_std = np.std(processed_audio)
        audio_rms = np.sqrt(np.mean(processed_audio ** 2))
        audio_dynamic_range = np.max(processed_audio) - np.min(processed_audio)
        audio_duration = len(processed_audio) / sr
        
        logger.info(
            f"[{trace_id}] Audio data validation: "
            f"shape={processed_audio.shape}, "
            f"dtype={processed_audio.dtype}, "
            f"min={np.min(processed_audio):.4f}, "
            f"max={np.max(processed_audio):.4f}, "
            f"mean={np.mean(processed_audio):.4f}, "
            f"std={audio_std:.4f}, "
            f"rms={audio_rms:.4f}, "
            f"dynamic_range={audio_dynamic_range:.4f}, "
            f"duration={audio_duration:.3f}s, "
            f"is_contiguous={processed_audio.flags['C_CONTIGUOUS']}"
        )
        
        # 7.5. éŸ³é¢‘è´¨é‡æ£€æŸ¥ï¼ˆé˜²æ­¢ä½è´¨é‡éŸ³é¢‘è¿›å…¥ ASRï¼‰
        # å¦‚æœéŸ³é¢‘è´¨é‡å¤ªå·®ï¼Œç›´æ¥è¿”å›ç©ºå“åº”ï¼Œé¿å…æµªè´¹ ASR èµ„æº
        # æ³¨æ„ï¼šFaster Whisper é€šå¸¸éœ€è¦è‡³å°‘ 0.5-1 ç§’çš„éŸ³é¢‘æ‰èƒ½æœ‰æ•ˆè¯†åˆ«
        # è°ƒæ•´é˜ˆå€¼ä»¥é€‚åº”å®é™…ä½¿ç”¨åœºæ™¯å’ŒOpusç¼–ç åçš„éŸ³é¢‘è´¨é‡
        # å…³é”®ä¿®å¤ï¼šé™ä½é˜ˆå€¼ï¼Œé€‚åº” Opus ç¼–ç åçš„éŸ³é¢‘ç‰¹æ€§
        # ä»æ—¥å¿—çœ‹ï¼ŒOpus ç¼–ç åçš„éŸ³é¢‘ RMS/STD å€¼é€šå¸¸è¾ƒä½ï¼ˆ0.0003-0.0007ï¼‰ï¼Œ
        # ä½†è¿™äº›éŸ³é¢‘ä»ç„¶å¯èƒ½åŒ…å«æœ‰æ•ˆè¯­éŸ³ï¼Œåº”è¯¥è®© ASR æ¨¡å‹æ¥åˆ¤æ–­
        # é™ä½é˜ˆå€¼ï¼Œå‡å°‘è¯¯åˆ¤ï¼Œè®©æ›´å¤šæœ‰æ•ˆéŸ³é¢‘è¿›å…¥ ASR
        MIN_AUDIO_RMS = 0.0005  # æœ€å° RMS èƒ½é‡ï¼ˆé™ä½åˆ° 0.0005ï¼Œé€‚åº” Opus ç¼–ç éŸ³é¢‘ï¼‰
        MIN_AUDIO_STD = 0.0005  # æœ€å°æ ‡å‡†å·®ï¼ˆé™ä½åˆ° 0.0005ï¼Œé€‚åº” Opus ç¼–ç éŸ³é¢‘ï¼‰
        MIN_AUDIO_DYNAMIC_RANGE = 0.005  # æœ€å°åŠ¨æ€èŒƒå›´ï¼ˆé™ä½åˆ° 0.005ï¼Œé€‚åº” Opus ç¼–ç éŸ³é¢‘ï¼‰
        # å…³é”®ä¿®å¤ï¼šå¢åŠ æœ€çŸ­éŸ³é¢‘æ—¶é•¿æ£€æŸ¥
        # Faster Whisper é€šå¸¸éœ€è¦è‡³å°‘ 0.5-1 ç§’çš„éŸ³é¢‘æ‰èƒ½æœ‰æ•ˆè¯†åˆ«
        # è™½ç„¶è´¨é‡æ£€æŸ¥å…è®¸ 0.3 ç§’ï¼Œä½†å®é™… ASR è¯†åˆ«éœ€è¦æ›´é•¿çš„éŸ³é¢‘
        MIN_AUDIO_DURATION = 0.3  # æœ€å°æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œé™ä½åˆ° 0.3 ç§’ï¼Œè®©æ›´å¤šçŸ­éŸ³é¢‘è¿›å…¥ ASR
        
        audio_quality_issues = []
        
        if audio_rms < MIN_AUDIO_RMS:
            audio_quality_issues.append(f"RMS too low ({audio_rms:.4f} < {MIN_AUDIO_RMS})")
        
        if audio_std < MIN_AUDIO_STD:
            audio_quality_issues.append(f"std too low ({audio_std:.4f} < {MIN_AUDIO_STD})")
        
        if audio_dynamic_range < MIN_AUDIO_DYNAMIC_RANGE:
            audio_quality_issues.append(f"dynamic_range too small ({audio_dynamic_range:.4f} < {MIN_AUDIO_DYNAMIC_RANGE})")
        
        if audio_duration < MIN_AUDIO_DURATION:
            audio_quality_issues.append(f"duration too short ({audio_duration:.3f}s < {MIN_AUDIO_DURATION}s)")
        
        if audio_quality_issues:
            logger.warning(
                f"[{trace_id}] trace_id={trace_id} "
                f"audio_rms={audio_rms:.4f} "
                f"audio_std={audio_std:.4f} "
                f"audio_dynamic_range={audio_dynamic_range:.4f} "
                f"audio_duration={audio_duration:.3f}s "
                f"issues={', '.join(audio_quality_issues)} "
                f"'Audio quality too poor (likely silence, noise, or decoding issue), skipping ASR and returning empty response'"
            )
            # è¿”å›ç©ºç»“æœï¼Œä¸è°ƒç”¨ ASR
            return UtteranceResponse(
                text="",
                segments=[],
                language=asr_language or "unknown",
                duration=audio_duration,
                vad_segments=vad_segments,
            )
        
        # 8. ä½¿ç”¨ ASR Worker Manager è¿›è¡Œ ASRï¼ˆè¿›ç¨‹éš”ç¦»æ¶æ„ï¼‰
        asr_start_time = time.time()
        
        # è·å–ASR Worker Manager
        manager = get_asr_worker_manager()
        
        # æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å·²æ»¡ï¼ˆèƒŒå‹æ§åˆ¶ï¼‰
        if manager.is_queue_full():
            stats = manager.get_stats()
            logger.warning(
                f"[{trace_id}] ASR queue is full, returning 503 Service Busy. "
                f"queue_depth={stats['queue_depth']}"
            )
            raise HTTPException(
                status_code=503,
                detail="ASR service is busy, please retry later",
                headers={"Retry-After": "1"}
            )
        
        # åœ¨è°ƒç”¨transcribeä¹‹å‰è®°å½•å…³é”®ä¿¡æ¯ï¼ˆåŒ…æ‹¬ä¸Šä¸‹æ–‡ï¼‰
        stats = manager.get_stats()
        logger.info(
            f"[{trace_id}] ========== ASR è¯†åˆ«è¯·æ±‚å¼€å§‹ =========="
        )
        logger.info(
            f"[{trace_id}] ASR å‚æ•°: "
            f"language={asr_language}, "
            f"task={req.task}, "
            f"beam_size={req.beam_size}, "
            f"condition_on_previous_text={req.condition_on_previous_text}, "
            f"queue_depth={stats['queue_depth']}, "
            f"worker_state={stats['worker_state']}"
        )
        logger.info(
            f"[{trace_id}] ASR ä¸Šä¸‹æ–‡å‚æ•°: "
            f"has_initial_prompt={text_context is not None and len(text_context) > 0}, "
            f"initial_prompt_length={len(text_context) if text_context else 0}, "
            f"initial_prompt_preview='{text_context[:100] if text_context else '(None)'}'"
        )
        logger.info(
            f"[{trace_id}] ASR éŸ³é¢‘å‚æ•°: "
            f"audio_len={len(processed_audio)}, "
            f"sample_rate={sr}, "
            f"duration_sec={len(processed_audio) / sr:.2f}"
        )
        
        try:
            # æäº¤ä»»åŠ¡åˆ°ASR Workerè¿›ç¨‹
            asr_result = await manager.submit_task(
                audio=processed_audio,
                sample_rate=sr,
                language=asr_language,
                task=req.task,
                beam_size=req.beam_size,
                initial_prompt=text_context if text_context else None,
                condition_on_previous_text=req.condition_on_previous_text,
                trace_id=trace_id,
                max_wait=MAX_WAIT_SECONDS,
                # ä¼ é€’ä¼˜åŒ–å‚æ•°ä»¥æé«˜å‡†ç¡®åº¦
                best_of=req.best_of,
                temperature=req.temperature,
                patience=req.patience,
                compression_ratio_threshold=req.compression_ratio_threshold,
                log_prob_threshold=req.log_prob_threshold,
                no_speech_threshold=req.no_speech_threshold,
            )
            
            # æ£€æŸ¥ç»“æœ
            if asr_result.error:
                logger.error(
                    f"[{trace_id}] ASR Worker returned error: {asr_result.error}",
                    exc_info=True
                )
                raise HTTPException(
                    status_code=500,
                    detail=f"ASR processing failed: {asr_result.error}"
                )
            
            # ä»ç»“æœä¸­è·å–æ–‡æœ¬å’Œè¯­è¨€ä¿¡æ¯
            full_text = asr_result.text or ""
            detected_language = asr_result.language
            language_probabilities = asr_result.language_probabilities  # æ–°å¢ï¼šè¯­è¨€æ¦‚ç‡ä¿¡æ¯
            segments_info_raw = asr_result.segments  # æ–°å¢ï¼šSegment å…ƒæ•°æ®
            duration_sec = asr_result.duration_ms / 1000.0 if asr_result.duration_ms > 0 else 0.0
            
            # è®¡ç®—æ£€æµ‹åˆ°çš„è¯­è¨€çš„æ¦‚ç‡ï¼ˆå¦‚æœ language_probabilities å­˜åœ¨ï¼‰
            language_probability = None
            if language_probabilities and detected_language:
                language_probability = language_probabilities.get(detected_language)
                if language_probability is not None:
                    logger.info(
                        f"[{trace_id}] ASR è¯­è¨€æ£€æµ‹æ¦‚ç‡: language={detected_language}, "
                        f"probability={language_probability:.4f}"
                    )
            
            logger.info(
                f"[{trace_id}] ========== ASR æ¥å£è¾“å‡ºç»“æœ =========="
            )
            logger.info(
                f"[{trace_id}] ASR Worker completed successfully, "
                f"text_len={len(full_text)}, language={detected_language}, "
                f"duration_ms={asr_result.duration_ms}"
            )
            logger.info(
                f"[{trace_id}] ASR æ¥å£è¾“å‡ºåŸå§‹æ–‡æœ¬ (repr): {repr(full_text)}"
            )
            logger.info(
                f"[{trace_id}] ASR æ¥å£è¾“å‡ºåŸå§‹æ–‡æœ¬ (preview): '{full_text[:200]}'"
            )
            logger.info(
                f"[{trace_id}] ASR æ¥å£è¾“å‡ºåŸå§‹æ–‡æœ¬ (bytes): {full_text.encode('utf-8') if full_text else b''}"
            )
            
            # ä½¿ç”¨çœŸæ­£çš„ segments æ•°æ®ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
            segments_info: List[SegmentInfo] = []
            if segments_info_raw:
                # è½¬æ¢ SegmentInfo å¯¹è±¡ä¸º Pydantic æ¨¡å‹
                segments_info = [
                    SegmentInfo(
                        text=seg.text,
                        start=seg.start,
                        end=seg.end,
                        no_speech_prob=seg.no_speech_prob,
                    )
                    for seg in segments_info_raw
                ]
            
            # å¦‚æœ segments ä¸ºç©ºï¼Œä»æ–‡æœ¬ç”Ÿæˆï¼ˆå‘åå…¼å®¹ï¼‰
            if not segments_info and full_text:
                # æŒ‰ç©ºæ ¼åˆ†å‰²ä½œä¸ºåå¤‡æ–¹æ¡ˆ
                segment_texts_split = [s.strip() for s in full_text.split() if s.strip()]
                if segment_texts_split:
                    segments_info = [
                        SegmentInfo(text=text, start=None, end=None, no_speech_prob=None)
                        for text in segment_texts_split
                    ]
                else:
                    segments_info = [SegmentInfo(text=full_text, start=None, end=None, no_speech_prob=None)]
            
            # ä¿å­˜æ£€æµ‹åˆ°çš„è¯­è¨€å’Œæ—¶é•¿ï¼Œä¾›åç»­ä½¿ç”¨
            info_language = detected_language
            # language_probability å’Œ language_probabilities å·²ç»åœ¨ä¸Šé¢è®¡ç®—/æå–
            info_duration = duration_sec
            
        except asyncio.TimeoutError:
            stats = manager.get_stats()
            logger.error(
                f"[{trace_id}] ASR task timeout after {MAX_WAIT_SECONDS}s, "
                f"queue_depth={stats['queue_depth']}"
            )
            raise HTTPException(
                status_code=504,
                detail=f"ASR processing timeout after {MAX_WAIT_SECONDS}s"
            )
        except RuntimeError as e:
            # Worker è¿›ç¨‹ä¸å¯ç”¨
            logger.error(
                f"[{trace_id}] ASR Worker process not available: {e}",
                exc_info=True
            )
            raise HTTPException(
                status_code=503,
                detail="ASR service is temporarily unavailable, please retry later",
                headers={"Retry-After": "2"}
            )
        except Exception as e:
            logger.error(
                f"[{trace_id}] ASR Worker exception: {e}",
                exc_info=True
            )
            raise HTTPException(
                status_code=500,
                detail=f"ASR processing failed: {str(e)}"
            )
        
        asr_elapsed = time.time() - asr_start_time
        
        logger.info(f"[{trace_id}] Step 8.1: Text extraction completed, segments={len(segments_info)}, full_text_len={len(full_text)}")
        
        # è®°å½• ASR å¤„ç†æ—¶é—´ï¼ˆç”¨äºæ€§èƒ½ç›‘æ§ï¼‰
        if asr_elapsed > 1.0:
            audio_duration = len(processed_audio) / sr
            ratio = asr_elapsed / audio_duration if audio_duration > 0 else 0
            logger.warning(
                f"[{trace_id}] "
                f"âš ï¸ ASR processing took {asr_elapsed:.2f}s "
                f"(audio duration: {audio_duration:.2f}s, ratio: {ratio:.2f}x)"
            )
        
        logger.info(f"[{trace_id}] Step 9: Starting ASR result processing")
        
        # 9. ASR è¯†åˆ«å®Œæˆï¼Œè®°å½•ç»“æœ
        # ä¸¥æ ¼æŒ‰ç…§ node-inference çš„æ—¥å¿—æ ¼å¼
        try:
            full_text_trimmed = full_text.strip()
            logger.info(f"[{trace_id}] Step 9.1: Text trimmed, len={len(full_text_trimmed)}")
            
            # 9.2. å»é‡å¤„ç†ï¼šç§»é™¤é‡å¤çš„æ–‡æœ¬ç‰‡æ®µ
            # é—®é¢˜ï¼šASRæ¨¡å‹ä½¿ç”¨initial_promptå’Œcondition_on_previous_textå¯èƒ½å¯¼è‡´é‡å¤è¯†åˆ«
            # ä¾‹å¦‚ï¼š"è¿™è¾¹èƒ½ä¸èƒ½ç”¨è¿™è¾¹èƒ½ä¸èƒ½ç”¨" -> "è¿™è¾¹èƒ½ä¸èƒ½ç”¨"
            if full_text_trimmed:
                from text_deduplicator import deduplicate_text
                original_text = full_text_trimmed
                full_text_trimmed = deduplicate_text(full_text_trimmed, trace_id=trace_id)
                
                # å¦‚æœæ–‡æœ¬è¢«ä¿®æ”¹ï¼Œè®°å½•æ—¥å¿—
                if full_text_trimmed != original_text:
                    logger.info(
                        f"[{trace_id}] Step 9.2: Deduplication applied, "
                        f"original_len={len(original_text)}, "
                        f"deduplicated_len={len(full_text_trimmed)}, "
                        f"original_text=\"{original_text[:100]}\", "
                        f"deduplicated_text=\"{full_text_trimmed[:100]}\""
                    )
                
                # æ³¨æ„ï¼šè·¨ utterance å»é‡å·²è¿ç§»åˆ° Aggregator å±‚ï¼ˆèŠ‚ç‚¹ç«¯ï¼‰
                # Step 9.2 ä¿ç•™ï¼šå•ä¸ª utterance å†…éƒ¨å»é‡ï¼ˆå¤„ç†å¦‚ "è¿™è¾¹èƒ½ä¸èƒ½ç”¨è¿™è¾¹èƒ½ä¸èƒ½ç”¨" çš„æƒ…å†µï¼‰
                # Step 9.3 å·²ç§»é™¤ï¼šè·¨ utterance å»é‡ç”± Aggregator ç»Ÿä¸€å¤„ç†ï¼Œé¿å…é‡å¤å¤„ç†ï¼ŒèŒè´£æ›´æ¸…æ™°
                
                # ä¿®å¤ï¼šåœ¨ASRä¹‹åè¿›è¡Œè·¨utteranceçš„æ–‡æœ¬è¿‡æ»¤
                # å½“éŸ³é¢‘è´¨é‡è¾ƒå·®ï¼ˆé™éŸ³æˆ–ç™½å™ªéŸ³ï¼‰æ—¶ï¼ŒASRæ¨¡å‹å¯èƒ½ä¼šåŸºäºinitial_promptç”Ÿæˆæ–‡æœ¬
                # å¯¼è‡´è¯†åˆ«å‡ºçš„æ–‡æœ¬æ˜¯å‰ä¸€ä¸ªutteranceçš„éƒ¨åˆ†å†…å®¹
                # éœ€è¦åœ¨ASRæœåŠ¡å†…éƒ¨è¿›è¡Œè¿‡æ»¤ï¼Œé¿å…è¿”å›é‡å¤æ–‡æœ¬
                # æ”¹è¿›ï¼šåªæœ‰åœ¨éŸ³é¢‘è´¨é‡å¾ˆå·®æ—¶æ‰è¿›è¡Œè¿‡æ»¤ï¼Œé¿å…è¯¯åˆ¤ç”¨æˆ·çœŸçš„è¯´äº†ç±»ä¼¼çš„è¯
                if text_context and full_text_trimmed:
                    # æ ‡å‡†åŒ–æ–‡æœ¬ï¼ˆå»é™¤ç©ºæ ¼å·®å¼‚ï¼‰
                    def normalize_text(text: str) -> str:
                        return text.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ').replace(' ', '').strip()
                    
                    normalized_current = normalize_text(full_text_trimmed)
                    normalized_context = normalize_text(text_context)
                    
                    # æ£€æŸ¥éŸ³é¢‘è´¨é‡ï¼šåªæœ‰å½“éŸ³é¢‘è´¨é‡å¾ˆå·®æ—¶æ‰è¿›è¡Œå­ä¸²è¿‡æ»¤
                    # ä»æ—¥å¿—çœ‹ï¼ŒJob8-17 çš„éŸ³é¢‘è´¨é‡éƒ½å¾ˆå·®ï¼ˆRMS < 0.001, duration < 1.0ï¼‰
                    # æ­£å¸¸çš„éŸ³é¢‘åº”è¯¥ RMS > 0.001 ä¸” duration > 1.0
                    # å¦‚æœéŸ³é¢‘è´¨é‡æ­£å¸¸ï¼Œå³ä½¿æ–‡æœ¬æœ‰å­ä¸²å…³ç³»ï¼Œä¹Ÿå¯èƒ½æ˜¯ç”¨æˆ·çœŸçš„è¯´äº†ç±»ä¼¼çš„è¯ï¼Œä¸åº”è¯¥è¿‡æ»¤
                    POOR_AUDIO_RMS_THRESHOLD = 0.001  # RMS é˜ˆå€¼ï¼ˆä½äºæ­¤å€¼è®¤ä¸ºéŸ³é¢‘è´¨é‡å·®ï¼‰
                    POOR_AUDIO_DURATION_THRESHOLD = 1.0  # æ—¶é•¿é˜ˆå€¼ï¼ˆä½äºæ­¤å€¼è®¤ä¸ºéŸ³é¢‘è´¨é‡å·®ï¼‰
                    
                    is_poor_audio_quality = (
                        audio_rms < POOR_AUDIO_RMS_THRESHOLD or 
                        audio_duration < POOR_AUDIO_DURATION_THRESHOLD
                    )
                    
                    # æ£€æŸ¥å½“å‰æ–‡æœ¬æ˜¯å¦æ˜¯ä¸Šä¸‹æ–‡æ–‡æœ¬çš„å­ä¸²ï¼ˆè‡³å°‘3ä¸ªå­—ç¬¦ï¼Œé¿å…è¯¯åˆ¤ï¼‰
                    if len(normalized_current) >= 3 and normalized_context and normalized_context.find(normalized_current) != -1:
                        if is_poor_audio_quality:
                            logger.warning(
                                f"[{trace_id}] Step 9.3: Current text is a substring of context text, "
                                f"and audio quality is poor (rms={audio_rms:.4f}, duration={audio_duration:.3f}s), "
                                f"likely generated from initial_prompt due to poor audio quality. "
                                f"Filtering to avoid duplicate output. "
                                f"current_text='{full_text_trimmed[:50]}', "
                                f"context_text='{text_context[:50]}'"
                            )
                            # è¿”å›ç©ºç»“æœï¼Œé¿å…é‡å¤è¾“å‡º
                            full_text_trimmed = ""
                        else:
                            logger.info(
                                f"[{trace_id}] Step 9.3: Current text is a substring of context text, "
                                f"but audio quality is normal (rms={audio_rms:.4f}, duration={audio_duration:.3f}s), "
                                f"likely user actually said similar content. Not filtering. "
                                f"current_text='{full_text_trimmed[:50]}', "
                                f"context_text='{text_context[:50]}'"
                            )
                    
                    # æ£€æŸ¥ä¸Šä¸‹æ–‡æ–‡æœ¬æ˜¯å¦æ˜¯å½“å‰æ–‡æœ¬çš„å­ä¸²ï¼ˆè‡³å°‘3ä¸ªå­—ç¬¦ï¼Œé¿å…è¯¯åˆ¤ï¼‰
                    elif len(normalized_context) >= 3 and normalized_current and normalized_current.find(normalized_context) != -1:
                        if is_poor_audio_quality:
                            logger.warning(
                                f"[{trace_id}] Step 9.3: Context text is a substring of current text, "
                                f"and audio quality is poor (rms={audio_rms:.4f}, duration={audio_duration:.3f}s), "
                                f"likely generated from initial_prompt due to poor audio quality. "
                                f"Filtering to avoid duplicate output. "
                                f"current_text='{full_text_trimmed[:50]}', "
                                f"context_text='{text_context[:50]}'"
                            )
                            # è¿”å›ç©ºç»“æœï¼Œé¿å…é‡å¤è¾“å‡º
                            full_text_trimmed = ""
                        else:
                            logger.info(
                                f"[{trace_id}] Step 9.3: Context text is a substring of current text, "
                                f"but audio quality is normal (rms={audio_rms:.4f}, duration={audio_duration:.3f}s), "
                                f"likely user actually said similar content. Not filtering. "
                                f"current_text='{full_text_trimmed[:50]}', "
                                f"context_text='{text_context[:50]}'"
                            )
        except Exception as e:
            logger.error(f"[{trace_id}] Step 9.1: Failed to trim text: {e}", exc_info=True)
            raise
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‹¬å·ï¼ˆç”¨äºè°ƒè¯•ï¼Œä¸ node-inference ä¸€è‡´ï¼‰
        try:
            if '(' in full_text_trimmed or 'ï¼ˆ' in full_text_trimmed or '[' in full_text_trimmed or 'ã€' in full_text_trimmed:
                logger.warning(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"transcript='{full_text_trimmed}' "
                    f"transcript_len={len(full_text_trimmed)} "
                    f"'âš ï¸ [ASR Filter Check] Transcript contains brackets before setting to context!'"
                )
        except Exception as e:
            logger.error(f"[{trace_id}] Step 9.2: Failed to check brackets: {e}", exc_info=True)
        
        logger.info(
            f"[{trace_id}] trace_id={trace_id} "
            f"transcript_len={len(full_text)} "
            f"transcript_preview='{full_text[:50]}' "
            f"transcript_trimmed_len={len(full_text_trimmed)} "
            f"transcript_deduplicated_preview='{full_text_trimmed[:50]}' "
            f"'âœ… ASR è¯†åˆ«å®Œæˆ'"
        )
        
        # åœ¨å»é‡åï¼Œé‡æ–°ç”Ÿæˆ segments_infoï¼ˆä½¿ç”¨å»é‡åçš„æ–‡æœ¬ï¼‰
        # æ³¨æ„ï¼šå»é‡å¯èƒ½ä¼šæ”¹å˜æ–‡æœ¬ï¼Œæ‰€ä»¥éœ€è¦é‡æ–°ç”Ÿæˆ segments
        # ä½†å°½é‡ä¿ç•™æ—¶é—´æˆ³ä¿¡æ¯ï¼ˆå¦‚æœåŸå§‹ segments å­˜åœ¨ï¼‰
        if segments_info and full_text_trimmed != full_text:
            # æ–‡æœ¬è¢«å»é‡ä¿®æ”¹äº†ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆ segments
            # ç®€å•å¤„ç†ï¼šæŒ‰ç©ºæ ¼åˆ†å‰²ï¼Œä½†ä¿ç•™ç¬¬ä¸€ä¸ª segment çš„æ—¶é—´æˆ³ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            segment_texts_split = [s.strip() for s in full_text_trimmed.split() if s.strip()]
            if segment_texts_split:
                # å°è¯•ä¿ç•™ç¬¬ä¸€ä¸ª segment çš„æ—¶é—´æˆ³
                first_seg_start = segments_info[0].start if segments_info else None
                first_seg_end = segments_info[-1].end if segments_info else None
                segments_info = [
                    SegmentInfo(
                        text=text,
                        start=first_seg_start if i == 0 else None,
                        end=first_seg_end if i == len(segment_texts_split) - 1 else None,
                        no_speech_prob=None,
                    )
                    for i, text in enumerate(segment_texts_split)
                ]
            else:
                segments_info = [SegmentInfo(text=full_text_trimmed, start=None, end=None, no_speech_prob=None)]
        elif not segments_info and full_text_trimmed:
            # å¦‚æœåŸå§‹ segments ä¸ºç©ºï¼Œä»å»é‡åçš„æ–‡æœ¬ç”Ÿæˆ
            segment_texts_split = [s.strip() for s in full_text_trimmed.split() if s.strip()]
            if segment_texts_split:
                segments_info = [
                    SegmentInfo(text=text, start=None, end=None, no_speech_prob=None)
                    for text in segment_texts_split
                ]
            else:
                segments_info = [SegmentInfo(text=full_text_trimmed, start=None, end=None, no_speech_prob=None)]
        
        logger.info(f"[{trace_id}] Step 10: Starting text validation")
        
        # 10. æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ä¸ºæ— æ„ä¹‰çš„è¯†åˆ«ç»“æœï¼ˆä¸¥æ ¼æŒ‰ç…§ node_inference å®ç°ï¼‰
        # é‡è¦ï¼šåªæœ‰åœ¨æ–‡æœ¬æœ‰æ„ä¹‰æ—¶æ‰æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒºï¼Œé¿å…é™éŸ³éŸ³é¢‘æ±¡æŸ“ä¸Šä¸‹æ–‡
        try:
            if not full_text_trimmed:
                logger.warning(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"transcript='{full_text}' "
                    f"'ASR transcript is empty, skipping NMT and TTS, and NOT updating context buffer'"
                )
                logger.info(f"[{trace_id}] Step 10.1: Returning empty response (empty transcript)")
                # è¿”å›ç©ºç»“æœï¼Œä¸æ›´æ–°ä¸Šä¸‹æ–‡
                return UtteranceResponse(
                    text="",
                    segments=[],
                    language=info_language,
                    duration=info_duration,
                    vad_segments=[],
                )
        except Exception as e:
            logger.error(f"[{trace_id}] Step 10.1: Failed to check empty text: {e}", exc_info=True)
            raise
        
        try:
            logger.info(f"[{trace_id}] Step 10.2: Checking if transcript is meaningless")
            is_meaningless = is_meaningless_transcript(full_text_trimmed)
            logger.info(f"[{trace_id}] Step 10.2: Meaningless check result: {is_meaningless}")
        except Exception as e:
            logger.error(f"[{trace_id}] Step 10.2: Failed to check meaningless transcript: {e}", exc_info=True)
            raise
        
        if is_meaningless:
                logger.warning(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"transcript='{full_text_trimmed}' "
                    f"transcript_len={len(full_text_trimmed)} "
                    f"'ASR transcript is meaningless (likely silence misrecognition), skipping NMT and TTS, and NOT updating context buffer'"
                )
                logger.info(f"[{trace_id}] Step 10.3: Returning empty response (meaningless transcript)")
                # è¿”å›ç©ºç»“æœï¼Œä¸æ›´æ–°ä¸Šä¸‹æ–‡
                return UtteranceResponse(
                    text="",
                    segments=[],
                    language=info_language,
                    duration=info_duration,
                    vad_segments=[],
                )
        
        logger.info(f"[{trace_id}] Step 11: Starting text context update (use_text_context={req.use_text_context})")
        
        # 11. æ›´æ–°æ–‡æœ¬ä¸Šä¸‹æ–‡ç¼“å­˜ï¼ˆåªæ›´æ–°æœ‰æ„ä¹‰çš„æ–‡æœ¬ï¼‰
        # å…³é”®ä¿®å¤ï¼šä½¿ç”¨å»é‡åçš„æ–‡æœ¬æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å­˜ï¼Œé¿å…é‡å¤æ–‡æœ¬è¢«åå¤ä½¿ç”¨
        try:
            if req.use_text_context:
                # åªä¿ç•™æœ€åä¸€å¥
                logger.info(f"[{trace_id}] Step 11.1: Splitting text into sentences")
                sentences = full_text_trimmed.split('.')  # ä½¿ç”¨å»é‡åçš„æ–‡æœ¬
                if len(sentences) > 1:
                    last_sentence = sentences[-1].strip()
                    if last_sentence and not is_meaningless_transcript(last_sentence):
                        logger.info(f"[{trace_id}] Step 11.2: Updating text context with last sentence (deduplicated)")
                        update_text_context(last_sentence)
                        logger.info(f"[{trace_id}] Step 11.2: Text context updated successfully")
                else:
                    if not is_meaningless_transcript(full_text_trimmed):
                        logger.info(f"[{trace_id}] Step 11.3: Updating text context with full text (deduplicated)")
                        update_text_context(full_text_trimmed)
                        logger.info(f"[{trace_id}] Step 11.3: Text context updated successfully")
            logger.info(f"[{trace_id}] Step 11: Text context update completed")
        except Exception as e:
            logger.error(f"[{trace_id}] Step 11: Failed to update text context: {e}", exc_info=True)
            raise
        
        logger.info(f"[{trace_id}] Step 12: Starting context buffer update (use_context_buffer={req.use_context_buffer})")
        
        # 12. æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒºï¼ˆä½¿ç”¨åŸå§‹éŸ³é¢‘ï¼Œä¸å¸¦ä¸Šä¸‹æ–‡ï¼‰
        # é‡è¦ï¼šåªæœ‰åœ¨æ–‡æœ¬æœ‰æ„ä¹‰æ—¶æ‰æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒº
        # ä¸¥æ ¼æŒ‰ç…§ node-inference çš„æ—¥å¿—æ ¼å¼
        try:
            if req.use_context_buffer:
                # ä½¿ç”¨ VAD æ£€æµ‹åŸå§‹éŸ³é¢‘çš„è¯­éŸ³æ®µ
                logger.info(f"[{trace_id}] Step 12.1: Starting VAD detection for context buffer (audio_len={len(audio)})")
                try:
                    original_vad_segments = detect_speech(audio)
                    logger.info(f"[{trace_id}] Step 12.1: VAD detection completed, segments={len(original_vad_segments)}")
                except Exception as e:
                    # VADæ£€æµ‹å¤±è´¥ï¼Œå›é€€åˆ°ç®€å•å°¾éƒ¨ä¿å­˜
                    logger.warning(
                        f"[{trace_id}] trace_id={trace_id} "
                        f"error='{str(e)}' "
                        f"'VADæ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨ç®€å•å°¾éƒ¨ä¿å­˜ä¸Šä¸‹æ–‡'"
                    )
                    original_vad_segments = []
                
                if len(original_vad_segments) > 0:
                    # é€‰æ‹©æœ€åä¸€ä¸ªè¯­éŸ³æ®µ
                    last_start, last_end = original_vad_segments[-1]
                    last_segment = audio[last_start:last_end]
                    context_samples = int(CONTEXT_DURATION_SEC * CONTEXT_SAMPLE_RATE)
                    
                    if len(last_segment) > context_samples:
                        logger.info(
                            f"[{trace_id}] trace_id={trace_id} "
                            f"context_samples={context_samples} "
                            f"context_duration_sec={context_samples/CONTEXT_SAMPLE_RATE:.3f} "
                            f"segment_start={last_start} "
                            f"segment_end={last_end} "
                            f"segment_samples={len(last_segment)} "
                            f"'âœ… æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒºï¼ˆä½¿ç”¨VADé€‰æ‹©çš„æœ€åä¸€ä¸ªè¯­éŸ³æ®µå°¾éƒ¨ï¼‰'"
                        )
                    else:
                        logger.info(
                            f"[{trace_id}] trace_id={trace_id} "
                            f"context_samples={len(last_segment)} "
                            f"context_duration_sec={len(last_segment)/CONTEXT_SAMPLE_RATE:.3f} "
                            f"segment_samples={len(last_segment)} "
                            f"'âœ… æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒºï¼ˆæœ€åä¸€ä¸ªè¯­éŸ³æ®µè¾ƒçŸ­ï¼Œä¿å­˜å…¨éƒ¨ï¼‰'"
                        )
                    
                    logger.info(f"[{trace_id}] Step 12.2: Updating context buffer")
                    update_context_buffer(audio, original_vad_segments)
                    logger.info(f"[{trace_id}] Step 12.2: Context buffer updated successfully")
                else:
                    # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³æ®µï¼Œå›é€€åˆ°ç®€å•å°¾éƒ¨ä¿å­˜
                    context_samples = int(CONTEXT_DURATION_SEC * CONTEXT_SAMPLE_RATE)
                    if len(audio) > context_samples:
                        logger.info(
                            f"[{trace_id}] trace_id={trace_id} "
                            f"context_samples={context_samples} "
                            f"context_duration_sec={context_samples/CONTEXT_SAMPLE_RATE:.3f} "
                            f"original_samples={len(audio)} "
                            f"'âš ï¸ æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒºï¼ˆVADæœªæ£€æµ‹åˆ°è¯­éŸ³æ®µï¼Œä¿å­˜æœ€å{CONTEXT_DURATION_SEC}ç§’ï¼‰'"
                        )
                    else:
                        logger.info(
                            f"[{trace_id}] trace_id={trace_id} "
                            f"context_samples={len(audio)} "
                            f"context_duration_sec={len(audio)/CONTEXT_SAMPLE_RATE:.3f} "
                            f"original_samples={len(audio)} "
                            f"'âš ï¸ æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒºï¼ˆutteranceè¾ƒçŸ­ï¼Œä¿å­˜å…¨éƒ¨ï¼‰'"
                        )
                    
                    logger.info(f"[{trace_id}] Step 12.2: Updating context buffer")
                    update_context_buffer(audio, [])
                    logger.info(f"[{trace_id}] Step 12.2: Context buffer updated successfully")
            logger.info(f"[{trace_id}] Step 12: Context buffer update completed")
        except Exception as e:
            logger.error(f"[{trace_id}] Step 12: Failed to update context buffer: {e}", exc_info=True)
            raise
        
        logger.info(f"[{trace_id}] Step 13: Starting response construction")
        
        # 13. è¿”å›ç»“æœ
        # å…³é”®ä¿®å¤ï¼šè¿”å›å»é‡åçš„æ–‡æœ¬ï¼Œè€Œä¸æ˜¯åŸå§‹æ–‡æœ¬
        try:
            response = UtteranceResponse(
                text=full_text_trimmed,  # ä½¿ç”¨å»é‡åçš„æ–‡æœ¬
                segments=segments_info,  # ä½¿ç”¨åŒ…å«æ—¶é—´æˆ³çš„ segments
                language=info_language,
                language_probability=language_probability,  # æ–°å¢ï¼šæ£€æµ‹åˆ°çš„è¯­è¨€çš„æ¦‚ç‡
                language_probabilities=language_probabilities,  # æ–°å¢ï¼šæ‰€æœ‰è¯­è¨€çš„æ¦‚ç‡ä¿¡æ¯
                duration=info_duration,
                vad_segments=vad_segments,
            )
            logger.info(f"[{trace_id}] Step 13: Response constructed successfully, returning deduplicated text (len={len(full_text_trimmed)})")
            return response
        except Exception as e:
            logger.error(f"[{trace_id}] Step 13: Failed to construct response: {e}", exc_info=True)
            raise
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Utterance processing error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Utterance processing failed: {str(e)}")

# ---------------------
# Main
# ---------------------
if __name__ == "__main__":
    import uvicorn
    logger.info(f"Starting Faster Whisper + Silero VAD service on port {PORT}...")
    uvicorn.run(app, host="0.0.0.0", port=PORT)
