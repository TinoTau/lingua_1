# 方言 + 用户参与训练方向：可行性评估

## 方向简述

- **后期**允许用户参与训练方言/口音模型；
- 对常用方言的用户做**细化**，对通用模型做**调参**或**换模型**；
- 当用户选择「某种方言 + 普通话」为常用语言时，为其安排**带口音的普通话 ASR 模型**执行语音识别。

结论：**可行**，但宜分阶段做；短期可先做「用户偏好 → 语言/模型路由」，中长期再考虑用户参与训练与专用口音模型。

---

## 一、当前能力与缺口

### 1. 现有链路

- **节点端**：ASR 请求带 `src_lang`（及可选 `lang_a`/`lang_b`），见 `task-router-asr.ts`。
- **faster-whisper-vad**：请求体有 `src_lang`、`language`；`api_routes.py` 中若 `src_lang != "auto"` 则 `asr_language = req.src_lang`，否则用 `req.language` 或自动检测；最终传给 `model.transcribe(..., language=asr_language)`。
- **模型**：当前多为 `Systran/faster-whisper-base`，单模型、单 checkpoint；通过 `ASR_MODEL_PATH` 配置。

即：**语言/方言维度**已具备「请求 → ASR 服务 → transcribe(language=…)」的贯通，缺的是「用户常用方言」到「用哪个 language / 用哪套模型」的决策与路由。

### 2. Whisper / faster-whisper 对中文方言的支持

- **语言代码**：支持 `zh`（普通话）、`yue`（粤语）等；large-v3 等大模型对多种中文方言/口音支持更好。
- **已知问题**：自动检测常把粤语识别成 `zh`；**显式传 `language=yue`** 可显著改善粤语识别。
- **口音/带口音普通话**：大模型本身对「带口音的普通话」有一定鲁棒性；若要更好，需**针对该口音微调**或使用**口音专用 checkpoint**（见下）。

因此：  
- 短期不换模型，仅靠「用户选方言 → 传对应 language 码」即可见效（尤其粤语等已有码的方言）。  
- 中期可引入「多模型/多 checkpoint」并按用户偏好路由。  
- 长期再考虑「用户参与训练」得到专用口音模型。

---

## 二、分阶段可行性

### 阶段一：用户偏好 → 语言码（不换模型、不训练）

- **做法**：在会话/用户配置中增加「常用语言/方言」选项（如 普通话、粤语+普通话、四川话+普通话 等）。调度/节点在组 ASR 任务时，根据该偏好设置 `src_lang`（或等价字段）：例如选「粤语+普通话」时传 `language=yue` 或按策略在 `zh`/`yue` 间选择。现有 faster-whisper-vad 已支持按 `language` 解码，**无需改 ASR 服务代码**，只需在上游（central 或节点）根据用户偏好写入请求参数。
- **可行性**：高；仅涉及配置与路由逻辑，无新模型、无训练。
- **局限**：只能利用现有 Whisper 对 `zh`/`yue` 等的支持；对「四川话+普通话」等无独立语言码的口音，仍主要依赖 `zh` 或未来扩展的语言码。

### 阶段二：多模型/多 checkpoint 按用户路由（调参/换模型）

- **做法**：  
  - 同一套 faster-whisper-vad 支持多套模型路径（如 通用 base、粤语优化、四川口音微调），通过配置或环境区分；或  
  - 不同节点/实例挂载不同 ASR 模型，调度层按用户「方言+普通话」偏好把任务派到对应实例。  
  用户选择「粤语+普通话」时，为其分配使用「粤语/口音优化」模型或更大模型（如 large-v3）的 ASR 实例；选择「仅普通话」则用通用 base 即可。
- **可行性**：中高；需要部署与调度配合（模型版本、实例标签、路由策略），以及适量「口音优化」或「方言」模型来源（见下）。
- **模型来源**：  
  - 使用官方或社区的 **large-v3** 等，对多方言/口音更好；  
  - 使用已公开的**方言/口音微调模型**（如 HuggingFace 上的 faster-whisper-large-v3-zh-TW 等）；  
  - 自行在「通用模型 + 方言/口音数据」上微调，得到专用 checkpoint，再通过 `ASR_MODEL_PATH` 或类似机制切换。

### 阶段三：用户参与训练方言/口音模型

- **含义**：用户贡献语音或转写，用于微调/训练「带口音的普通话」或某方言的 ASR模型；系统对该用户（或同口音群体）后续使用「专用口音模型」或专用调参。
- **可行性**：中长期可行，但依赖数据与合规。
  - **数据**：需收集该口音下的「音频 + 转写」；可来自用户自愿上传、授权录音或脱敏语料。
  - **合规**：隐私政策、授权同意、数据保留与删除、是否允许用于训练等，需明确并落地。
  - **工程**：训练/微调管线（数据清洗、标注/校验、训练脚本、评估、版本发布）、模型版本与 A/B 策略、回滚机制。
  - **产品**：用户侧「是否参与贡献」「贡献哪些场景」的入口与说明；对「已参与训练」的用户如何绑定到专用模型或参数的策略。
- **建议**：先做阶段一、二，验证「方言/口音路由」的价值和用量，再投入用户参与训练与专用模型管线。

---

## 三、与「调参」的关系

- **仅调参（不换模型）**：在现有单模型上，按用户偏好调整 **decode 参数**（如 `language`、`beam_size`、`temperature` 等）是可行的；faster-whisper-vad 已支持从请求或配置传入部分参数，扩展为「按用户偏好选择预设参数组」即可。
- **换模型 / 多模型**：若希望「带口音的普通话」明显优于通用 base，通常需要**换用更大模型或口音/方言微调模型**（即阶段二），单靠调参收益有限。

因此：「对通用模型调参」适合作为阶段一的补充；真正细化到「带口音普通话」体验，需要阶段二的模型路由或专用 checkpoint。

---

## 四、建议落地顺序

| 阶段 | 内容 | 可行性 | 说明 |
|------|------|--------|------|
| 1 | 用户选「方言+普通话」→ 仅改 `src_lang`/`language`，不换模型 | 高 | 立刻可用；粤语等已有语言码收益明显。 |
| 2 | 按用户偏好做 ASR 模型/实例路由（多 checkpoint 或多实例） | 中高 | 需部署与调度设计；可先用 large-v3 或现成方言模型。 |
| 3 | 用户参与训练 + 专用口音模型 | 中（长期） | 依赖数据、合规与训练管线；建议在 1、2 验证后再投入。 |

当前代码已支持「请求级 language」与单模型配置；新增「用户常用方言 → language/模型路由」即可支撑阶段一，并为阶段二预留扩展（例如在 job/session 上带 `asr_model_preference` 或 `dialect`，由调度/节点映射到具体 ASR 实例或模型配置）。

---

## 五、小结

- **方向可行**：先根据用户选择的「方言+普通话」做语言码或模型路由（带口音的普通话 ASR），再视需要引入用户参与训练与专用口音模型。
- **建议**：  
  - 短期：实现「用户常用语言/方言 → `src_lang`/`language`」映射，必要时对部分方言显式传 `language`（如 `yue`），不换模型即可见效。  
  - 中期：支持多 ASR 模型/实例并按用户偏好路由，或引入 large-v3/方言微调模型。  
  - 长期：在合规与数据到位的前提下，再考虑用户参与训练和专用口音模型的闭环。
