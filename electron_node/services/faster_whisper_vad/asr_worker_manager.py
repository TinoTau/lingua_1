"""
ASR Worker Manager - è¿›ç¨‹ç®¡ç†å’Œ Watchdog
ç®¡ç† ASR Worker å­è¿›ç¨‹ï¼Œå®ç°è‡ªåŠ¨é‡å¯å’Œå¥åº·ç›‘æ§
"""
import multiprocessing as mp
import queue
import asyncio
import logging
import time
import numpy as np
import pickle
from typing import Optional, Dict, Any, List
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)

# é˜Ÿåˆ—é…ç½®
QUEUE_MAX = 1  # è¿›ç¨‹é—´é˜Ÿåˆ—å»ºè®®ä½¿ç”¨è¾ƒå°çš„å€¼ï¼ˆ1-2ï¼‰
MAX_WAIT_SECONDS = 30.0  # æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰


class WorkerState(Enum):
    """Worker çŠ¶æ€"""
    STOPPED = "stopped"
    STARTING = "starting"
    RUNNING = "running"
    CRASHED = "crashed"
    RESTARTING = "restarting"


@dataclass
class ASRTask:
    """ASR ä»»åŠ¡ï¼ˆç”¨äºè¿›ç¨‹é—´é€šä¿¡ï¼‰"""
    job_id: str
    trace_id: str
    audio: bytes  # åºåˆ—åŒ–çš„ numpy array
    audio_len: int
    sample_rate: int
    language: Optional[str]
    task: str
    beam_size: int
    initial_prompt: Optional[str]
    condition_on_previous_text: bool
    # æ–°å¢ï¼šæé«˜å‡†ç¡®åº¦çš„å‚æ•°
    best_of: Optional[int] = None
    temperature: Optional[float] = None
    patience: Optional[float] = None
    compression_ratio_threshold: Optional[float] = None
    log_prob_threshold: Optional[float] = None
    no_speech_threshold: Optional[float] = None


@dataclass
class SegmentInfo:
    """Segment ä¿¡æ¯"""
    text: str
    start: Optional[float] = None  # å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
    end: Optional[float] = None    # ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
    no_speech_prob: Optional[float] = None  # æ— è¯­éŸ³æ¦‚ç‡ï¼ˆå¯é€‰ï¼‰

@dataclass
class ASRResult:
    """ASR ç»“æœ"""
    job_id: str
    text: Optional[str] = None
    language: Optional[str] = None
    language_probabilities: Optional[Dict[str, float]] = None  # æ–°å¢ï¼šè¯­è¨€æ¦‚ç‡ä¿¡æ¯ï¼ˆå­—å…¸ï¼šè¯­è¨€ä»£ç  -> æ¦‚ç‡ï¼‰
    segments: Optional[List[SegmentInfo]] = None  # æ–°å¢ï¼šSegment å…ƒæ•°æ®ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
    duration_ms: int = 0
    error: Optional[str] = None


class ASRWorkerManager:
    """
    ASR Worker è¿›ç¨‹ç®¡ç†å™¨
    è´Ÿè´£å¯åŠ¨ã€ç›‘æ§å’Œé‡å¯ ASR Worker å­è¿›ç¨‹
    """
    
    def __init__(self, queue_max: int = QUEUE_MAX):
        self.queue_max = queue_max
        self.task_queue: Optional[mp.Queue] = None
        self.result_queue: Optional[mp.Queue] = None
        self.worker_process: Optional[mp.Process] = None
        self.state = WorkerState.STOPPED
        self.watchdog_task: Optional[asyncio.Task] = None
        self.is_running = False
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_tasks": 0,
            "completed_tasks": 0,
            "failed_tasks": 0,
            "worker_restarts": 0,
            "queue_depth": 0,
            "avg_wait_ms": 0.0,
        }
        
        # å¾…å¤„ç†çš„ç»“æœï¼ˆjob_id -> Futureï¼‰
        self.pending_results: Dict[str, asyncio.Future] = {}
        
        # ç»“æœç›‘å¬ä»»åŠ¡
        self.result_listener_task: Optional[asyncio.Task] = None
    
    async def start(self):
        """å¯åŠ¨ Worker Manager"""
        if self.is_running:
            logger.warning("ASR Worker Manager is already running")
            return
        
        logger.info("Starting ASR Worker Manager...")
        
        # åˆ›å»ºè¿›ç¨‹é—´é˜Ÿåˆ—
        self.task_queue = mp.Queue(maxsize=self.queue_max)
        self.result_queue = mp.Queue()
        
        # å¯åŠ¨ Worker è¿›ç¨‹
        await self._start_worker()
        
        # å¯åŠ¨ç»“æœç›‘å¬å™¨
        self.result_listener_task = asyncio.create_task(self._result_listener())
        
        # å¯åŠ¨ Watchdog
        self.is_running = True
        self.watchdog_task = asyncio.create_task(self._watchdog_loop())
        
        logger.info("ASR Worker Manager started")
    
    async def stop(self):
        """åœæ­¢ Worker Manager"""
        logger.info("Stopping ASR Worker Manager...")
        
        self.is_running = False
        
        # åœæ­¢ Watchdog
        if self.watchdog_task:
            self.watchdog_task.cancel()
            try:
                await self.watchdog_task
            except asyncio.CancelledError:
                pass
        
        # åœæ­¢ç»“æœç›‘å¬å™¨
        if self.result_listener_task:
            self.result_listener_task.cancel()
            try:
                await self.result_listener_task
            except asyncio.CancelledError:
                pass
        
        # åœæ­¢ Worker è¿›ç¨‹
        await self._stop_worker()
        
        logger.info("ASR Worker Manager stopped")
    
    async def _start_worker(self):
        """å¯åŠ¨ Worker å­è¿›ç¨‹"""
        if self.worker_process and self.worker_process.is_alive():
            logger.warning("Worker process is already running")
            return
        
        logger.info("Starting ASR Worker process...")
        self.state = WorkerState.STARTING
        
        try:
            # å¯¼å…¥ worker å‡½æ•°ï¼ˆå¿…é¡»åœ¨ä¸»è¿›ç¨‹ä¸­å¯¼å…¥ï¼‰
            from asr_worker_process import asr_worker_process
            
            # åˆ›å»ºå­è¿›ç¨‹
            self.worker_process = mp.Process(
                target=asr_worker_process,
                args=(self.task_queue, self.result_queue),
                name="ASRWorkerProcess"
            )
            self.worker_process.start()
            
            # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œæ£€æŸ¥è¿›ç¨‹æ˜¯å¦ç«‹å³å´©æºƒ
            await asyncio.sleep(0.5)
            
            if not self.worker_process.is_alive():
                logger.error("Worker process crashed immediately after start")
                self.state = WorkerState.CRASHED
                raise RuntimeError("Worker process failed to start")
            
            self.state = WorkerState.RUNNING
            logger.info(f"ASR Worker process started (PID: {self.worker_process.pid})")
            
        except Exception as e:
            logger.error(f"Failed to start ASR Worker process: {e}", exc_info=True)
            self.state = WorkerState.CRASHED
            raise
    
    async def _stop_worker(self):
        """åœæ­¢ Worker å­è¿›ç¨‹"""
        if not self.worker_process:
            return
        
        logger.info("Stopping ASR Worker process...")
        self.state = WorkerState.STOPPED
        
        # å‘é€é€€å‡ºä¿¡å·
        try:
            if self.task_queue:
                self.task_queue.put(None)  # None è¡¨ç¤ºé€€å‡ºä¿¡å·
        except Exception as e:
            logger.warning(f"Failed to send shutdown signal to worker: {e}")
        
        # ç­‰å¾…è¿›ç¨‹é€€å‡ºï¼ˆæœ€å¤š 5 ç§’ï¼‰
        try:
            self.worker_process.join(timeout=5.0)
            if self.worker_process.is_alive():
                logger.warning("Worker process did not exit gracefully, terminating...")
                self.worker_process.terminate()
                self.worker_process.join(timeout=2.0)
                if self.worker_process.is_alive():
                    logger.warning("Worker process still alive, killing...")
                    self.worker_process.kill()
                    self.worker_process.join()
        except Exception as e:
            logger.error(f"Error stopping worker process: {e}", exc_info=True)
        
        self.worker_process = None
        logger.info("ASR Worker process stopped")
    
    async def _watchdog_loop(self):
        """Watchdog å¾ªç¯ï¼šç›‘æ§ Worker è¿›ç¨‹å¥åº·çŠ¶æ€"""
        logger.info("ASR Worker Watchdog started")
        
        last_check_time = time.time()
        consecutive_checks = 0
        
        while self.is_running:
            try:
                await asyncio.sleep(1.0)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
                consecutive_checks += 1
                current_time = time.time()
                
                if not self.worker_process:
                    if consecutive_checks % 60 == 0:  # æ¯åˆ†é’Ÿè®°å½•ä¸€æ¬¡
                        logger.warning("ASR Worker process is None, waiting for initialization...")
                    continue
                
                # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜æ´»
                is_alive = self.worker_process.is_alive()
                worker_pid = self.worker_process.pid if self.worker_process else None
                
                # æ¯ 30 ç§’è®°å½•ä¸€æ¬¡å¥åº·çŠ¶æ€ï¼ˆç”¨äºç›‘æ§ï¼‰
                if consecutive_checks % 30 == 0:
                    logger.debug(
                        f"Watchdog health check: worker_pid={worker_pid}, "
                        f"is_alive={is_alive}, state={self.state.value}, "
                        f"queue_depth={self.task_queue.qsize() if self.task_queue else 0}, "
                        f"pending_results={len(self.pending_results)}"
                    )
                
                if not is_alive:
                    # Worker è¿›ç¨‹å´©æºƒ
                    logger.error("=" * 80)
                    logger.error("ğŸš¨ ASR Worker process CRASHED detected by Watchdog")
                    logger.error(f"   Worker PID: {worker_pid}")
                    logger.error(f"   State before crash: {self.state.value}")
                    logger.error(f"   Time since last check: {current_time - last_check_time:.2f}s")
                    logger.error(f"   Pending results: {len(self.pending_results)}")
                    logger.error(f"   Queue depth: {self.task_queue.qsize() if self.task_queue else 0}")
                    
                    # å°è¯•è·å–é€€å‡ºç ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    try:
                        exitcode = self.worker_process.exitcode
                        if exitcode is not None:
                            logger.error(f"   Exit code: {exitcode}")
                            if exitcode < 0:
                                logger.error(f"   Process terminated by signal: {-exitcode}")
                            elif exitcode > 0:
                                logger.error(f"   Process exited with error code: {exitcode}")
                            else:
                                logger.info(f"   Process exited normally (code 0)")
                    except Exception as e:
                        logger.warning(f"   Could not get exit code: {e}")
                    
                    logger.error("=" * 80)
                    
                    self.state = WorkerState.CRASHED
                    self.stats["worker_restarts"] += 1
                    
                    # æ¸…ç†å¤±è´¥çš„è¿›ç¨‹
                    old_pid = worker_pid
                    self.worker_process = None
                    
                    # é‡å¯ Worker
                    logger.info(f"Attempting to restart ASR Worker process (restart #{self.stats['worker_restarts']})...")
                    try:
                        self.state = WorkerState.RESTARTING
                        restart_start = time.time()
                        await self._start_worker()
                        restart_elapsed = time.time() - restart_start
                        new_pid = self.worker_process.pid if self.worker_process else None
                        logger.info(
                            f"âœ… ASR Worker process restarted successfully "
                            f"(old_pid={old_pid}, new_pid={new_pid}, elapsed={restart_elapsed:.2f}s)"
                        )
                    except Exception as e:
                        logger.error(
                            f"âŒ Failed to restart ASR Worker process: {e}",
                            exc_info=True
                        )
                        self.state = WorkerState.CRASHED
                        # ç»§ç»­å°è¯•é‡å¯ï¼ˆåœ¨ä¸‹æ¬¡å¾ªç¯ä¸­ï¼‰
                        await asyncio.sleep(2.0)  # ç­‰å¾… 2 ç§’åé‡è¯•
                
                last_check_time = current_time
                
            except asyncio.CancelledError:
                logger.info("ASR Worker Watchdog cancelled")
                break
            except Exception as e:
                logger.error(f"Watchdog loop error: {e}", exc_info=True)
                await asyncio.sleep(1.0)
        
        logger.info("ASR Worker Watchdog stopped")
    
    async def _result_listener(self):
        """ç»“æœç›‘å¬å™¨ï¼šä»ç»“æœé˜Ÿåˆ—è¯»å–ç»“æœå¹¶è®¾ç½® Future"""
        logger.info("ASR Worker result listener started")
        
        while self.is_running:
            try:
                # éé˜»å¡æ£€æŸ¥ç»“æœé˜Ÿåˆ—
                # æ³¨æ„ï¼šmultiprocessing.Queue æ²¡æœ‰å¼‚æ­¥æ¥å£ï¼Œéœ€è¦ä½¿ç”¨çº¿ç¨‹
                try:
                    # å…ˆæ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦ä¸ºç©ºï¼ˆé¿å…é˜»å¡ï¼‰
                    if self.result_queue.empty():
                        await asyncio.sleep(0.1)  # çŸ­æš‚ç­‰å¾…
                        continue
                    
                    # é˜Ÿåˆ—ä¸ä¸ºç©ºï¼Œè·å–ç»“æœï¼ˆä½¿ç”¨ get_nowait æˆ–å¸¦è¶…æ—¶çš„ getï¼‰
                    try:
                        result_data = await asyncio.to_thread(
                            lambda: self.result_queue.get_nowait()
                        )
                    except queue.Empty:
                        # é˜Ÿåˆ—ä¸ºç©ºï¼ˆå¯èƒ½åœ¨æ£€æŸ¥ååˆè¢«å…¶ä»–è¿›ç¨‹å–èµ°ï¼‰ï¼Œç»§ç»­å¾ªç¯
                        await asyncio.sleep(0.1)
                        continue
                    except Exception as e:
                        # å…¶ä»–å¼‚å¸¸ï¼Œè®°å½•å¹¶ç»§ç»­
                        logger.warning(f"Result queue get_nowait error: {e}")
                        await asyncio.sleep(0.1)
                        continue
                except Exception as e:
                    # è¶…æ—¶æˆ–é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­å¾ªç¯
                    error_str = str(e).lower()
                    if "empty" not in error_str and "timeout" not in error_str:
                        logger.warning(f"Result queue get error: {e}")
                    await asyncio.sleep(0.1)  # çŸ­æš‚ç­‰å¾…åç»§ç»­
                    continue
                
                # å¤„ç†ç»“æœ
                job_id = result_data.get("job_id")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åˆå§‹åŒ–é”™è¯¯
                if job_id == "__init_error__":
                    logger.error("=" * 80)
                    logger.error("ğŸš¨ Worker process initialization failed!")
                    logger.error(f"   Error: {result_data.get('error')}")
                    logger.error("=" * 80)
                    # é€šçŸ¥æ‰€æœ‰å¾…å¤„ç†çš„ä»»åŠ¡
                    for future in list(self.pending_results.values()):
                        if not future.done():
                            future.set_exception(
                                RuntimeError(f"Worker initialization failed: {result_data.get('error')}")
                            )
                    self.pending_results.clear()
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ Worker é€€å‡ºé€šçŸ¥
                if job_id == "__worker_exit__":
                    logger.warning("=" * 80)
                    logger.warning("âš ï¸  Worker process exit notification received")
                    logger.warning(f"   Message: {result_data.get('error')}")
                    logger.warning("=" * 80)
                    # é€šçŸ¥æ‰€æœ‰å¾…å¤„ç†çš„ä»»åŠ¡
                    for future in list(self.pending_results.values()):
                        if not future.done():
                            future.set_exception(
                                RuntimeError(f"Worker process exited: {result_data.get('error')}")
                            )
                    self.pending_results.clear()
                    # Watchdog ä¼šæ£€æµ‹åˆ°è¿›ç¨‹æ­»äº¡å¹¶é‡å¯
                    continue
                
                # æŸ¥æ‰¾å¯¹åº”çš„ Future
                future = self.pending_results.pop(job_id, None)
                if future:
                    if result_data.get("error"):
                        # è®¾ç½®å¼‚å¸¸
                        future.set_exception(Exception(result_data["error"]))
                        self.stats["failed_tasks"] += 1
                    else:
                        # è®¾ç½®ç»“æœ
                        # è½¬æ¢ segments æ•°æ®
                        segments_raw = result_data.get("segments")
                        segments_list = None
                        if segments_raw:
                            segments_list = [
                                SegmentInfo(
                                    text=seg.get("text", ""),
                                    start=seg.get("start"),
                                    end=seg.get("end"),
                                    no_speech_prob=seg.get("no_speech_prob"),
                                )
                                for seg in segments_raw
                            ]
                        
                        result = ASRResult(
                            job_id=job_id,
                            text=result_data.get("text"),
                            language=result_data.get("language"),
                            language_probabilities=result_data.get("language_probabilities"),  # æ–°å¢ï¼šè¯­è¨€æ¦‚ç‡ä¿¡æ¯
                            segments=segments_list,  # æ–°å¢ï¼šSegment å…ƒæ•°æ®
                            duration_ms=result_data.get("duration_ms", 0),
                            error=None
                        )
                        future.set_result(result)
                        self.stats["completed_tasks"] += 1
                else:
                    logger.warning(f"Received result for unknown job_id: {job_id}")
                
            except asyncio.CancelledError:
                logger.info("ASR Worker result listener cancelled")
                break
            except Exception as e:
                logger.error(f"Result listener error: {e}", exc_info=True)
                await asyncio.sleep(0.1)
        
        logger.info("ASR Worker result listener stopped")
    
    async def submit_task(
        self,
        audio: np.ndarray,
        sample_rate: int,
        language: Optional[str],
        task: str,
        beam_size: int,
        initial_prompt: Optional[str],
        condition_on_previous_text: bool,
        trace_id: str,
        max_wait: float = MAX_WAIT_SECONDS,
        # æ–°å¢ï¼šæé«˜å‡†ç¡®åº¦çš„å‚æ•°
        best_of: Optional[int] = None,
        temperature: Optional[float] = None,
        patience: Optional[float] = None,
        compression_ratio_threshold: Optional[float] = None,
        log_prob_threshold: Optional[float] = None,
        no_speech_threshold: Optional[float] = None,
    ) -> ASRResult:
        """
        æäº¤ ASR ä»»åŠ¡åˆ° Worker è¿›ç¨‹
        
        Returns:
            ASRResult: ASR ç»“æœ
            
        Raises:
            asyncio.TimeoutError: ç­‰å¾…è¶…æ—¶
            RuntimeError: Worker è¿›ç¨‹ä¸å¯ç”¨
        """
        # æ£€æŸ¥ Worker çŠ¶æ€
        if self.state != WorkerState.RUNNING or not self.worker_process or not self.worker_process.is_alive():
            raise RuntimeError("ASR Worker process is not available")
        
        # æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å·²æ»¡
        if self.task_queue.full():
            raise RuntimeError("ASR queue is full")
        
        # ç”Ÿæˆ job_id
        job_id = f"{trace_id}_{int(time.time() * 1000)}"
        
        # åºåˆ—åŒ–éŸ³é¢‘æ•°æ®
        try:
            audio_bytes = pickle.dumps(audio)
        except Exception as e:
            raise RuntimeError(f"Failed to serialize audio data: {e}")
        
        # åˆ›å»ºä»»åŠ¡
        asr_task = ASRTask(
            job_id=job_id,
            trace_id=trace_id,
            audio=audio_bytes,
            audio_len=len(audio),
            sample_rate=sample_rate,
            language=language,
            task=task,
            beam_size=beam_size,
            initial_prompt=initial_prompt,
            condition_on_previous_text=condition_on_previous_text,
            best_of=best_of,
            temperature=temperature,
            patience=patience,
            compression_ratio_threshold=compression_ratio_threshold,
            log_prob_threshold=log_prob_threshold,
            no_speech_threshold=no_speech_threshold,
        )
        
        # åˆ›å»º Future
        future = asyncio.get_event_loop().create_future()
        self.pending_results[job_id] = future
        
        # è®°å½•ç­‰å¾…å¼€å§‹æ—¶é—´
        wait_start = time.time()
        
        # æäº¤åˆ°é˜Ÿåˆ—
        try:
            # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œé˜»å¡çš„ put æ“ä½œ
            # æ³¨æ„ï¼šéœ€è¦ä¼ é€’æ‰€æœ‰ä¼˜åŒ–å‚æ•°åˆ° worker è¿›ç¨‹
            task_dict = {
                "job_id": job_id,
                "trace_id": trace_id,
                "audio": audio_bytes,
                "audio_len": len(audio),
                "sample_rate": sample_rate,
                "language": language,
                "task": task,
                "beam_size": beam_size,
                "initial_prompt": initial_prompt,
                "condition_on_previous_text": condition_on_previous_text,
            }
            # æ·»åŠ ä¼˜åŒ–å‚æ•°ï¼ˆå¦‚æœæä¾›ï¼‰
            if best_of is not None:
                task_dict["best_of"] = best_of
            if temperature is not None:
                task_dict["temperature"] = temperature
            if patience is not None:
                task_dict["patience"] = patience
            if compression_ratio_threshold is not None:
                task_dict["compression_ratio_threshold"] = compression_ratio_threshold
            if log_prob_threshold is not None:
                task_dict["log_prob_threshold"] = log_prob_threshold
            if no_speech_threshold is not None:
                task_dict["no_speech_threshold"] = no_speech_threshold
            
            await asyncio.to_thread(self.task_queue.put, task_dict)
        except Exception as e:
            # æ¸…ç† Future
            self.pending_results.pop(job_id, None)
            raise RuntimeError(f"Failed to submit task to queue: {e}")
        
        self.stats["total_tasks"] += 1
        
        # ç­‰å¾…ç»“æœï¼ˆå¸¦è¶…æ—¶ï¼‰
        try:
            result = await asyncio.wait_for(future, timeout=max_wait)
            
            # è®¡ç®—ç­‰å¾…æ—¶é—´
            wait_time_ms = (time.time() - wait_start) * 1000
            if self.stats["completed_tasks"] > 0:
                self.stats["avg_wait_ms"] = (
                    (self.stats["avg_wait_ms"] * (self.stats["completed_tasks"] - 1) + wait_time_ms) /
                    self.stats["completed_tasks"]
                )
            else:
                self.stats["avg_wait_ms"] = wait_time_ms
            
            return result
            
        except asyncio.TimeoutError:
            # è¶…æ—¶ï¼šæ¸…ç† Future
            self.pending_results.pop(job_id, None)
            logger.warning(
                f"[{trace_id}] ASR task timeout after {max_wait}s, "
                f"queue_depth={self.task_queue.qsize()}"
            )
            raise
        except Exception as e:
            # å…¶ä»–å¼‚å¸¸ï¼šæ¸…ç† Future
            self.pending_results.pop(job_id, None)
            raise
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å– Worker Manager ç»Ÿè®¡ä¿¡æ¯"""
        queue_depth = 0
        if self.task_queue:
            try:
                queue_depth = self.task_queue.qsize()
            except Exception:
                pass
        
        return {
            **self.stats,
            "queue_depth": queue_depth,
            "is_running": self.is_running,
            "worker_state": self.state.value,
            "worker_pid": self.worker_process.pid if (self.worker_process and self.worker_process.is_alive()) else None,
            "pending_results": len(self.pending_results),
        }
    
    def is_queue_full(self) -> bool:
        """æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å·²æ»¡"""
        if not self.task_queue:
            return True
        try:
            return self.task_queue.full()
        except Exception:
            return True

