"""
Faster Whisper + Silero VAD Service - Utterance Processor
å¤„ç† Utterance è¯·æ±‚çš„æ ¸å¿ƒé€»è¾‘
"""
import numpy as np
import logging
import time
import asyncio
from typing import Optional, List, Tuple, Dict, Any
from fastapi import HTTPException
from scipy import signal

from config import (
    MAX_AUDIO_DURATION_SEC,
    CONTEXT_SAMPLE_RATE,
    CONTEXT_DURATION_SEC,
    MAX_WAIT_SECONDS,
)
from audio_decoder import decode_audio
from vad import detect_speech
from context import get_context_audio, update_context_buffer
from audio_validation import (
    validate_audio_format,
    log_audio_validation_info,
    check_audio_quality,
    truncate_audio_if_needed,
)
from shared_types import SegmentInfo as SharedSegmentInfo
from text_processing import (
    SegmentInfo as SegmentInfoModel,
    process_text_deduplication,
    filter_context_substring,
    update_segments_after_deduplication,
    update_text_context_if_needed,
)
from text_filter import is_meaningless_transcript
from asr_worker_manager import ASRWorkerManager

logger = logging.getLogger(__name__)


def decode_and_preprocess_audio(
    audio_b64: str,
    audio_format: str,
    sample_rate: int,
    padding_ms: Optional[int],
    trace_id: str
) -> Tuple[np.ndarray, int]:
    """
    è§£ç å’Œé¢„å¤„ç†éŸ³é¢‘
    
    Args:
        audio_b64: Base64ç¼–ç çš„éŸ³é¢‘æ•°æ®
        audio_format: éŸ³é¢‘æ ¼å¼
        sample_rate: é‡‡æ ·ç‡
        padding_ms: å°¾éƒ¨é™éŸ³paddingï¼ˆæ¯«ç§’ï¼‰
        trace_id: è¿½è¸ªID
    
    Returns:
        (audio, sample_rate) - å¤„ç†åçš„éŸ³é¢‘å’Œé‡‡æ ·ç‡
    """
    logger.info(f"[{trace_id}] Audio format: {audio_format}, sample_rate: {sample_rate}")
    
    try:
        audio, sr = decode_audio(audio_b64, audio_format, sample_rate, trace_id)
    except ValueError as e:
        logger.error(f"[{trace_id}] Audio decoding failed: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.critical(
            f"[{trace_id}] ğŸš¨ CRITICAL: Audio decoding raised unexpected exception: {e}, "
            f"error_type={type(e).__name__}",
            exc_info=True
        )
        raise HTTPException(status_code=500, detail=f"Audio decoding error: {str(e)}")
    
    # æ£€æŸ¥éŸ³é¢‘é•¿åº¦é™åˆ¶
    audio = truncate_audio_if_needed(audio, sr, trace_id)
    
    # é‡é‡‡æ ·åˆ°æŒ‡å®šé‡‡æ ·ç‡ï¼ˆé»˜è®¤ 16kHzï¼‰
    if sr != sample_rate:
        logger.warning(f"[{trace_id}] Audio sample rate is {sr}Hz, expected {sample_rate}Hz. Resampling...")
        num_samples = int(len(audio) * sample_rate / sr)
        audio = signal.resample(audio, num_samples).astype(np.float32)
        sr = sample_rate
    
    # é‡é‡‡æ ·åå†æ¬¡æ£€æŸ¥éŸ³é¢‘é•¿åº¦é™åˆ¶
    audio = truncate_audio_if_needed(audio, sr, trace_id)
    
    # ç¡®ä¿éŸ³é¢‘æ˜¯è¿ç»­çš„
    if not audio.flags['C_CONTIGUOUS']:
        audio = np.ascontiguousarray(audio)
    
    # EDGE-4: Paddingï¼ˆåœ¨éŸ³é¢‘æœ«å°¾æ·»åŠ é™éŸ³ï¼‰
    if padding_ms is not None and padding_ms > 0:
        padding_samples = int((padding_ms / 1000.0) * sr)
        if padding_samples > 0:
            padding = np.zeros(padding_samples, dtype=np.float32)
            audio = np.concatenate([audio, padding])
            logger.info(
                f"[{trace_id}] EDGE-4: Applied padding: {padding_ms}ms "
                f"({padding_samples} samples), total_duration={len(audio)/sr:.3f}s"
            )
    
    return audio, sr


def prepare_audio_with_context(
    audio: np.ndarray,
    sample_rate: int,
    use_context_buffer: bool,
    trace_id: str
) -> Tuple[np.ndarray, List[Tuple[int, int]]]:
    """
    å‡†å¤‡å¸¦ä¸Šä¸‹æ–‡çš„éŸ³é¢‘å¹¶è¿›è¡ŒVADæ£€æµ‹
    
    Args:
        audio: åŸå§‹éŸ³é¢‘
        sample_rate: é‡‡æ ·ç‡
        use_context_buffer: æ˜¯å¦ä½¿ç”¨ä¸Šä¸‹æ–‡ç¼“å†²åŒº
        trace_id: è¿½è¸ªID
    
    Returns:
        (processed_audio, vad_segments) - å¤„ç†åçš„éŸ³é¢‘å’ŒVADæ£€æµ‹åˆ°çš„è¯­éŸ³æ®µ
    """
    # å‰ç½®ä¸Šä¸‹æ–‡éŸ³é¢‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if use_context_buffer:
        context_audio = get_context_audio()
        if len(context_audio) > 0:
            audio_with_context = np.concatenate([context_audio, audio])
            context_duration_sec = len(context_audio) / sample_rate
            original_duration_sec = len(audio) / sample_rate
            total_duration_sec = len(audio_with_context) / sample_rate
            logger.info(
                f"[{trace_id}] trace_id={trace_id} "
                f"context_samples={len(context_audio)} "
                f"context_duration_sec={context_duration_sec:.3f} "
                f"original_samples={len(audio)} "
                f"original_duration_sec={original_duration_sec:.3f} "
                f"total_samples={len(audio_with_context)} "
                f"total_duration_sec={total_duration_sec:.3f} "
                f"'âœ… å‰ç½®ä¸Šä¸‹æ–‡éŸ³é¢‘åˆ°å½“å‰utteranceï¼ˆä¸Šä¸‹æ–‡ç¼“å†²åŒºä¸ä¸ºç©ºï¼‰'"
            )
        else:
            audio_with_context = audio
            logger.info(
                f"[{trace_id}] trace_id={trace_id} "
                f"original_samples={len(audio)} "
                f"original_duration_sec={len(audio)/sample_rate:.3f} "
                f"'â„¹ï¸ ä¸Šä¸‹æ–‡ç¼“å†²åŒºä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘ï¼ˆç¬¬ä¸€ä¸ªutteranceæˆ–ä¸Šä¸‹æ–‡å·²æ¸…ç©ºï¼‰'"
            )
    else:
        audio_with_context = audio
    
    # ä½¿ç”¨ VAD æ£€æµ‹æœ‰æ•ˆè¯­éŸ³æ®µï¼ˆLevel 2æ–­å¥ï¼‰
    try:
        vad_segments = detect_speech(audio_with_context)
    except Exception as e:
        logger.warning(
            f"[{trace_id}] trace_id={trace_id} "
            f"error='{str(e)}' "
            f"'VADæ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨å®Œæ•´éŸ³é¢‘è¿›è¡ŒASR'"
        )
        vad_segments = []
    
    if len(vad_segments) == 0:
        logger.warning(
            f"[{trace_id}] trace_id={trace_id} "
            f"'VADæœªæ£€æµ‹åˆ°è¯­éŸ³æ®µï¼Œä½¿ç”¨å®Œæ•´éŸ³é¢‘è¿›è¡ŒASR'"
        )
        processed_audio = audio_with_context
    else:
        # æå–æœ‰æ•ˆè¯­éŸ³æ®µï¼ˆå»é™¤é™éŸ³éƒ¨åˆ†ï¼‰
        processed_audio_parts = []
        for start, end in vad_segments:
            processed_audio_parts.append(audio_with_context[start:end])
        processed_audio = np.concatenate(processed_audio_parts)
        
        logger.info(
            f"[{trace_id}] trace_id={trace_id} "
            f"segments_count={len(vad_segments)} "
            f"original_samples={len(audio_with_context)} "
            f"processed_samples={len(processed_audio)} "
            f"removed_samples={len(audio_with_context) - len(processed_audio)} "
            f"'VADæ£€æµ‹åˆ°{len(vad_segments)}ä¸ªè¯­éŸ³æ®µï¼Œå·²æå–æœ‰æ•ˆè¯­éŸ³'"
        )
        
        # å¦‚æœå¤„ç†åçš„éŸ³é¢‘å¤ªçŸ­ï¼ˆ< 0.5ç§’ï¼‰ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘
        MIN_AUDIO_SAMPLES = int(sample_rate * 0.5)  # 0.5ç§’
        if len(processed_audio) < MIN_AUDIO_SAMPLES:
            logger.warning(
                f"[{trace_id}] trace_id={trace_id} "
                f"processed_samples={len(processed_audio)} "
                f"'VADå¤„ç†åçš„éŸ³é¢‘è¿‡çŸ­ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘'"
            )
            processed_audio = audio_with_context
    
    # æœ€ç»ˆæ£€æŸ¥ï¼šç¡®ä¿ä¼ é€’ç»™ Faster Whisper çš„éŸ³é¢‘ä¸è¶…è¿‡æœ€å¤§é•¿åº¦
    processed_audio = truncate_audio_if_needed(processed_audio, sample_rate, trace_id)
    
    return processed_audio, vad_segments


async def perform_asr(
    processed_audio: np.ndarray,
    sample_rate: int,
    asr_language: Optional[str],
    task: str,
    beam_size: int,
    text_context: Optional[str],
    condition_on_previous_text: bool,
    trace_id: str,
    manager: ASRWorkerManager,
    best_of: Optional[int] = None,
    temperature: Optional[float] = None,
    patience: Optional[float] = None,
    compression_ratio_threshold: Optional[float] = None,
    log_prob_threshold: Optional[float] = None,
    no_speech_threshold: Optional[float] = None,
) -> Tuple[str, Optional[str], Optional[Dict[str, float]], List[SharedSegmentInfo], float]:
    """
    æ‰§è¡ŒASRè¯†åˆ«
    
    Args:
        processed_audio: å¤„ç†åçš„éŸ³é¢‘
        sample_rate: é‡‡æ ·ç‡
        asr_language: è¯­è¨€ä»£ç 
        task: ä»»åŠ¡ç±»å‹
        beam_size: Beam searchå®½åº¦
        text_context: æ–‡æœ¬ä¸Šä¸‹æ–‡
        condition_on_previous_text: æ˜¯å¦åŸºäºå‰æ–‡ç”Ÿæˆ
        trace_id: è¿½è¸ªID
        manager: ASR Worker Manager
        å…¶ä»–å‚æ•°: ASRä¼˜åŒ–å‚æ•°
    
    Returns:
        (full_text, detected_language, language_probabilities, segments_info, duration_sec)
    """
    asr_start_time = time.time()
    
    # æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å·²æ»¡ï¼ˆèƒŒå‹æ§åˆ¶ï¼‰
    if manager.is_queue_full():
        stats = manager.get_stats()
        logger.warning(
            f"[{trace_id}] ASR queue is full, returning 503 Service Busy. "
            f"queue_depth={stats['queue_depth']}"
        )
        raise HTTPException(
            status_code=503,
            detail="ASR service is busy, please retry later",
            headers={"Retry-After": "1"}
        )
    
    # åœ¨è°ƒç”¨transcribeä¹‹å‰è®°å½•å…³é”®ä¿¡æ¯ï¼ˆåŒ…æ‹¬ä¸Šä¸‹æ–‡ï¼‰
    stats = manager.get_stats()
    logger.info(f"[{trace_id}] ========== ASR è¯†åˆ«è¯·æ±‚å¼€å§‹ ==========")
    logger.info(
        f"[{trace_id}] ASR å‚æ•°: "
        f"language={asr_language}, "
        f"task={task}, "
        f"beam_size={beam_size}, "
        f"condition_on_previous_text={condition_on_previous_text}, "
        f"queue_depth={stats['queue_depth']}, "
        f"worker_state={stats['worker_state']}"
    )
    logger.info(
        f"[{trace_id}] ASR ä¸Šä¸‹æ–‡å‚æ•°: "
        f"has_initial_prompt={text_context is not None and len(text_context) > 0}, "
        f"initial_prompt_length={len(text_context) if text_context else 0}, "
        f"initial_prompt_preview='{text_context[:100] if text_context else '(None)'}'"
    )
    logger.info(
        f"[{trace_id}] ASR éŸ³é¢‘å‚æ•°: "
        f"audio_len={len(processed_audio)}, "
        f"sample_rate={sample_rate}, "
        f"duration_sec={len(processed_audio) / sample_rate:.2f}"
    )
    
    try:
        # æäº¤ä»»åŠ¡åˆ°ASR Workerè¿›ç¨‹
        asr_result = await manager.submit_task(
            audio=processed_audio,
            sample_rate=sample_rate,
            language=asr_language,
            task=task,
            beam_size=beam_size,
            initial_prompt=text_context if text_context else None,
            condition_on_previous_text=condition_on_previous_text,
            trace_id=trace_id,
            max_wait=MAX_WAIT_SECONDS,
            best_of=best_of,
            temperature=temperature,
            patience=patience,
            compression_ratio_threshold=compression_ratio_threshold,
            log_prob_threshold=log_prob_threshold,
            no_speech_threshold=no_speech_threshold,
        )
        
        # æ£€æŸ¥ç»“æœ
        if asr_result.error:
            logger.error(
                f"[{trace_id}] ASR Worker returned error: {asr_result.error}",
                exc_info=True
            )
            raise HTTPException(
                status_code=500,
                detail=f"ASR processing failed: {asr_result.error}"
            )
        
        # ä»ç»“æœä¸­è·å–æ–‡æœ¬å’Œè¯­è¨€ä¿¡æ¯
        full_text = asr_result.text or ""
        detected_language = asr_result.language
        language_probabilities = asr_result.language_probabilities
        segments_info_raw = asr_result.segments
        duration_sec = asr_result.duration_ms / 1000.0 if asr_result.duration_ms > 0 else 0.0
        
        logger.info(f"[{trace_id}] ========== ASR æ¥å£è¾“å‡ºç»“æœ ==========")
        logger.info(
            f"[{trace_id}] ASR Worker completed successfully, "
            f"text_len={len(full_text)}, language={detected_language}, "
            f"duration_ms={asr_result.duration_ms}"
        )
        logger.info(f"[{trace_id}] ASR æ¥å£è¾“å‡ºåŸå§‹æ–‡æœ¬ (repr): {repr(full_text)}")
        logger.info(f"[{trace_id}] ASR æ¥å£è¾“å‡ºåŸå§‹æ–‡æœ¬ (preview): '{full_text[:200]}'")
        logger.info(f"[{trace_id}] ASR æ¥å£è¾“å‡ºåŸå§‹æ–‡æœ¬ (bytes): {full_text.encode('utf-8') if full_text else b''}")
        
        # ä½¿ç”¨çœŸæ­£çš„ segments æ•°æ®ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
        segments_info: List[SharedSegmentInfo] = []
        if segments_info_raw:
            segments_info = [
                SharedSegmentInfo(
                    text=seg.text,
                    start=seg.start,
                    end=seg.end,
                    no_speech_prob=seg.no_speech_prob,
                )
                for seg in segments_info_raw
            ]
        
        # å¦‚æœ segments ä¸ºç©ºï¼Œä»æ–‡æœ¬ç”Ÿæˆï¼ˆå‘åå…¼å®¹ï¼‰
        if not segments_info and full_text:
            segment_texts_split = [s.strip() for s in full_text.split() if s.strip()]
            if segment_texts_split:
                segments_info = [
                    SharedSegmentInfo(text=text, start=None, end=None, no_speech_prob=None)
                    for text in segment_texts_split
                ]
            else:
                segments_info = [SharedSegmentInfo(text=full_text, start=None, end=None, no_speech_prob=None)]
        
        asr_elapsed = time.time() - asr_start_time
        logger.info(f"[{trace_id}] Step 8.1: Text extraction completed, segments={len(segments_info)}, full_text_len={len(full_text)}")
        
        # è®°å½• ASR å¤„ç†æ—¶é—´ï¼ˆç”¨äºæ€§èƒ½ç›‘æ§ï¼‰
        if asr_elapsed > 1.0:
            audio_duration = len(processed_audio) / sample_rate
            ratio = asr_elapsed / audio_duration if audio_duration > 0 else 0
            logger.warning(
                f"[{trace_id}] "
                f"âš ï¸ ASR processing took {asr_elapsed:.2f}s "
                f"(audio duration: {audio_duration:.2f}s, ratio: {ratio:.2f}x)"
            )
        
        return full_text, detected_language, language_probabilities, segments_info, duration_sec
        
    except asyncio.TimeoutError:
        stats = manager.get_stats()
        logger.error(
            f"[{trace_id}] ASR task timeout after {MAX_WAIT_SECONDS}s, "
            f"queue_depth={stats['queue_depth']}"
        )
        raise HTTPException(
            status_code=504,
            detail=f"ASR processing timeout after {MAX_WAIT_SECONDS}s"
        )
    except RuntimeError as e:
        logger.error(
            f"[{trace_id}] ASR Worker process not available: {e}",
            exc_info=True
        )
        raise HTTPException(
            status_code=503,
            detail="ASR service is temporarily unavailable, please retry later",
            headers={"Retry-After": "2"}
        )
    except Exception as e:
        logger.error(
            f"[{trace_id}] ASR Worker exception: {e}",
            exc_info=True
        )
        raise HTTPException(
            status_code=500,
            detail=f"ASR processing failed: {str(e)}"
        )


def update_context_buffer_if_needed(
    audio: np.ndarray,
    use_context_buffer: bool,
    trace_id: str
) -> None:
    """
    æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒºï¼ˆä½¿ç”¨åŸå§‹éŸ³é¢‘ï¼Œä¸å¸¦ä¸Šä¸‹æ–‡ï¼‰
    
    Args:
        audio: åŸå§‹éŸ³é¢‘
        use_context_buffer: æ˜¯å¦ä½¿ç”¨ä¸Šä¸‹æ–‡ç¼“å†²åŒº
        trace_id: è¿½è¸ªID
    """
    if not use_context_buffer:
        return
    
    logger.info(f"[{trace_id}] Step 12: Starting context buffer update (use_context_buffer={use_context_buffer})")
    
    try:
        # ä½¿ç”¨ VAD æ£€æµ‹åŸå§‹éŸ³é¢‘çš„è¯­éŸ³æ®µ
        logger.info(f"[{trace_id}] Step 12.1: Starting VAD detection for context buffer (audio_len={len(audio)})")
        try:
            original_vad_segments = detect_speech(audio)
            logger.info(f"[{trace_id}] Step 12.1: VAD detection completed, segments={len(original_vad_segments)}")
        except Exception as e:
            logger.warning(
                f"[{trace_id}] trace_id={trace_id} "
                f"error='{str(e)}' "
                f"'VADæ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨ç®€å•å°¾éƒ¨ä¿å­˜ä¸Šä¸‹æ–‡'"
            )
            original_vad_segments = []
        
        if len(original_vad_segments) > 0:
            # é€‰æ‹©æœ€åä¸€ä¸ªè¯­éŸ³æ®µ
            last_start, last_end = original_vad_segments[-1]
            last_segment = audio[last_start:last_end]
            context_samples = int(CONTEXT_DURATION_SEC * CONTEXT_SAMPLE_RATE)
            
            if len(last_segment) > context_samples:
                logger.info(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"context_samples={context_samples} "
                    f"context_duration_sec={context_samples/CONTEXT_SAMPLE_RATE:.3f} "
                    f"segment_start={last_start} "
                    f"segment_end={last_end} "
                    f"segment_samples={len(last_segment)} "
                    f"'âœ… æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒºï¼ˆä½¿ç”¨VADé€‰æ‹©çš„æœ€åä¸€ä¸ªè¯­éŸ³æ®µå°¾éƒ¨ï¼‰'"
                )
            else:
                logger.info(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"context_samples={len(last_segment)} "
                    f"context_duration_sec={len(last_segment)/CONTEXT_SAMPLE_RATE:.3f} "
                    f"segment_samples={len(last_segment)} "
                    f"'âœ… æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒºï¼ˆæœ€åä¸€ä¸ªè¯­éŸ³æ®µè¾ƒçŸ­ï¼Œä¿å­˜å…¨éƒ¨ï¼‰'"
                )
            
            logger.info(f"[{trace_id}] Step 12.2: Updating context buffer")
            update_context_buffer(audio, original_vad_segments)
            logger.info(f"[{trace_id}] Step 12.2: Context buffer updated successfully")
        else:
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³æ®µï¼Œå›é€€åˆ°ç®€å•å°¾éƒ¨ä¿å­˜
            context_samples = int(CONTEXT_DURATION_SEC * CONTEXT_SAMPLE_RATE)
            if len(audio) > context_samples:
                logger.info(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"context_samples={context_samples} "
                    f"context_duration_sec={context_samples/CONTEXT_SAMPLE_RATE:.3f} "
                    f"original_samples={len(audio)} "
                    f"'âš ï¸ æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒºï¼ˆVADæœªæ£€æµ‹åˆ°è¯­éŸ³æ®µï¼Œä¿å­˜æœ€å{CONTEXT_DURATION_SEC}ç§’ï¼‰'"
                )
            else:
                logger.info(
                    f"[{trace_id}] trace_id={trace_id} "
                    f"context_samples={len(audio)} "
                    f"context_duration_sec={len(audio)/CONTEXT_SAMPLE_RATE:.3f} "
                    f"original_samples={len(audio)} "
                    f"'âš ï¸ æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å†²åŒºï¼ˆutteranceè¾ƒçŸ­ï¼Œä¿å­˜å…¨éƒ¨ï¼‰'"
                )
            
            logger.info(f"[{trace_id}] Step 12.2: Updating context buffer")
            update_context_buffer(audio, [])
            logger.info(f"[{trace_id}] Step 12.2: Context buffer updated successfully")
        
        logger.info(f"[{trace_id}] Step 12: Context buffer update completed")
    except Exception as e:
        logger.error(f"[{trace_id}] Step 12: Failed to update context buffer: {e}", exc_info=True)
        raise
