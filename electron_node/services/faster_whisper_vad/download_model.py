"""
ä¸‹è½½ Faster Whisper æ¨¡å‹åˆ°æœ¬åœ°
ä½¿ç”¨ HuggingFace token ä¸‹è½½æ¨¡å‹å¹¶è½¬æ¢ä¸º CTranslate2 æ ¼å¼
"""
import os
import sys
import logging
from pathlib import Path

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def download_model(
    model_name: str = "Systran/faster-whisper-large-v3",
    output_dir: str = "models/asr/faster-whisper-large-v3",
    device: str = "cpu",
    compute_type: str = "float32",
    hf_token: str = None
):
    """
    ä¸‹è½½ Faster Whisper æ¨¡å‹åˆ°æœ¬åœ°
    
    Args:
        model_name: HuggingFace æ¨¡å‹åç§°ï¼Œå¦‚ "Systran/faster-whisper-large-v3"
        output_dir: æœ¬åœ°è¾“å‡ºç›®å½•
        device: è®¾å¤‡ç±»å‹ ("cpu" æˆ– "cuda")
        compute_type: è®¡ç®—ç±»å‹ ("float32", "float16", "int8")
        hf_token: HuggingFace tokenï¼ˆå¦‚æœæ¨¡å‹éœ€è¦è®¤è¯ï¼‰
    """
    try:
        from faster_whisper import WhisperModel
    except ImportError:
        logger.error("âŒ faster-whisper æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…: pip install faster-whisper")
        sys.exit(1)
    
    # è®¾ç½® HuggingFace tokenï¼ˆå¦‚æœæä¾›ï¼‰
    if hf_token:
        os.environ["HF_TOKEN"] = hf_token
        logger.info("âœ… HuggingFace token å·²è®¾ç½®")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {output_path.absolute()}")
    
    logger.info("=" * 80)
    logger.info(f"ğŸš€ å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_name}")
    logger.info(f"   è®¾å¤‡: {device}")
    logger.info(f"   è®¡ç®—ç±»å‹: {compute_type}")
    logger.info(f"   è¾“å‡ºç›®å½•: {output_path.absolute()}")
    logger.info("=" * 80)
    
    try:
        # ä½¿ç”¨ faster-whisper ä¸‹è½½æ¨¡å‹
        # faster-whisper ä¼šè‡ªåŠ¨ä» HuggingFace ä¸‹è½½å¹¶è½¬æ¢ä¸º CTranslate2 æ ¼å¼
        logger.info("ğŸ“¥ æ­£åœ¨ä» HuggingFace ä¸‹è½½æ¨¡å‹ï¼ˆè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰...")
        
        model = WhisperModel(
            model_name,
            device=device,
            compute_type=compute_type,
            download_root=str(output_path.parent),  # è®¾ç½®ä¸‹è½½æ ¹ç›®å½•
        )
        
        logger.info("âœ… æ¨¡å‹ä¸‹è½½å¹¶è½¬æ¢æˆåŠŸï¼")
        logger.info(f"ğŸ“ æ¨¡å‹ä½ç½®: {output_path.absolute()}")
        
        # éªŒè¯æ¨¡å‹æ–‡ä»¶
        model_files = list(output_path.glob("*"))
        if model_files:
            logger.info(f"ğŸ“¦ æ¨¡å‹æ–‡ä»¶:")
            for f in model_files:
                size_mb = f.stat().st_size / (1024 * 1024)
                logger.info(f"   - {f.name} ({size_mb:.2f} MB)")
        else:
            # æ£€æŸ¥çˆ¶ç›®å½•ï¼ˆfaster-whisper å¯èƒ½å°†æ¨¡å‹æ”¾åœ¨ä¸åŒçš„ä½ç½®ï¼‰
            parent_files = list(output_path.parent.glob("*"))
            logger.info(f"ğŸ“¦ åœ¨çˆ¶ç›®å½•æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶:")
            for f in parent_files:
                if f.is_dir():
                    size_mb = sum(p.stat().st_size for p in f.rglob("*") if p.is_file()) / (1024 * 1024)
                    logger.info(f"   - {f.name}/ ({size_mb:.2f} MB)")
        
        logger.info("=" * 80)
        logger.info("âœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        logger.info(f"   ç°åœ¨å¯ä»¥åœ¨é…ç½®ä¸­ä½¿ç”¨æœ¬åœ°è·¯å¾„: {output_path.absolute()}")
        logger.info("=" * 80)
        
        return str(output_path.absolute())
        
    except Exception as e:
        logger.error(f"âŒ ä¸‹è½½æ¨¡å‹å¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ä¸‹è½½ Faster Whisper æ¨¡å‹åˆ°æœ¬åœ°")
    parser.add_argument(
        "--model",
        type=str,
        default="Systran/faster-whisper-large-v3",
        help="HuggingFace æ¨¡å‹åç§°ï¼ˆé»˜è®¤: Systran/faster-whisper-large-v3ï¼‰"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="models/asr/faster-whisper-large-v3",
        help="æœ¬åœ°è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: models/asr/faster-whisper-large-v3ï¼‰"
    )
    parser.add_argument(
        "--device",
        type=str,
        choices=["cpu", "cuda"],
        default="cpu",
        help="è®¾å¤‡ç±»å‹ï¼ˆé»˜è®¤: cpuï¼‰"
    )
    parser.add_argument(
        "--compute-type",
        type=str,
        choices=["float32", "float16", "int8"],
        default="float32",
        help="è®¡ç®—ç±»å‹ï¼ˆé»˜è®¤: float32ï¼‰"
    )
    parser.add_argument(
        "--token",
        type=str,
        default=None,
        help="HuggingFace tokenï¼ˆå¦‚æœæ¨¡å‹éœ€è¦è®¤è¯ï¼‰"
    )
    
    args = parser.parse_args()
    
    # å¦‚æœæ²¡æœ‰æä¾› tokenï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶è¯»å–
    if not args.token:
        # å°è¯•ä»ç¯å¢ƒå˜é‡è¯»å–
        args.token = os.getenv("HF_TOKEN")
        # å¦‚æœç¯å¢ƒå˜é‡ä¹Ÿæ²¡æœ‰ï¼Œå°è¯•ä»é…ç½®æ–‡ä»¶è¯»å–
        if not args.token:
            try:
                from config import HF_TOKEN
                args.token = HF_TOKEN
            except:
                pass
    
    download_model(
        model_name=args.model,
        output_dir=args.output,
        device=args.device,
        compute_type=args.compute_type,
        hf_token=args.token
    )


if __name__ == "__main__":
    main()

