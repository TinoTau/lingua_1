# 按需服务选择配置驱动设计 - 更新说明

## 更新内容

根据用户需求，对按需服务选择设计进行了以下调整：

### 1. TONE 流程调整

**之前**：
- TONE 包括 TTS + TONE 两个步骤
- 流程：ASR → Aggregation → Semantic Repair → Dedup → Translation → TTS → TONE

**现在**：
- TONE 使用 YourTTS 步骤
- 流程：ASR → Aggregation → Semantic Repair → Dedup → Translation → **YourTTS**
- **注意**：YourTTS 会从 `reference_audio` 中自动提取音色向量，不需要单独的 Embedding 步骤

### 2. 新增步骤类型

#### YOURTTS 步骤
- **位置**：`electron_node/electron-node/main/src/pipeline/steps/yourtts-step.ts`
- **功能**：使用 YourTTS 服务进行音色克隆
- **服务**：调用 `your-tts` 服务（端口 5004）
- **输入**：翻译文本、speakerId（job_id）、voiceEmbedding
- **输出**：WAV 格式的音频（base64 编码）

### 3. 音色标识调整

**之前**：
- 使用 `speaker_id` 作为音色标识
- 需要 web 端提供 `speaker_id`

**现在**：
- 使用 `job_id` 作为音色标识
- 每段音频使用自己的 `job_id` 作为 `speaker_id`
- 支持不同 session 的任务随机分配

### 4. Pipeline 模式配置更新

#### PERSONAL_VOICE_TRANSLATION 模式

**步骤序列**：
```
ASR → AGGREGATION → SEMANTIC_REPAIR → DEDUP → TRANSLATION → YOURTTS
```

**依赖关系**：
- AGGREGATION 依赖 ASR
- SEMANTIC_REPAIR 依赖 AGGREGATION
- DEDUP 依赖 SEMANTIC_REPAIR
- TRANSLATION 依赖 DEDUP
- YOURTTS 依赖 TRANSLATION

**执行条件**：
- YOURTTS：`use_tone === true`

**注意**：YourTTS 会从 `reference_audio` 中自动提取音色向量，不需要单独的 Embedding 步骤

### 5. 步骤注册表更新

在 `pipeline-step-registry.ts` 中注册了新步骤：

```typescript
export const STEP_REGISTRY: Record<PipelineStepType, StepExecutor> = {
  // ... 其他步骤
  YOURTTS: async (job, ctx, services) => {
    await runYourTtsStep(job, ctx, services);
  },
};
```

**注意**：已移除 EMBEDDING 步骤，因为 YourTTS 会从 `reference_audio` 中自动提取音色向量

### 6. JobContext 扩展

在 `JobContext` 中添加了以下字段（通过类型扩展）：

```typescript
interface JobContext {
  // ... 现有字段
  // Embedding 相关（通过类型扩展）
  voiceEmbedding?: string; // base64 编码的 embedding
  speakerId?: string;      // 使用 job_id
  useDefaultVoice?: boolean; // 是否使用默认音色
}
```

## 实现细节

### YourTTS 步骤实现

1. **服务选择**：
   - 选择 `your-tts` 服务端点（`serviceId === 'your-tts'`）

2. **参数准备**：
   - 从 `ctx.voiceEmbedding` 获取 embedding（如果需要）
   - 使用 `ctx.speakerId` 或 `job.job_id` 作为 `speaker_id`

3. **服务调用**：
   - 调用 `/synthesize` 端点
   - 传递 `text`、`speaker_id`、`language`

4. **结果处理**：
   - YourTTS 返回 JSON：`{ audio: number[], sample_rate: 22050 }`
   - 将 f32 数组转换为 WAV 格式
   - 存储到 `ctx.ttsAudio`（base64 编码）

## 使用示例

### Web 端配置

```json
{
  "pipeline": {
    "use_asr": true,
    "use_nmt": true,
    "use_tts": true,
    "use_tone": true
  }
}
```

### 节点端执行流程

1. **ASR 步骤**：识别音频文本，将解码后的 PCM16 音频存储到 `ctx.audio`
2. **Aggregation 步骤**：聚合文本
3. **Semantic Repair 步骤**：语义修复
4. **Dedup 步骤**：去重检查
5. **Translation 步骤**：翻译文本
6. **YourTTS 步骤**：从 `ctx.audio` 获取 PCM16 音频，转换为 f32 后作为 `reference_audio` 传递，YourTTS 会从 `reference_audio` 中自动提取音色向量

## 注意事项

1. **音频格式**：
   - YourTTS 步骤需要 PCM16 格式的音频（ASR 步骤已解码并存储到 `ctx.audio`）
   - 将 PCM16 转换为 f32 格式后传递给 YourTTS 服务

2. **音色向量提取**：
   - YourTTS 服务会从 `reference_audio` 中自动提取音色向量
   - 不需要单独的 Embedding 步骤

3. **错误处理**：
   - YourTTS 失败时返回空音频

4. **性能考虑**：
   - YourTTS 合成比普通 TTS 慢，需要更长的超时时间（30 秒）
   - YourTTS 内部会从 `reference_audio` 中提取音色向量，这个过程在服务端完成

## 后续优化建议

1. **音频格式优化**：
   - 统一音频格式处理，避免重复转换

2. **YourTTS 性能优化**：
   - 如果未来需要缓存音色向量，可以考虑在节点端缓存 `reference_audio`
   - 或者使用 YourTTS 的 `/register_speaker` 端点缓存 speaker
