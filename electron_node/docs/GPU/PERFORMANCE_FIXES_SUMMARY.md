# 性能问题修复总结

## 修复内容

### ✅ 1. 修复max_new_tokens（保持动态机制）

**问题**：Job 12文本丢失，可能是`max_new_tokens`限制不够

**修复**：
- 增加默认上限：从512增加到1024
- 保持动态机制：根据输入长度动态调整上限
  - 短文本（<20 tokens）：256
  - 中等文本（20-50 tokens）：512（从384增加）
  - 长文本（50-100 tokens）：768（新增）
  - 超长文本（>100 tokens）：1024（从512增加）

**修改文件**：
- `translation_utils.py` - 增加动态上限
- `nmt_service.py` - 更新默认max_tokens参数

### ✅ 2. 改进extract_translation提取逻辑

**问题**：提取的翻译可能太短，导致文本丢失

**修复**：
- 改进长度检查：更严格地检测截断
  - 如果提取的翻译少于原文30%，且原文较长（>10字符），记录警告
  - 如果提取的翻译少于原文50%，且原文较长（>5字符），记录警告
  - 添加比例日志，便于调试

**修改文件**：
- `translation_extractor.py` - 改进长度检查逻辑

### ✅ 3. 修复removeTail逻辑（检测叠字叠词）

**问题**：removeTail固定移除6个字符，应该检测并移除末尾的重复文本（叠字叠词）

**修复**：
- 新增`detectTailRepetition`函数：检测文本末尾的重复（叠字叠词）
  - CJK模式：检测末尾重复的字符或短语（如 "速度速度" 或 "再提高了一点速度 再提高了一点速度"）
  - 英文模式：检测末尾重复的词或短语（如 "speed speed"）
- 修改`removeTail`函数：
  - 优先检测并移除末尾的重复文本（叠字叠词）
  - 如果没有检测到重复，再使用原有的tail buffer逻辑
  - 保留兜底逻辑：如果检测失败，使用固定字符数移除

**修改文件**：
- `tail-carry.ts` - 新增重复检测逻辑，改进removeTail函数

### ✅ 4. 改进context_text获取逻辑

**问题**：Job 13使用了Job 12的完整文本作为context_text，导致重复翻译

**修复**：
- 提高相似度阈值：从20%增加到30%，避免误判
- 新增检查：如果历史文本包含当前文本，且长度差异很大（超过50%），跳过该历史文本
  - 例如：当前文本="再提高了一点速度"
  - 历史文本="提高了一点,那我希望接下来可以做到更好更快 也就是说我们需要把这个事情继续做下去 然后这个架构也没有太大的问题,只是需要再提升一点速度"
  - 这种情况下，历史文本是合并后的长文本，不应该作为context

**修改文件**：
- `aggregator-manager.ts` - 改进getLastCommittedText逻辑

## 预期效果

1. **Job 12文本丢失问题**：
   - 增加max_new_tokens上限，支持更长文本的翻译
   - 改进extract_translation逻辑，更准确地检测截断

2. **Job 13和14文本被截断问题**：
   - removeTail现在会检测并移除末尾的重复文本，而不是固定移除6个字符
   - 避免误删重要文本

3. **Job 13和14重复Job 12问题**：
   - 改进context_text获取逻辑，避免使用包含当前文本的长文本作为context
   - 提高相似度阈值，减少误判

## 测试建议

1. 重新运行集成测试，验证修复效果
2. 检查Job 12的翻译是否完整
3. 检查Job 13和14的文本是否被正确截断（移除重复部分）
4. 检查context_text是否正确（不应该使用包含当前文本的长文本）
