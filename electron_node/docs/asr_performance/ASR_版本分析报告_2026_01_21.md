# ASR 版本分析与环境诊断报告

**日期**: 2026-01-21 00:50  
**目的**: 对比当前环境与备份环境，定位版本差异

---

## 📋 当前环境版本信息

### Python依赖包

| 包名 | 当前版本 | requirements.txt要求 | 状态 |
|------|---------|-------------------|------|
| **faster-whisper** | 1.2.1 | >=1.0.0 | ✅ |
| **onnxruntime-gpu** | 1.23.2 | ==1.23.2（锁定） | ✅ |
| **ctranslate2** | 4.6.2 | （依赖） | ✅ |
| numpy | 1.26.4 | >=1.24.0 | ✅ |
| torch | （未使用） | - | - |

### CUDA/cuDNN环境

| 组件 | 版本 | 状态 |
|------|------|------|
| **CUDA** | 12.4 | ✅ |
| **cuDNN** | 9.1.0 (90100) | ✅ |
| **GPU Driver** | 551.61 | ✅ |
| **GPU型号** | RTX 4060 | ✅ |

### ONNX Runtime配置

```python
Version: 1.23.2
Available Providers:
- TensorrtExecutionProvider  ✅
- CUDAExecutionProvider      ✅
- CPUExecutionProvider        ✅
```

---

## 🔍 与备份环境的差异

### requirements.txt对比

| 包 | 备份代码 | 当前代码 | 差异 |
|---|---------|---------|------|
| onnxruntime-gpu | `>=1.16.0` | `==1.23.2` | 🔴 **锁定版本** |

**重要发现**:
```
备份代码 requirements.txt:
onnxruntime-gpu>=1.16.0  ← 允许任意>=1.16的版本

当前代码 requirements.txt:
onnxruntime-gpu==1.23.2  ← 强制锁定到1.23.2
```

**修改时间**: 2026-01-20  
**修改原因**: "锁定版本以支持cuDNN 9.x"  
**修改记录**: 见`VAD_ONNX_RUNTIME_VERSION_FIX_2026_01_20.md`

---

## 📊 关键时间线

```
时间线分析：
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
2026-01-19之前:
  备份代码正常运行
  onnxruntime-gpu: 可能是1.16.x-1.22.x之间某个版本
  真实音频测试: ✅ 通过
  
2026-01-20 上午:
  升级cuDNN 9.6
  发现ONNX Runtime 1.16.x不兼容
  升级onnxruntime-gpu到1.23.2
  验证: ✅ 服务能启动（但未做性能测试）

2026-01-20 晚上:
  运行50次基准测试（合成音频）
  结果: ✅ 性能稳定（但segments_count=0）

2026-01-21 凌晨:
  真实音频集成测试
  发现: ❌ 性能慢（1.7-2.2x音频时长）
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

**关键问题**: 
2026-01-20升级到1.23.2后，**只验证了服务启动，没有验证性能**。

---

## 💡 可能的版本问题

### 问题1: onnxruntime-gpu 1.23.2 可能有性能回归

#### 证据

1. **时间巧合**
   - 2026-01-20升级到1.23.2
   - 2026-01-21发现性能问题

2. **版本特性**
   - 1.23.2是相对较新的版本（2024年12月发布）
   - 可能包含未发现的性能bug

3. **没有对比数据**
   - 备份代码时用的是什么版本？未知
   - 无法确认1.23.2是否真的有问题

#### 验证方法

**降级到中间版本测试**:
```bash
# 1.19.0（2024年6月，相对稳定）
pip install onnxruntime-gpu==1.19.0

# 1.20.0（2024年8月）
pip install onnxruntime-gpu==1.20.0

# 1.21.0（2024年9月）
pip install onnxruntime-gpu==1.21.0
```

每次安装后：
1. 重启ASR服务
2. 运行集成测试
3. 记录性能数据
4. 对比哪个版本最快

---

### 问题2: cuDNN 9.x vs 8.x的性能差异

#### 证据

```
备份代码可能用的配置:
- onnxruntime-gpu 1.16.x + cuDNN 8.x

当前代码配置:
- onnxruntime-gpu 1.23.2 + cuDNN 9.1
```

**假设**: 
- cuDNN 9.x可能比8.x慢（某些操作的优化程度不同）
- 或者onnxruntime-gpu 1.23.2对cuDNN 9.x的优化不够好

#### 验证方法

无法简单验证（需要降级整个CUDA/cuDNN环境，成本太高）

---

### 问题3: ctranslate2 4.6.2 的兼容性

faster-whisper依赖ctranslate2进行底层推理。

#### 验证方法

```bash
# 尝试降级到稳定版本
pip install ctranslate2==4.4.0
# 或
pip install ctranslate2==4.5.0
```

---

## 🧪 建议的测试顺序

### 🔴 测试1: 重启ASR服务后验证（5分钟）

**目的**: 确认重新安装是否解决了损坏残留的问题

```bash
# 1. 启动ASR服务
cd d:\Programs\github\lingua_1\electron_node\services\faster_whisper_vad
python faster_whisper_vad_service.py

# 2. 进行集成测试（您的标准测试）
# 3. 观察性能是否改善
```

**预期结果**:
- 如果性能改善 → 是安装损坏问题（已解决）✅
- 如果性能仍慢 → 是版本问题，继续测试2

---

### 🟡 测试2: 降级到1.19.0（20分钟）

**目的**: 验证1.23.2是否有性能回归

```bash
# 1. 停止ASR服务
# 2. 降级
pip install onnxruntime-gpu==1.19.0

# 3. 重启ASR服务
# 4. 集成测试
# 5. 对比性能数据
```

**预期结果**:
- 如果1.19.0更快 → 确认1.23.2有性能问题
- 如果1.19.0同样慢 → 不是版本问题

---

### 🟡 测试3: 尝试其他版本（如果测试2有改善，继续微调）

```bash
# 如果1.19.0有改善，尝试1.20.0和1.21.0找到最佳版本
pip install onnxruntime-gpu==1.20.0
pip install onnxruntime-gpu==1.21.0
pip install onnxruntime-gpu==1.22.0
```

---

### 🟢 测试4: 如果所有版本都慢，降级ctranslate2

```bash
pip install ctranslate2==4.4.0
```

---

## 📊 预期的测试结果矩阵

| onnxruntime版本 | 预期性能 | 如果达到 | 建议 |
|----------------|---------|---------|------|
| 1.23.2（当前） | 1.7-2.2x | 慢 ❌ | 降级 |
| 1.22.0 | 1.0-1.5x？ | 中 | 继续测试 |
| 1.21.0 | 1.0-1.5x？ | 中 | 继续测试 |
| 1.20.0 | 0.8-1.2x？ | 可接受 | 考虑使用 |
| 1.19.0 | 0.5-1.0x？ | 好 ✅ | 推荐使用 |
| 1.18.0 | 0.5-1.0x？ | 好 ✅ | 备选 |

**目标**: 找到性能<1.0x（处理时间<音频时长）的版本

---

## 🎯 版本推荐策略

### 策略A: 保守降级（推荐）

```
降级到: onnxruntime-gpu==1.19.0
理由:
- 相对稳定（2024年6月发布）
- 支持cuDNN 9.x
- 距离1.23.2不太远，兼容性好
```

### 策略B: 激进降级

```
降级到: onnxruntime-gpu==1.18.0
理由:
- 第一个支持cuDNN 9.x的版本
- 如果1.19-1.23都有问题，这个可能OK
```

### 策略C: 微调优化

```
在1.19-1.23之间二分查找最佳版本
```

---

## 🔧 快速修复脚本

我为您准备了一个测试脚本：

```powershell
# test_onnx_versions.ps1
$versions = @("1.19.0", "1.20.0", "1.21.0", "1.22.0", "1.23.2")

foreach ($ver in $versions) {
    Write-Host "`n===== Testing onnxruntime-gpu $ver =====" -ForegroundColor Cyan
    
    # 安装
    pip install "onnxruntime-gpu==$ver" -q
    
    # 验证
    python -c "import onnxruntime; print('Installed:', onnxruntime.__version__)"
    
    # 提示测试
    Write-Host "请运行集成测试，然后输入本次测试的平均耗时（秒）:" -ForegroundColor Yellow
    $result = Read-Host
    
    Write-Host "版本 $ver 的性能: $result 秒" -ForegroundColor Green
}

Write-Host "`n所有版本测试完成！" -ForegroundColor Cyan
```

---

## 📞 立即行动建议

### 方案A: 快速验证（推荐）

```bash
# 1. 重启ASR服务（使用当前1.23.2）
cd d:\Programs\github\lingua_1\electron_node\services\faster_whisper_vad
python faster_whisper_vad_service.py

# 2. 运行您的标准集成测试
# 3. 记录性能数据

# 4. 如果仍然慢，立即降级到1.19.0
pip install onnxruntime-gpu==1.19.0
# 重启服务
# 再次测试
```

**预计时间**: 20分钟  
**预期结果**: 
- 如果1.23.2重装后OK → 问题已解决
- 如果1.23.2仍慢，1.19.0快 → 锁定1.19.0

---

### 方案B: 系统测试（如果有时间）

使用上面的`test_onnx_versions.ps1`脚本，测试所有版本，找到最优解。

**预计时间**: 1.5小时

---

## ⚠️ 重要提醒

### 损坏残留的警告

```
WARNING: Ignoring invalid distribution -nnxruntime-gpu
```

虽然我们尝试清理，但警告仍然存在。这可能：
- 只是pip元数据问题（不影响功能）
- 或者残留在其他位置

**如果测试后性能仍慢**，可能需要：
```bash
# 完全清理Python环境（最后手段）
pip cache purge
rm -r d:\python\python310\lib\site-packages\onnxruntime*
rm -r d:\python\python310\lib\site-packages\*nnx*
pip install onnxruntime-gpu==1.19.0
```

---

## 📊 当前配置总结

```yaml
环境配置:
  Python: 3.10
  faster-whisper: 1.2.1
  onnxruntime-gpu: 1.23.2 (已重新安装)
  ctranslate2: 4.6.2
  CUDA: 12.4
  cuDNN: 9.1.0
  GPU: RTX 4060 (8GB)

性能状态:
  基线性能: 1.7-2.2x 音频时长 ⚠️ 慢
  目标性能: <1.0x 音频时长
  差距: 1.7-2.2倍

下一步:
  1. 重启ASR服务
  2. 运行集成测试
  3. 如果仍慢，降级到1.19.0
```

---

**报告状态**: ✅ 环境清理完成，等待测试验证  
**下一步**: 重启ASR服务并测试  
**备选方案**: 降级到onnxruntime-gpu 1.19.0
